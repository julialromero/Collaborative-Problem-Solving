{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48addfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import itertools\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap \n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8de4c",
   "metadata": {},
   "source": [
    "# Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df414ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURES_FILE = \"MdRQA_measures_prelim.csv\"\n",
    "SHUFF_MEASURES_FILE = \"shuff_MdRQA_measures_prelim.csv\"\n",
    "LABELS_FILE = \"team_block_outcomes.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084f123",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2951565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MdRQA_measures_prelim.csv shape: (271, 11)\n",
      "shuff_MdRQA_measures_prelim.csv shape: (271, 11)\n",
      "team_block_outcomes.csv shape: (274, 7)\n"
     ]
    }
   ],
   "source": [
    "dfMeasures = pd.read_csv(MEASURES_FILE)\n",
    "dfShuffMeasures = pd.read_csv(SHUFF_MEASURES_FILE)\n",
    "dfLabels = pd.read_csv(LABELS_FILE)\n",
    "\n",
    "\n",
    "# dfTaskScore = dfLabels.loc[:, ['GROUPID', 'block', 'task_score']]\n",
    "# dfSubjectiveOutcomes = dfLabels.loc[:, ['GROUPID', 'block', 'CPS_and_ITN_mean']]\n",
    "# dfValence = dfLabels.loc[:, ['GROUPID', 'block', 'Valence']]\n",
    "\n",
    "print(\"%s shape: %s\" % (MEASURES_FILE, dfMeasures.shape))\n",
    "print(\"%s shape: %s\" % (SHUFF_MEASURES_FILE, dfShuffMeasures.shape))\n",
    "print(\"%s shape: %s\" % (LABELS_FILE, dfLabels.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7980252",
   "metadata": {},
   "source": [
    "# Experiment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e0b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfData shape:  (271, 11)\n",
      "dfLabels shape:  (271, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get model type\n",
    "shuffled = False\n",
    "num_iters = 2\n",
    "num_folds = 5\n",
    "\n",
    "if shuffled:\n",
    "    dfData = dfShuffMeasures\n",
    "    dfLabels = pd.merge(dfLabels, dfMeasures, on=['GROUPID', 'block'], how='inner')\\\n",
    "           [['GROUPID', 'block', 'CPS_and_ITN_mean', 'Valence', 'task_score']]\n",
    "else:\n",
    "    dfData = dfMeasures\n",
    "    dfLabels = pd.merge(dfLabels, dfShuffMeasures, on=['GROUPID', 'block'], how='inner')\\\n",
    "           [['GROUPID', 'block', 'CPS_and_ITN_mean', 'Valence', 'task_score']]\n",
    "\n",
    "print(\"dfData shape: \", dfData.shape)\n",
    "print(\"dfLabels shape: \", dfLabels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0743a",
   "metadata": {},
   "source": [
    "## Prep for team-level cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a614206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fold names:  ['Fold1_train', 'Fold2_train', 'Fold3_train', 'Fold4_train', 'Fold5_train']\n",
      "\n",
      "Test fold names:  ['Fold1_test', 'Fold2_test', 'Fold3_test', 'Fold4_test', 'Fold5_test']\n",
      "* No team overlap *\n",
      "* No team overlap *\n",
      "Number of iterations:  2\n",
      "\n",
      " Fold1_test\n",
      "[1059 1035 1080 1086 1044 1039 1050 1038 1037 2036 2049 2039 1020 2035\n",
      " 2046 2027 1010 1078 1051]\n",
      "Num groups:  19\n",
      "\n",
      " Fold1_train\n",
      "[2054, 1051, 2029, 1047, 2071, 2046, 1069, 2016, 2070, 2014, 2015, 1035, 2044, 1098, 2018, 2037, 1077, 1039, 2048, 2034, 10104, 1045, 1040, 1046, 1062, 2039, 1096, 2052, 2036, 2033, 1052, 1086, 2069, 1010, 2063, 2062, 10103, 1041, 2068, 2066, 1059, 1061, 1070, 2057, 1054, 1076, 1099, 2056, 2038, 2019, 1078, 1034, 2045, 1075, 1043, 2035, 1067, 1037, 2049, 1071, 1042, 2030, 1056, 2043, 1084, 2020, 1074, 1093, 2027, 2031, 1068, 1020, 1097, 1090]\n",
      "Num groups:  74\n",
      "\n",
      " Fold2_test\n",
      "[ 1090  2063  1036 10104  1097  2052  2071  1046  2031  2069  2048  2030\n",
      "  1069  2066  1096  2054  1056  2034  1099]\n",
      "Num groups:  19\n",
      "\n",
      " Fold2_train\n",
      "[1032, 1025, 10102, 1089, 1044, 1036, 2053, 1083, 1087, 1038, 1080, 2040, 2060, 1060, 10100, 1072, 1050, 1024, 1091, 2034, 10104, 1045, 1040, 1046, 1062, 2039, 1096, 2052, 2036, 2033, 1052, 1086, 2069, 1010, 2063, 2062, 10103, 1041, 2068, 2066, 1059, 1061, 1070, 2057, 1054, 1076, 1099, 2056, 2038, 2019, 1078, 1034, 2045, 1075, 1043, 2035, 1067, 1037, 2049, 1071, 1042, 2030, 1056, 2043, 1084, 2020, 1074, 1093, 2027, 2031, 1068, 1020, 1097, 1090]\n",
      "Num groups:  74\n",
      "\n",
      " Fold3_test\n",
      "[1068 2029 1083 1071 2045 2040 2053 1040 1067 2043 2038 1091 1043 1074\n",
      " 1076 1062 1041 1047 1070]\n",
      "Num groups:  19\n",
      "\n",
      " Fold3_train\n",
      "[1032, 1025, 10102, 1089, 1044, 1036, 2053, 1083, 1087, 1038, 1080, 2040, 2060, 1060, 10100, 1072, 1050, 1024, 1091, 2054, 1051, 2029, 1047, 2071, 2046, 1069, 2016, 2070, 2014, 2015, 1035, 2044, 1098, 2018, 2037, 1077, 1039, 2048, 2068, 2066, 1059, 1061, 1070, 2057, 1054, 1076, 1099, 2056, 2038, 2019, 1078, 1034, 2045, 1075, 1043, 2035, 1067, 1037, 2049, 1071, 1042, 2030, 1056, 2043, 1084, 2020, 1074, 1093, 2027, 2031, 1068, 1020, 1097, 1090]\n",
      "Num groups:  74\n",
      "\n",
      " Fold4_test\n",
      "[ 1077  2044  2014  2056 10100  2018  2019  2062  2070  2020  1025  1034\n",
      " 10102  1042  1045  1060  2015  2037]\n",
      "Num groups:  18\n",
      "\n",
      " Fold4_train\n",
      "[1032, 1025, 10102, 1089, 1044, 1036, 2053, 1083, 1087, 1038, 1080, 2040, 2060, 1060, 10100, 1072, 1050, 1024, 1091, 2054, 1051, 2029, 1047, 2071, 2046, 1069, 2016, 2070, 2014, 2015, 1035, 2044, 1098, 2018, 2037, 1077, 1039, 2048, 2034, 10104, 1045, 1040, 1046, 1062, 2039, 1096, 2052, 2036, 2033, 1052, 1086, 2069, 1010, 2063, 2062, 10103, 1041, 1067, 1037, 2049, 1071, 1042, 2030, 1056, 2043, 1084, 2020, 1074, 1093, 2027, 2031, 1068, 1020, 1097, 1090]\n",
      "Num groups:  75\n",
      "\n",
      " Fold5_test\n",
      "[ 1093  1032 10103  1052  1089  2057  2060  2016  2033  1084  1061  2068\n",
      "  1054  1072  1098  1087  1075  1024]\n",
      "Num groups:  18\n",
      "\n",
      " Fold5_train\n",
      "[1032, 1025, 10102, 1089, 1044, 1036, 2053, 1083, 1087, 1038, 1080, 2040, 2060, 1060, 10100, 1072, 1050, 1024, 1091, 2054, 1051, 2029, 1047, 2071, 2046, 1069, 2016, 2070, 2014, 2015, 1035, 2044, 1098, 2018, 2037, 1077, 1039, 2048, 2034, 10104, 1045, 1040, 1046, 1062, 2039, 1096, 2052, 2036, 2033, 1052, 1086, 2069, 1010, 2063, 2062, 10103, 1041, 2068, 2066, 1059, 1061, 1070, 2057, 1054, 1076, 1099, 2056, 2038, 2019, 1078, 1034, 2045, 1075, 1043, 2035]\n",
      "Num groups:  75\n",
      "\n",
      " Fold1_test\n",
      "[1059 1035 1080 1086 1044 1039 1050 1038 1037 2036 2049 2039 1020 2035\n",
      " 2046 2027 1010 1078 1051]\n",
      "Num groups:  19\n",
      "\n",
      " Fold1_train\n",
      "[1090, 2063, 1036, 10104, 1097, 2052, 2071, 1046, 2031, 2069, 2048, 2030, 1069, 2066, 1096, 2054, 1056, 2034, 1099, 1068, 2029, 1083, 1071, 2045, 2040, 2053, 1040, 1067, 2043, 2038, 1091, 1043, 1074, 1076, 1062, 1041, 1047, 1070, 1077, 2044, 2014, 2056, 10100, 2018, 2019, 2062, 2070, 2020, 1025, 1034, 10102, 1042, 1045, 1060, 2015, 2037, 1093, 1032, 10103, 1052, 1089, 2057, 2060, 2016, 2033, 1084, 1061, 2068, 1054, 1072, 1098, 1087, 1075, 1024]\n",
      "Num groups:  74\n",
      "\n",
      " Fold2_test\n",
      "[ 1090  2063  1036 10104  1097  2052  2071  1046  2031  2069  2048  2030\n",
      "  1069  2066  1096  2054  1056  2034  1099]\n",
      "Num groups:  19\n",
      "\n",
      " Fold2_train\n",
      "[1059, 1035, 1080, 1086, 1044, 1039, 1050, 1038, 1037, 2036, 2049, 2039, 1020, 2035, 2046, 2027, 1010, 1078, 1051, 1068, 2029, 1083, 1071, 2045, 2040, 2053, 1040, 1067, 2043, 2038, 1091, 1043, 1074, 1076, 1062, 1041, 1047, 1070, 1077, 2044, 2014, 2056, 10100, 2018, 2019, 2062, 2070, 2020, 1025, 1034, 10102, 1042, 1045, 1060, 2015, 2037, 1093, 1032, 10103, 1052, 1089, 2057, 2060, 2016, 2033, 1084, 1061, 2068, 1054, 1072, 1098, 1087, 1075, 1024]\n",
      "Num groups:  74\n",
      "\n",
      " Fold3_test\n",
      "[1068 2029 1083 1071 2045 2040 2053 1040 1067 2043 2038 1091 1043 1074\n",
      " 1076 1062 1041 1047 1070]\n",
      "Num groups:  19\n",
      "\n",
      " Fold3_train\n",
      "[1059, 1035, 1080, 1086, 1044, 1039, 1050, 1038, 1037, 2036, 2049, 2039, 1020, 2035, 2046, 2027, 1010, 1078, 1051, 1090, 2063, 1036, 10104, 1097, 2052, 2071, 1046, 2031, 2069, 2048, 2030, 1069, 2066, 1096, 2054, 1056, 2034, 1099, 1077, 2044, 2014, 2056, 10100, 2018, 2019, 2062, 2070, 2020, 1025, 1034, 10102, 1042, 1045, 1060, 2015, 2037, 1093, 1032, 10103, 1052, 1089, 2057, 2060, 2016, 2033, 1084, 1061, 2068, 1054, 1072, 1098, 1087, 1075, 1024]\n",
      "Num groups:  74\n",
      "\n",
      " Fold4_test\n",
      "[ 1077  2044  2014  2056 10100  2018  2019  2062  2070  2020  1025  1034\n",
      " 10102  1042  1045  1060  2015  2037]\n",
      "Num groups:  18\n",
      "\n",
      " Fold4_train\n",
      "[1059, 1035, 1080, 1086, 1044, 1039, 1050, 1038, 1037, 2036, 2049, 2039, 1020, 2035, 2046, 2027, 1010, 1078, 1051, 1090, 2063, 1036, 10104, 1097, 2052, 2071, 1046, 2031, 2069, 2048, 2030, 1069, 2066, 1096, 2054, 1056, 2034, 1099, 1068, 2029, 1083, 1071, 2045, 2040, 2053, 1040, 1067, 2043, 2038, 1091, 1043, 1074, 1076, 1062, 1041, 1047, 1070, 1093, 1032, 10103, 1052, 1089, 2057, 2060, 2016, 2033, 1084, 1061, 2068, 1054, 1072, 1098, 1087, 1075, 1024]\n",
      "Num groups:  75\n",
      "\n",
      " Fold5_test\n",
      "[ 1093  1032 10103  1052  1089  2057  2060  2016  2033  1084  1061  2068\n",
      "  1054  1072  1098  1087  1075  1024]\n",
      "Num groups:  18\n",
      "\n",
      " Fold5_train\n",
      "[1059, 1035, 1080, 1086, 1044, 1039, 1050, 1038, 1037, 2036, 2049, 2039, 1020, 2035, 2046, 2027, 1010, 1078, 1051, 1090, 2063, 1036, 10104, 1097, 2052, 2071, 1046, 2031, 2069, 2048, 2030, 1069, 2066, 1096, 2054, 1056, 2034, 1099, 1068, 2029, 1083, 1071, 2045, 2040, 2053, 1040, 1067, 2043, 2038, 1091, 1043, 1074, 1076, 1062, 1041, 1047, 1070, 1077, 2044, 2014, 2056, 10100, 2018, 2019, 2062, 2070, 2020, 1025, 1034, 10102, 1042, 1045, 1060, 2015, 2037]\n",
      "Num groups:  75\n"
     ]
    }
   ],
   "source": [
    "# Define fold names\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "set_type = \"test\"\n",
    "for i in range(1,num_folds+1): \n",
    "    col_name = \"Fold\" + str(i) + \"_\" + set_type\n",
    "    test_folds.append(col_name)\n",
    "    set_type = \"train\"  \n",
    "    col_name = \"Fold\" + str(i) + \"_\" + set_type\n",
    "    train_folds.append(col_name)\n",
    "    set_type = \"test\"\n",
    "\n",
    "print(\"Train fold names: \", train_folds)\n",
    "print(\"\\nTest fold names: \",test_folds)\n",
    "\n",
    "\n",
    "folds_dict_list = []\n",
    "\n",
    "# Split teams into 5 groups\n",
    "teams = pd.unique(dfMeasures.GROUPID)\n",
    "\n",
    "for j in range(num_iters):\n",
    "    random.Random(j).shuffle(teams)\n",
    "    groups = np.array_split(teams, 5)\n",
    "    \n",
    "    # Define groups for each fold\n",
    "    fold_groups = {}\n",
    "    for i, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
    "        # make the current group the test group\n",
    "        fold_groups[test_fold] = groups[i]\n",
    "        # make all other groups the train group\n",
    "        train_group = groups[:i] + groups[i+1:]\n",
    "        train_group = [team for group in train_group for team in group]\n",
    "        fold_groups[train_fold] = train_group\n",
    "        \n",
    "    ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
    "    for i in range(1,num_folds+1):\n",
    "        assert set(fold_groups['Fold'+str(i)+'_test']).isdisjoint(set(fold_groups['Fold'+str(i)+'_train'])), \"There is overlap in train and test set \" + str(i)\n",
    "    \n",
    "    print(\"* No team overlap *\")\n",
    "    \n",
    "    # Add fold groups to dictionary\n",
    "    folds_dict_list.append(fold_groups)\n",
    "\n",
    "# Informational\n",
    "print(\"Number of iterations: \", len(folds_dict_list))\n",
    "# for fold_groups in folds_dict_list:\n",
    "#     for key in fold_groups:\n",
    "#         print(\"\\n\", key)\n",
    "#         print(fold_groups[key])\n",
    "#         print(\"Num groups: \", len(fold_groups[key]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bed641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['REC', 'DET', 'ADL', 'MDL', 'DENTR', 'LAM', 'AVL', 'MVL', 'VENTR']\n",
    "\n",
    "def get_group_data(dfData, dfLabels, GROUPID_list, features_list, label_name):\n",
    "    data_to_labels = pd.merge(dfData, dfLabels, on=['GROUPID', 'block'], how='inner') \n",
    "    \n",
    "    dfGroupsData = pd.DataFrame()    \n",
    "    for GROUPID in GROUPID_list:\n",
    "        dfGroupsData = pd.concat([dfGroupsData, data_to_labels.loc[:, dfData['GROUPID'] == GROUPID]], ignore_index=True)\n",
    "        \n",
    "    data = dfGroupsData.loc[:, features_list]  \n",
    "    labels = dfGroupsData.loc[:, label_name]\n",
    "    return [data, labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd208c3d",
   "metadata": {},
   "source": [
    "# Predict Task Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store AUROCS for all iterations\n",
    "aurocs = []\n",
    "# all_test_indices_task_score = [[] for i in range(num_iters)]\n",
    "all_y_test_task_score = [[] for i in range(num_iters)]\n",
    "predictions_task_score = [] for i in range(num_iters)]\n",
    "predict_proba_task_score = [[] for i in range(num_iters)]\n",
    "\n",
    "# Store feature importances and std dev for all iterations\n",
    "impurity_importances_task_score = pd.DataFrame(columns=features)\n",
    "importances_std_task_score = pd.DataFrame(columns=features)\n",
    "\n",
    "# For storing shap values across all folds\n",
    "task_score_shap_values_0 = None\n",
    "task_score_shap_values_1 = None\n",
    "task_score_full_X_test = pd.DataFrame()\n",
    "\n",
    "#-----------------------------------------------#\n",
    "#      5-fold team level cross-validation       #\n",
    "#-----------------------------------------------#\n",
    "\n",
    "# For each iteration \n",
    "for i in range(num_iters):\n",
    "    print(\"Iteration: \", i+1)\n",
    "    \n",
    "    # Lists for cumulative test set and predictions for iteration\n",
    "#     all_test_indices = []\n",
    "    all_y_test = []\n",
    "    predictions = []\n",
    "    predict_proba = []\n",
    "    \n",
    "    # Create RandomForestClassifier for task_score prediction\n",
    "    rfc_task_score = RandomForestClassifier(n_estimators=100, random_state=1, \\\n",
    "                                            max_features='sqrt', class_weight='balanced') \n",
    "    \n",
    "    # Get fold groups\n",
    "    fold_groups = folds_dict_list[i]\n",
    "    \n",
    "    # For each fold\n",
    "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
    "        # Get data for teams in test set\n",
    "        test_data_list = get_group_data(dfData, dfLabels, fold_groups[test_fold], features, 'task_score')\n",
    "        X_test = test_data_list[0]\n",
    "        y_test = test_data_list[1]\n",
    "        all_y_test.extend(y_test.tolist())\n",
    "        \n",
    "        print(\"X_test shape: \", X_test.shape)\n",
    "        display(X_test.head())\n",
    "        print(\"y_test shape: \", y_test.shape)\n",
    "        display(y_test.head())\n",
    "\n",
    "\n",
    "        # Get data for teams in train set\n",
    "        train_data_list = get_group_data(dfData, dfLabels, fold_groups[train_fold], features, 'task_score')\n",
    "        X_train = train_data_list[0]\n",
    "        y_train = train_data_list[1]\n",
    "        \n",
    "        print(\"X_train shape: \", X_train.shape)\n",
    "        display(X_train.head())\n",
    "        print(\"y_train shape: \", y_train.shape)\n",
    "        display(y_train.head())\n",
    "\n",
    "\n",
    "        # Train model\n",
    "        rfc_task_score.fit(X_train, y_train)\n",
    "\n",
    "        # Test model\n",
    "        y_pred = rfc_task_score.predict(X_test)\n",
    "        predictions.extend(y_pred.tolist())\n",
    "\n",
    "        y_pp = rfc_task_score.predict_proba(X_test)[:, 1]\n",
    "        predict_proba.extend(y_pp.tolist())\n",
    "        \n",
    "        ## Get SHAP values\n",
    "        explainer = shap.TreeExplainer(rfc_task_score)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        if j==0:\n",
    "            COMM_shap_values_0 = shap_values[0]\n",
    "            COMM_shap_values_1 = shap_values[1]\n",
    "        else:\n",
    "            task_score_shap_values_0 = np.vstack([task_score_shap_values_0, shap_values[0]])\n",
    "            task_score_shap_values_1 = np.vstack([task_score_shap_values_1, shap_values[1]])\n",
    "            \n",
    "        task_score_full_X_test = pd.concat([task_score_full_X_test, X_test], ignore_index=True)\n",
    "        ## End of get SHAP values\n",
    "        \n",
    "    \n",
    "    # Get AUROC of iteration\n",
    "    auroc = roc_auc_score(all_y_test, predict_proba)\n",
    "    aurocs.append(auroc)\n",
    "    print(\"AUROC: \", auroc)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Save iteration task score truth labels, and predictions for micro auroc\n",
    "#     all_test_indices_COMM[i] = all_test_indices\n",
    "    all_y_test_task_score[i] = all_y_test\n",
    "    predictions_task_score[i] = predictions\n",
    "    predict_proba_task_score[i] = predict_proba\n",
    "    \n",
    "    #-----------------------------------------------#\n",
    "    #   Compute Feature Importances for iteration   #\n",
    "    #-----------------------------------------------#\n",
    "    # Impurity-based importances\n",
    "    importances = rfc_task_score.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rfc_task_score.estimators_], axis=0)\n",
    "    imps = pd.Series(importances, index=features)\n",
    "    stds = pd.Series(std, index=features)\n",
    "    impurity_importances_task_score = pd.concat([impurity_importances_task_score, imps], ignore_index=True)\n",
    "    importances_std_task_score = pd.concat([importances_std_task_score, stds], ignore_index=True)\n",
    "    \n",
    "#     # Plot feature importances\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     imps.plot.bar(yerr=std, ax=ax1)\n",
    "#     ax1.set_title(\"Task Score Feature importances using MDI\")\n",
    "#     ax1.set_ylabel(\"Mean decrease in impurity\")\n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "# Get mean AUROC over all iterations\n",
    "avg_auroc = np.mean(aurocs)\n",
    "print(\"Mean AUROC over %d iterations: %f\" % (i+1, avg_auroc))\n",
    "\n",
    "# Get median AUROC over all iterations\n",
    "med_auroc = np.median(aurocs)\n",
    "task_score_med_auroc_idx = np.argsort(aurocs)[len(aurocs)//2]\n",
    "print(\"Median AUROC over %d iterations: %f\" % (i+1, med_auroc))\n",
    "print(\"Median iteration number: \", task_score_med_auroc_idx+1)\n",
    "print(\"All AUROCS: \", aurocs)\n",
    "\n",
    "# Save median iteration labels and predictions\n",
    "med_y_test_task_score = all_y_test_task_score[task_score_med_auroc_idx]\n",
    "med_predictions_task_score = predictions_task_score[task_score_med_auroc_idx]\n",
    "med_predict_proba_task_score = predict_proba_task_score[task_score_med_auroc_idx]\n",
    "# med_test_indices_COMM = all_test_indices_COMM[COMM_med_auroc_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d3ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
