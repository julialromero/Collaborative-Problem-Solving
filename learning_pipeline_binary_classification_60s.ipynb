{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning_pipeline_binary_classification_60s.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP26wUt7iJnPFBH45/+NgKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julialromero/Collaborative-Problem-Solving/blob/main/learning_pipeline_binary_classification_60s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAxyTSiXLEOw",
        "outputId": "f6cf8a30-3029-487c-90cd-4c236680f65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "0ClMuiLpRLDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import os\n",
        "from skimage import io\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from keras import layers, Input, Model, optimizers\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "PROJECT_DIR = \"drive/MyDrive/CSCI 5922 - Final Project/\"  #<--- Make a shortcut for the \"CSCI 5922 - Final Project\" shared folder on your Google Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJh0Y08BQjFy",
        "outputId": "6bd77382-3563-46b6-be52-ee592ba4fbbd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  1 17:56:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                  N/A |\n",
            "| N/A   37C    P0    34W / 250W |    389MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get User Input"
      ],
      "metadata": {
        "id": "W7PXpsytRPbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose what size images to use\n",
        "PROJECT_DIR = \"drive/MyDrive/CSCI 5922 - Final Project/\"  #<--- Make a shortcut for the \"CSCI 5922 - Final Project\" shared folder on your Google Drive\n",
        "## \"small\" = 98x98, \"med\" = 266x266, \"large\" = 332x332\n",
        "image_size = \"small\"\n",
        "shuffled = False\n",
        "chance = False\n",
        "normalize = False\n",
        "scaled = False\n",
        "num_iters = 1\n",
        "num_folds = 10\n",
        "threshold = 0.5\n",
        "num_epochs = 50\n",
        "\n",
        "if image_size == \"large\":\n",
        "  imgsize = (332, 332)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"332x332 - Levels Recurrence Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"332x332 - Levels Recurrence Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"med\":\n",
        "  imgsize = (266, 266)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"332x332 - Levels Recurrence Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"332x332 - Levels Recurrence Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"small\":\n",
        "  imgsize = (98, 98)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"98x98 - Levels Recurrence Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"98x98 - Levels Recurrence Matrices/RAW/\"\n",
        "\n",
        "print(\"Processing images from: \", IMG_DIR)"
      ],
      "metadata": {
        "id": "v5BvT9jfQ_Je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d44748-d2d9-4ab9-8d2e-e760f2e86d59"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing images from:  98x98 - Levels Recurrence Matrices/RAW/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "C-Xr5-J_SEwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    read, preprocess, and scale images to uniform dimension\n",
        "'''\n",
        "def extract_image(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) \n",
        "\n",
        "    return x\n",
        "\n",
        "'''\n",
        "    Converts grayscale image to 3 channels in order to fit Inception v3 model\n",
        "'''\n",
        "def extract_image_inceptionv3(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) \n",
        "    x = np.squeeze(np.stack((x,)*3))\n",
        "    x = x.swapaxes(0,1)\n",
        "    x = x.swapaxes(1,2)\n",
        "\n",
        "    return x\n",
        "\n",
        "def extract_level_score(filename, outcome_df, score_col=\"won\", shuffled=False):\n",
        "    #  match this file's id/block with task score and return\n",
        "    if shuffled:\n",
        "      GROUPID, UniqueID, NA = filename.split(\"_\")\n",
        "    else:\n",
        "      s, NA = filename.split(\".png\")\n",
        "      GROUPID, UniqueID = s.split(\"_\")\n",
        "\n",
        "    row = outcome_df.loc[(outcome_df.UniqueID == UniqueID)]\n",
        "\n",
        "    if(row.shape[0] != 1):\n",
        "        print(f\"Error -- Number of level scores recorded is not 1 for {UniqueID}\")\n",
        "        return np.nan\n",
        "    score = row[score_col].values[0]\n",
        "    return score\n",
        "\n",
        "\n",
        "def get_levels_fold_data(GROUPID_list, outcome_df, score_col, incv3=False, verbose=False):\n",
        "  # read data to np arrays\n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = []\n",
        "  else:\n",
        "    recurrence_plot_list = []\n",
        "  \n",
        "  levels_labels = []\n",
        "\n",
        "  for filename in os.listdir(PROJECT_DIR + IMG_DIR):\n",
        "      # print(\"filename: \", filename)\n",
        "\n",
        "      # Check if file belongs to one of the teams in the desired group\n",
        "      for GROUPID in GROUPID_list:\n",
        "        if str(GROUPID) == filename.split(\"_\")[0]:\n",
        "          # preprocess image\n",
        "          if incv3:\n",
        "            t_incv3 = extract_image_inceptionv3(PROJECT_DIR + IMG_DIR + filename)\n",
        "          else:\n",
        "            t = extract_image(PROJECT_DIR + IMG_DIR + filename)\n",
        "\n",
        "          # get level score\n",
        "          lab = extract_level_score(filename, outcome_df=outcome_df, score_col=score_col, shuffled=shuffled)\n",
        "\n",
        "          # append data \n",
        "          if incv3:\n",
        "            recurrence_plot_list_incv3.append(t_incv3)\n",
        "          else:\n",
        "            recurrence_plot_list.append(t)\n",
        "          \n",
        "          levels_labels.append(lab)\n",
        "\n",
        "  # convert to arrays \n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = np.array(recurrence_plot_list_incv3)\n",
        "    plot_list = recurrence_plot_list_incv3\n",
        "  else:\n",
        "    recurrence_plot_list = np.array(recurrence_plot_list)\n",
        "    plot_list = recurrence_plot_list\n",
        "  \n",
        "  labels = np.array(levels_labels)\n",
        "\n",
        "  if verbose:\n",
        "    print(\"\\nFOLD DATA INFO: \")\n",
        "    if incv3:\n",
        "      print(f\"\\trecurrence_plot_list_incv3: {recurrence_plot_list_incv3.shape}\")\n",
        "    else:\n",
        "      print(f\"\\trecurrence_plot_list: {recurrence_plot_list.shape}\")\n",
        "    \n",
        "    binary_counts = dict(Counter(labels))\n",
        "    print(\"\\tBinary label counts: \", binary_counts)\n",
        "\n",
        "  return [plot_list, labels]\n",
        "\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None,\n",
        "                          save_fn=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    if save_fn:\n",
        "      plt.savefig(save_fn + \".svg\", dpi=300, format=\"svg\")\n",
        "      plt.savefig(save_fn + \".png\", dpi=300, format=\"png\")"
      ],
      "metadata": {
        "id": "v6ebXR_uSCDN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Outcomes"
      ],
      "metadata": {
        "id": "GqAdOICCTs9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_df = pd.read_csv(PROJECT_DIR + \"Level_Attempts_60s.csv\")\n",
        "\n",
        "outcome_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "SnBccskmTny8",
        "outputId": "209d9072-eea8-4cfc-a78d-4ba6df4b8d2b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             UniqueID school           team      block  \\\n",
              "0     CPS2-ASU-T100-ExpBlock1-49.9049    ASU  CPS2-ASU-T100  ExpBlock1   \n",
              "1    CPS2-ASU-T100-ExpBlock2-155.1167    ASU  CPS2-ASU-T100  ExpBlock2   \n",
              "2     CPS2-ASU-T100-ExpBlock2-19.7534    ASU  CPS2-ASU-T100  ExpBlock2   \n",
              "3    CPS2-ASU-T100-ExpBlock2-419.7154    ASU  CPS2-ASU-T100  ExpBlock2   \n",
              "4    CPS2-ASU-T100-ExpBlock2-506.7689    ASU  CPS2-ASU-T100  ExpBlock2   \n",
              "..                                ...    ...            ...        ...   \n",
              "760    CPS2-CU-T71-ExpBlock2-768.7043     CU    CPS2-CU-T71  ExpBlock2   \n",
              "761       CPS2-CU-T71-Warmup-324.6296     CU    CPS2-CU-T71     Warmup   \n",
              "762       CPS2-CU-T71-Warmup-454.0428     CU    CPS2-CU-T71     Warmup   \n",
              "763       CPS2-CU-T71-Warmup-627.1388     CU    CPS2-CU-T71     Warmup   \n",
              "764        CPS2-CU-T71-Warmup-83.7726     CU    CPS2-CU-T71     Warmup   \n",
              "\n",
              "                    level  relative_start_time  relative_end_time  \\\n",
              "0                Top spin              49.9049           899.9790   \n",
              "1    Timing is Everything             155.1167           413.1691   \n",
              "2                   Scale              19.7534           144.8036   \n",
              "3             Green Apple             419.7154           496.1897   \n",
              "4                     Fe2             506.7689           900.0460   \n",
              "..                    ...                  ...                ...   \n",
              "760  Timing is Everything             768.7043           900.0360   \n",
              "761               Yippie!             324.6296           447.6709   \n",
              "762            Spider Web             454.0428           618.0744   \n",
              "763        Annoying Lever             627.1388           900.0090   \n",
              "764            Can Opener              83.7726           324.6296   \n",
              "\n",
              "     60_sec_start_time  60_sec_end_time  level_duration  gold_trophy  \\\n",
              "0                  840              899        850.0741            0   \n",
              "1                  344              403        258.0524            0   \n",
              "2                   75              134        125.0502            0   \n",
              "3                  427              486         76.4743            0   \n",
              "4                  840              899        393.2771            0   \n",
              "..                 ...              ...             ...          ...   \n",
              "760                840              899        131.3317            0   \n",
              "761                378              437        123.0413            0   \n",
              "762                549              608        164.0316            0   \n",
              "763                840              899        272.8702            0   \n",
              "764                255              314        240.8570            0   \n",
              "\n",
              "     silver_trophy  won  GROUPID  \n",
              "0                0    0    10100  \n",
              "1                1    1    10100  \n",
              "2                1    1    10100  \n",
              "3                1    1    10100  \n",
              "4                0    0    10100  \n",
              "..             ...  ...      ...  \n",
              "760              0    0     2071  \n",
              "761              1    1     2071  \n",
              "762              1    1     2071  \n",
              "763              0    0     2071  \n",
              "764              0    0     2071  \n",
              "\n",
              "[765 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-127c69b3-30c9-4339-8d28-607a5c31df08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UniqueID</th>\n",
              "      <th>school</th>\n",
              "      <th>team</th>\n",
              "      <th>block</th>\n",
              "      <th>level</th>\n",
              "      <th>relative_start_time</th>\n",
              "      <th>relative_end_time</th>\n",
              "      <th>60_sec_start_time</th>\n",
              "      <th>60_sec_end_time</th>\n",
              "      <th>level_duration</th>\n",
              "      <th>gold_trophy</th>\n",
              "      <th>silver_trophy</th>\n",
              "      <th>won</th>\n",
              "      <th>GROUPID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CPS2-ASU-T100-ExpBlock1-49.9049</td>\n",
              "      <td>ASU</td>\n",
              "      <td>CPS2-ASU-T100</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>Top spin</td>\n",
              "      <td>49.9049</td>\n",
              "      <td>899.9790</td>\n",
              "      <td>840</td>\n",
              "      <td>899</td>\n",
              "      <td>850.0741</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CPS2-ASU-T100-ExpBlock2-155.1167</td>\n",
              "      <td>ASU</td>\n",
              "      <td>CPS2-ASU-T100</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>Timing is Everything</td>\n",
              "      <td>155.1167</td>\n",
              "      <td>413.1691</td>\n",
              "      <td>344</td>\n",
              "      <td>403</td>\n",
              "      <td>258.0524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CPS2-ASU-T100-ExpBlock2-19.7534</td>\n",
              "      <td>ASU</td>\n",
              "      <td>CPS2-ASU-T100</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>Scale</td>\n",
              "      <td>19.7534</td>\n",
              "      <td>144.8036</td>\n",
              "      <td>75</td>\n",
              "      <td>134</td>\n",
              "      <td>125.0502</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CPS2-ASU-T100-ExpBlock2-419.7154</td>\n",
              "      <td>ASU</td>\n",
              "      <td>CPS2-ASU-T100</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>Green Apple</td>\n",
              "      <td>419.7154</td>\n",
              "      <td>496.1897</td>\n",
              "      <td>427</td>\n",
              "      <td>486</td>\n",
              "      <td>76.4743</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CPS2-ASU-T100-ExpBlock2-506.7689</td>\n",
              "      <td>ASU</td>\n",
              "      <td>CPS2-ASU-T100</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>Fe2</td>\n",
              "      <td>506.7689</td>\n",
              "      <td>900.0460</td>\n",
              "      <td>840</td>\n",
              "      <td>899</td>\n",
              "      <td>393.2771</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>CPS2-CU-T71-ExpBlock2-768.7043</td>\n",
              "      <td>CU</td>\n",
              "      <td>CPS2-CU-T71</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>Timing is Everything</td>\n",
              "      <td>768.7043</td>\n",
              "      <td>900.0360</td>\n",
              "      <td>840</td>\n",
              "      <td>899</td>\n",
              "      <td>131.3317</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>CPS2-CU-T71-Warmup-324.6296</td>\n",
              "      <td>CU</td>\n",
              "      <td>CPS2-CU-T71</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>Yippie!</td>\n",
              "      <td>324.6296</td>\n",
              "      <td>447.6709</td>\n",
              "      <td>378</td>\n",
              "      <td>437</td>\n",
              "      <td>123.0413</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>CPS2-CU-T71-Warmup-454.0428</td>\n",
              "      <td>CU</td>\n",
              "      <td>CPS2-CU-T71</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>Spider Web</td>\n",
              "      <td>454.0428</td>\n",
              "      <td>618.0744</td>\n",
              "      <td>549</td>\n",
              "      <td>608</td>\n",
              "      <td>164.0316</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>CPS2-CU-T71-Warmup-627.1388</td>\n",
              "      <td>CU</td>\n",
              "      <td>CPS2-CU-T71</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>Annoying Lever</td>\n",
              "      <td>627.1388</td>\n",
              "      <td>900.0090</td>\n",
              "      <td>840</td>\n",
              "      <td>899</td>\n",
              "      <td>272.8702</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>CPS2-CU-T71-Warmup-83.7726</td>\n",
              "      <td>CU</td>\n",
              "      <td>CPS2-CU-T71</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>Can Opener</td>\n",
              "      <td>83.7726</td>\n",
              "      <td>324.6296</td>\n",
              "      <td>255</td>\n",
              "      <td>314</td>\n",
              "      <td>240.8570</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>765 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-127c69b3-30c9-4339-8d28-607a5c31df08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-127c69b3-30c9-4339-8d28-607a5c31df08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-127c69b3-30c9-4339-8d28-607a5c31df08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification w/ Team-level Cross Validation"
      ],
      "metadata": {
        "id": "h_nBbMlEUxsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep folds for team-level cross validation"
      ],
      "metadata": {
        "id": "sHG214qtWUtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fold names\n",
        "train_folds = []\n",
        "test_folds = []\n",
        "set_type = \"test\"\n",
        "for j in range(1,num_folds+1): \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    test_folds.append(col_name)\n",
        "    set_type = \"train\"  \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    train_folds.append(col_name)\n",
        "    set_type = \"test\"\n",
        "\n",
        "folds_dict_list = []\n",
        "\n",
        "teams = pd.unique(outcome_df.GROUPID)\n",
        "\n",
        "# For every iteration\n",
        "for i in range(1,num_iters+1):\n",
        "    print(\"Iteration: \", i)\n",
        "    teams = shuffle(teams, random_state=i)\n",
        "    groups = np.array_split(teams, num_folds)\n",
        "    \n",
        "    # Define groups for each fold\n",
        "    fold_groups = {}\n",
        "    for j, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
        "        # make the current group the test group\n",
        "        fold_groups[test_fold] = groups[j]\n",
        "        # make all other groups the train group\n",
        "        train_group = groups[:j] + groups[j+1:]\n",
        "        train_group = [team for group in train_group for team in group]\n",
        "        fold_groups[train_fold] = train_group\n",
        "        \n",
        "    ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(fold_groups['Fold'+str(j)+'_test']).isdisjoint(set(fold_groups['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "    print(\"* No team overlap *\")\n",
        "\n",
        "      \n",
        "    # Add fold groups to dictionary\n",
        "    folds_dict_list.append(fold_groups)\n",
        "    \n",
        "\n",
        "# Informational\n",
        "print(\"\\nNumber of iterations: \", len(folds_dict_list))\n",
        "\n",
        "print(\"\\nIterating through folds_dict_list to check for overlap...\")\n",
        "for i,dicti in enumerate(folds_dict_list):\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(dicti['Fold'+str(j)+'_test']).isdisjoint(set(dicti['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "print(\"* No team overlap *\")  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCR7OUDzU0Yn",
        "outputId": "cde365ad-7a56-4fda-ed93-5815fe5379bc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "* No team overlap *\n",
            "\n",
            "Number of iterations:  1\n",
            "\n",
            "Iterating through folds_dict_list to check for overlap...\n",
            "* No team overlap *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Garcia Model"
      ],
      "metadata": {
        "id": "RUuUgtOcaM-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_garcia_model():\n",
        "  # Garcia-Ceja paper feeds CNN images with dims 100 x 100 x 4 (width x height x channels)\n",
        "  # Labels are one hot encoded\n",
        "  inputs = Input(shape=(imgsize[0], imgsize[1], 1))\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(inputs)\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Dense(512, activation=\"relu\")(x) \n",
        "  x = layers.Dropout(0.50)(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "  out = layers.Dense(1, activation=\"sigmoid\")(x)   # changed output layer to 1 and activation to sigmoid\n",
        "    \n",
        "\n",
        "  bc = tf.keras.losses.BinaryCrossentropy()        # changed loss to binary\n",
        "  lr = 0.00001 # paper used 0.001, our regression used 0.0001\n",
        "  eps = 1e-08  # paper used 1e-08, but keras default is 1e-07\n",
        "  adam = keras.optimizers.Adam(learning_rate=lr, epsilon=eps)\n",
        "  auc = tf.keras.metrics.AUC(\n",
        "        num_thresholds=200,\n",
        "        curve=\"ROC\",\n",
        "        from_logits=False\n",
        "  )\n",
        "  prec = tf.keras.metrics.Precision()\n",
        "  rec = tf.keras.metrics.Recall()\n",
        "\n",
        "\n",
        "  model_garcia = Model(inputs=inputs, outputs=out)\n",
        "  model_garcia.compile(\n",
        "    optimizer=adam,\n",
        "    loss=bc, \n",
        "    metrics=['accuracy', auc, prec, rec]\n",
        "  )\n",
        "\n",
        "  return model_garcia\n",
        "\n",
        "model_garcia = get_binary_garcia_model()\n",
        "model_garcia.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E0Aty4bWlxF",
        "outputId": "82e9279b-ec4f-4a88-c207-5fbcf8800a39"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_150\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_151 (InputLayer)      [(None, 98, 98, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_600 (Conv2D)         (None, 96, 96, 16)        160       \n",
            "                                                                 \n",
            " conv2d_601 (Conv2D)         (None, 94, 94, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_300 (MaxPooli  (None, 47, 47, 16)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_450 (Dropout)       (None, 47, 47, 16)        0         \n",
            "                                                                 \n",
            " conv2d_602 (Conv2D)         (None, 45, 45, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_603 (Conv2D)         (None, 43, 43, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_301 (MaxPooli  (None, 21, 21, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_451 (Dropout)       (None, 21, 21, 32)        0         \n",
            "                                                                 \n",
            " dense_300 (Dense)           (None, 21, 21, 512)       16896     \n",
            "                                                                 \n",
            " dropout_452 (Dropout)       (None, 21, 21, 512)       0         \n",
            "                                                                 \n",
            " flatten_150 (Flatten)       (None, 225792)            0         \n",
            "                                                                 \n",
            " dense_301 (Dense)           (None, 1)                 225793    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 259,057\n",
            "Trainable params: 259,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Garcia - Run team-level cross validation"
      ],
      "metadata": {
        "id": "kF4QypdEa9bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store metrics for all iterations\n",
        "aurocs = []\n",
        "precision = []\n",
        "recall = []\n",
        "accuracy = []\n",
        "\n",
        "all_y_test_task_score = [[] for i in range(num_iters)]\n",
        "predictions_task_score = [[] for i in range(num_iters)]\n",
        "predict_proba_task_score = [[] for i in range(num_iters)]\n",
        "\n",
        "\n",
        "# For each iteration \n",
        "for i in range(num_iters):\n",
        "    print(\"Iteration: \", i+1)\n",
        "    \n",
        "    # Lists for cumulative predictions for iteration\n",
        "    all_y_test = []\n",
        "    predictions = []\n",
        "    predict_proba = []\n",
        "    \n",
        "    # Get fold groups\n",
        "    fold_groups = folds_dict_list[i]\n",
        "\n",
        "    # For each fold\n",
        "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
        "        print(\"\\tFold: \", j+1)\n",
        "\n",
        "        # Get data for teams in test set\n",
        "        [plot_list, labels] = get_levels_fold_data(fold_groups[test_fold], outcome_df=outcome_df, score_col=\"won\", incv3=False)\n",
        "        X_test = plot_list\n",
        "        y_test = labels\n",
        "        all_y_test.extend(y_test.tolist())\n",
        "\n",
        "        # Get data for teams in train set\n",
        "        [plot_list, labels] = get_levels_fold_data(fold_groups[train_fold], outcome_df=outcome_df, score_col=\"won\", incv3=False)\n",
        "        X_train = plot_list\n",
        "        y_train = labels\n",
        "\n",
        "        # Train model\n",
        "        model_garcia = get_binary_garcia_model()\n",
        "        info_garcia_cv = model_garcia.fit(x=X_train, y=y_train, epochs=num_epochs, verbose=True)\n",
        "\n",
        "        # Test model: https://androidkt.com/get-class-labels-from-predict-method-in-keras/\n",
        "        y_pp = model_garcia.predict(X_test)\n",
        "        y_pred = np.where(y_pp > threshold, 1, 0)\n",
        "\n",
        "        predict_proba.extend(y_pp.tolist())\n",
        "        predictions.extend(y_pred.tolist())\n",
        "\n",
        "    # ----- END OF FOLDS\n",
        "\n",
        "    all_y_test = np.array(all_y_test)\n",
        "    all_y_test_task_score[i] = all_y_test\n",
        "\n",
        "    predictions = np.squeeze(np.array(predictions))\n",
        "    predict_proba = np.squeeze(np.array(predict_proba))\n",
        "    \n",
        "    predictions_task_score[i] = predictions\n",
        "    predict_proba_task_score[i] = predict_proba\n",
        "\n",
        "    # Get metrics of iteration\n",
        "    auroc = roc_auc_score(all_y_test, predict_proba)\n",
        "    prec = precision_score(all_y_test, predictions)\n",
        "    rec = recall_score(all_y_test, predictions)\n",
        "    acc = accuracy_score(all_y_test, predictions)\n",
        "    \n",
        "    aurocs.append(auroc)\n",
        "    precision.append(prec)\n",
        "    recall.append(rec)\n",
        "    accuracy.append(acc)\n",
        "\n",
        "    # Save actual labels and predictions for iteration\n",
        "    dfTruevPred = pd.DataFrame({'actual': all_y_test, 'predict_proba': predict_proba, 'prediction': predictions})\n",
        "    if shuffled:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/shuffled/\" + image_size + \"/\" + image_size + \"_TaskScore_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\"\n",
        "    else:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/non-shuffled/\" + image_size + \"/\" + image_size + \"_TaskScore_True_vs_Pred_\" + str(i+1) + \".csv\"\n",
        "    dfTruevPred.to_csv(ACTvPRED_SAVE_DIR, index=False) \n",
        "\n",
        "# ----- END OF ITERATIONS\n",
        "\n",
        "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
        "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], 'accuracy': accuracy, \\\n",
        "                          'auroc': aurocs, 'precision': precision, 'recall': recall})\n",
        "\n",
        "display(dfMetrics)\n",
        "\n",
        "if shuffled:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/shuffled/\" + image_size + \"/\" + image_size + \"_TaskScore_Metrics_SHUFF.csv\"\n",
        "else:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/non-shuffled/\" + image_size + \"/\" + image_size + \"_TaskScore_Metrics.csv\"\n",
        "dfMetrics.to_csv(METRICS_SAVE_DIR, index=False) \n",
        "\n",
        "print(\"Averages over all iterations: \")\n",
        "print(\"%12s %.2f\" % (\"AUROC:\", np.mean(dfMetrics['auroc'])))\n",
        "print(\"%12s %.2f\" % (\"Precision:\", np.mean(dfMetrics['precision'])))\n",
        "print(\"%12s %.2f\" % (\"Recall:\", np.mean(dfMetrics['recall'])))\n",
        "print(\"%12s %.2f\" % (\"Accuracy:\", np.mean(dfMetrics['accuracy'])))\n",
        "\n",
        "# Get median iterations\n",
        "med_auroc = np.median(aurocs)\n",
        "med_auroc_idx = np.argsort(aurocs)[len(aurocs)//2]\n",
        "med_iter_num = med_auroc_idx+1\n",
        "med_data = data = [[med_iter_num, med_auroc]]\n",
        "dfMedian = pd.DataFrame(med_data, columns=['med_iter_num', 'med_auroc'])\n",
        "\n",
        "if shuffled:\n",
        "  MEDIAN_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/shuffled/\" + image_size + \"/\" + image_size + \"_Median_SHUFF.csv\"\n",
        "else:\n",
        "  MEDIAN_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/non-shuffled/\" + image_size + \"/\" + image_size + \"_Median.csv\"\n",
        "dfMedian.to_csv(MEDIAN_SAVE_DIR, index=False) \n",
        "\n",
        "print(\"\\nMedian iteration number: \", med_iter_num)\n",
        "print(\"\\n%6s %.2f\" % (\"Median AUROC:\", np.median(dfMetrics['auroc'])))\n",
        "\n",
        "# Plot confusion matrix of median iteration\n",
        "if shuffled:\n",
        "  CM_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/shuffled/\" + image_size + \"/\" + image_size + \"_CM_SHUFF\"\n",
        "else:\n",
        "  CM_SAVE_DIR = PROJECT_DIR + \"level_attempt_results/Garcia_model/non-shuffled/\" + image_size + \"/\" + image_size + \"_CM\"\n",
        "\n",
        "cf_matrix = confusion_matrix(all_y_test_task_score[med_auroc_idx], predictions_task_score[med_auroc_idx])\n",
        "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "categories = ['Zero', 'One']\n",
        "make_confusion_matrix(cf_matrix, \n",
        "                      group_names=labels,\n",
        "                      categories=categories, \n",
        "                      cmap='Blues',\n",
        "                      save_fn = CM_SAVE_DIR)\n",
        "\n"
      ],
      "metadata": {
        "id": "BTGD-JCba4AO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98d88a68-eb8d-4ecf-874d-5597cdfd04fc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "\tFold:  1\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 13ms/step - loss: 0.6944 - accuracy: 0.4837 - auc_151: 0.4631 - precision_151: 0.5017 - recall_151: 0.8575\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6920 - accuracy: 0.5148 - auc_151: 0.5184 - precision_151: 0.5171 - recall_151: 0.9886\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5104 - auc_151: 0.4864 - precision_151: 0.5155 - recall_151: 0.9459\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5207 - auc_151: 0.4888 - precision_151: 0.5209 - recall_151: 0.9601\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5178 - auc_151: 0.5152 - precision_151: 0.5185 - recall_151: 0.9972\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5178 - auc_151: 0.4987 - precision_151: 0.5185 - recall_151: 0.9972\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5089 - auc_151: 0.5010 - precision_151: 0.5150 - recall_151: 0.9316\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5281 - auc_151: 0.5189 - precision_151: 0.5244 - recall_151: 0.9801\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5178 - auc_151: 0.4995 - precision_151: 0.5231 - recall_151: 0.8063\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5251 - auc_151: 0.5021 - precision_151: 0.5268 - recall_151: 0.8405\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6929 - accuracy: 0.5325 - auc_151: 0.4985 - precision_151: 0.5344 - recall_151: 0.7749\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5059 - auc_151: 0.5043 - precision_151: 0.5134 - recall_151: 0.9288\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5222 - auc_151: 0.5027 - precision_151: 0.5208 - recall_151: 1.0000\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5148 - auc_151: 0.5026 - precision_151: 0.5181 - recall_151: 0.9373\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5059 - auc_151: 0.4726 - precision_151: 0.5133 - recall_151: 0.9345\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5222 - auc_151: 0.5207 - precision_151: 0.5220 - recall_151: 0.9459\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5340 - auc_151: 0.5364 - precision_151: 0.5378 - recall_151: 0.7293\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6928 - accuracy: 0.4941 - auc_151: 0.4971 - precision_151: 0.5077 - recall_151: 0.8433\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5148 - auc_151: 0.5009 - precision_151: 0.5188 - recall_151: 0.9060\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.5178 - auc_151: 0.5435 - precision_151: 0.5186 - recall_151: 0.9943\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6918 - accuracy: 0.5222 - auc_151: 0.5238 - precision_151: 0.5208 - recall_151: 0.9972\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5192 - auc_151: 0.5447 - precision_151: 0.5193 - recall_151: 0.9972\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5148 - auc_151: 0.5431 - precision_151: 0.5174 - recall_151: 0.9744\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6911 - accuracy: 0.5207 - auc_151: 0.5502 - precision_151: 0.5200 - recall_151: 1.0000\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5222 - auc_151: 0.5218 - precision_151: 0.5209 - recall_151: 0.9943\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5044 - auc_151: 0.4920 - precision_151: 0.5131 - recall_151: 0.8917\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5192 - auc_151: 0.4983 - precision_151: 0.5193 - recall_151: 0.9943\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.5370 - auc_151: 0.5331 - precision_151: 0.5363 - recall_151: 0.8006\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6905 - accuracy: 0.5547 - auc_151: 0.5510 - precision_151: 0.5413 - recall_151: 0.9345\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.5178 - auc_151: 0.5268 - precision_151: 0.5185 - recall_151: 0.9972\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5163 - auc_151: 0.5110 - precision_151: 0.5178 - recall_151: 0.9943\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5222 - auc_151: 0.5327 - precision_151: 0.5216 - recall_151: 0.9630\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5178 - auc_151: 0.5204 - precision_151: 0.5195 - recall_151: 0.9487\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5222 - auc_151: 0.5249 - precision_151: 0.5208 - recall_151: 0.9972\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5222 - auc_151: 0.5536 - precision_151: 0.5208 - recall_151: 1.0000\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.5192 - auc_151: 0.5187 - precision_151: 0.5192 - recall_151: 1.0000\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5222 - auc_151: 0.5140 - precision_151: 0.5208 - recall_151: 1.0000\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5178 - auc_151: 0.5098 - precision_151: 0.5186 - recall_151: 0.9943\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5163 - auc_151: 0.5326 - precision_151: 0.5185 - recall_151: 0.9573\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5296 - auc_151: 0.5447 - precision_151: 0.5261 - recall_151: 0.9459\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5237 - auc_151: 0.5267 - precision_151: 0.5215 - recall_151: 1.0000\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5237 - auc_151: 0.5648 - precision_151: 0.5222 - recall_151: 0.9715\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5281 - auc_151: 0.5656 - precision_151: 0.5242 - recall_151: 0.9858\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5207 - auc_151: 0.5830 - precision_151: 0.5200 - recall_151: 1.0000\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5207 - auc_151: 0.5770 - precision_151: 0.5201 - recall_151: 0.9972\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5222 - auc_151: 0.5655 - precision_151: 0.5214 - recall_151: 0.9715\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5251 - auc_151: 0.5689 - precision_151: 0.5225 - recall_151: 0.9915\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5325 - auc_151: 0.5559 - precision_151: 0.5301 - recall_151: 0.8775\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5118 - auc_151: 0.5481 - precision_151: 0.5179 - recall_151: 0.8661\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5207 - auc_151: 0.5381 - precision_151: 0.5207 - recall_151: 0.9658\n",
            "\tFold:  2\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 2s 13ms/step - loss: 0.6948 - accuracy: 0.4912 - auc_152: 0.4813 - precision_152: 0.5225 - recall_152: 0.4807\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5308 - auc_152: 0.4737 - precision_152: 0.5314 - recall_152: 0.9807\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6950 - accuracy: 0.5293 - auc_152: 0.4379 - precision_152: 0.5301 - recall_152: 0.9972\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5235 - auc_152: 0.4744 - precision_152: 0.5282 - recall_152: 0.9586\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5308 - auc_152: 0.4889 - precision_152: 0.5315 - recall_152: 0.9779\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5264 - auc_152: 0.5117 - precision_152: 0.5288 - recall_152: 0.9890\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5191 - auc_152: 0.4886 - precision_152: 0.5266 - recall_152: 0.9282\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6927 - accuracy: 0.5337 - auc_152: 0.4751 - precision_152: 0.5328 - recall_152: 0.9862\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6911 - accuracy: 0.5235 - auc_152: 0.5230 - precision_152: 0.5302 - recall_152: 0.8978\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5205 - auc_152: 0.4718 - precision_152: 0.5267 - recall_152: 0.9530\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5308 - auc_152: 0.4832 - precision_152: 0.5310 - recall_152: 0.9945\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5323 - auc_152: 0.5195 - precision_152: 0.5333 - recall_152: 0.9503\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5308 - auc_152: 0.4911 - precision_152: 0.5311 - recall_152: 0.9917\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5249 - auc_152: 0.4952 - precision_152: 0.5281 - recall_152: 0.9862\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5249 - auc_152: 0.4737 - precision_152: 0.5315 - recall_152: 0.8867\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5279 - auc_152: 0.5138 - precision_152: 0.5310 - recall_152: 0.9475\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6929 - accuracy: 0.5279 - auc_152: 0.4816 - precision_152: 0.5304 - recall_152: 0.9641\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5308 - auc_152: 0.4850 - precision_152: 0.5311 - recall_152: 0.9917\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5191 - auc_152: 0.4961 - precision_152: 0.5266 - recall_152: 0.9309\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5308 - auc_152: 0.5329 - precision_152: 0.5313 - recall_152: 0.9834\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6937 - accuracy: 0.5249 - auc_152: 0.4618 - precision_152: 0.5287 - recall_152: 0.9669\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5352 - auc_152: 0.5082 - precision_152: 0.5332 - recall_152: 0.9972\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5293 - auc_152: 0.5170 - precision_152: 0.5304 - recall_152: 0.9890\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6918 - accuracy: 0.5191 - auc_152: 0.5071 - precision_152: 0.5253 - recall_152: 0.9751\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5205 - auc_152: 0.5096 - precision_152: 0.5270 - recall_152: 0.9448\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5279 - auc_152: 0.5015 - precision_152: 0.5295 - recall_152: 0.9917\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.5293 - auc_152: 0.4679 - precision_152: 0.5301 - recall_152: 0.9972\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6920 - accuracy: 0.5264 - auc_152: 0.5013 - precision_152: 0.5288 - recall_152: 0.9890\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5264 - auc_152: 0.5459 - precision_152: 0.5291 - recall_152: 0.9807\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5279 - auc_152: 0.4906 - precision_152: 0.5296 - recall_152: 0.9890\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5279 - auc_152: 0.4923 - precision_152: 0.5294 - recall_152: 0.9945\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5205 - auc_152: 0.4828 - precision_152: 0.5283 - recall_152: 0.9033\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.5308 - auc_152: 0.5328 - precision_152: 0.5312 - recall_152: 0.9890\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5323 - auc_152: 0.5128 - precision_152: 0.5316 - recall_152: 1.0000\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5381 - auc_152: 0.5077 - precision_152: 0.5390 - recall_152: 0.8978\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5279 - auc_152: 0.5078 - precision_152: 0.5298 - recall_152: 0.9834\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5425 - auc_152: 0.5106 - precision_152: 0.5386 - recall_152: 0.9641\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5205 - auc_152: 0.4756 - precision_152: 0.5276 - recall_152: 0.9227\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5264 - auc_152: 0.4946 - precision_152: 0.5289 - recall_152: 0.9862\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5425 - auc_152: 0.4993 - precision_152: 0.5380 - recall_152: 0.9779\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5308 - auc_152: 0.4856 - precision_152: 0.5311 - recall_152: 0.9917\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5205 - auc_152: 0.4971 - precision_152: 0.5289 - recall_152: 0.8840\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5308 - auc_152: 0.4895 - precision_152: 0.5311 - recall_152: 0.9917\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.5264 - auc_152: 0.4922 - precision_152: 0.5289 - recall_152: 0.9862\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6927 - accuracy: 0.5337 - auc_152: 0.4711 - precision_152: 0.5324 - recall_152: 1.0000\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.5279 - auc_152: 0.5232 - precision_152: 0.5299 - recall_152: 0.9807\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5440 - auc_152: 0.5333 - precision_152: 0.5416 - recall_152: 0.9171\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5337 - auc_152: 0.4630 - precision_152: 0.5328 - recall_152: 0.9862\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5323 - auc_152: 0.5331 - precision_152: 0.5316 - recall_152: 1.0000\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5117 - auc_152: 0.4926 - precision_152: 0.5233 - recall_152: 0.9006\n",
            "\tFold:  3\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 13ms/step - loss: 0.6962 - accuracy: 0.4765 - auc_153: 0.4676 - precision_153: 0.5031 - recall_153: 0.4540\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6939 - accuracy: 0.5249 - auc_153: 0.4842 - precision_153: 0.5263 - recall_153: 0.9749\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6935 - accuracy: 0.5176 - auc_153: 0.4794 - precision_153: 0.5224 - recall_153: 0.9749\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5161 - auc_153: 0.4790 - precision_153: 0.5235 - recall_153: 0.8997\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5132 - auc_153: 0.4920 - precision_153: 0.5226 - recall_153: 0.8691\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5235 - auc_153: 0.4967 - precision_153: 0.5284 - recall_153: 0.8802\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5249 - auc_153: 0.5071 - precision_153: 0.5264 - recall_153: 0.9721\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5235 - auc_153: 0.4817 - precision_153: 0.5279 - recall_153: 0.8969\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5220 - auc_153: 0.4948 - precision_153: 0.5270 - recall_153: 0.8969\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5337 - auc_153: 0.5307 - precision_153: 0.5308 - recall_153: 0.9833\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5293 - auc_153: 0.4983 - precision_153: 0.5308 - recall_153: 0.9109\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5352 - auc_153: 0.5129 - precision_153: 0.5330 - recall_153: 0.9443\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5220 - auc_153: 0.5092 - precision_153: 0.5254 - recall_153: 0.9499\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6955 - accuracy: 0.5176 - auc_153: 0.4493 - precision_153: 0.5229 - recall_153: 0.9554\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.5073 - auc_153: 0.4576 - precision_153: 0.5186 - recall_153: 0.8942\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5293 - auc_153: 0.5048 - precision_153: 0.5284 - recall_153: 0.9833\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6956 - accuracy: 0.5103 - auc_153: 0.4661 - precision_153: 0.5237 - recall_153: 0.7688\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5279 - auc_153: 0.4848 - precision_153: 0.5311 - recall_153: 0.8802\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5161 - auc_153: 0.4913 - precision_153: 0.5244 - recall_153: 0.8691\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5279 - auc_153: 0.5360 - precision_153: 0.5286 - recall_153: 0.9526\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.5147 - auc_153: 0.4729 - precision_153: 0.5222 - recall_153: 0.9192\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5147 - auc_153: 0.5160 - precision_153: 0.5217 - recall_153: 0.9387\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5235 - auc_153: 0.5087 - precision_153: 0.5302 - recall_153: 0.8301\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5235 - auc_153: 0.5162 - precision_153: 0.5363 - recall_153: 0.6992\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5132 - auc_153: 0.4854 - precision_153: 0.5203 - recall_153: 0.9638\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5249 - auc_153: 0.5029 - precision_153: 0.5310 - recall_153: 0.8357\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.4824 - auc_153: 0.4900 - precision_153: 0.5055 - recall_153: 0.7660\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5147 - auc_153: 0.4998 - precision_153: 0.5232 - recall_153: 0.8802\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6896 - accuracy: 0.5337 - auc_153: 0.5485 - precision_153: 0.5331 - recall_153: 0.9192\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5132 - auc_153: 0.4926 - precision_153: 0.5228 - recall_153: 0.8607\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5279 - auc_153: 0.5437 - precision_153: 0.5298 - recall_153: 0.9164\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5103 - auc_153: 0.4937 - precision_153: 0.5195 - recall_153: 0.9276\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.4897 - auc_153: 0.4817 - precision_153: 0.5096 - recall_153: 0.8134\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5015 - auc_153: 0.4857 - precision_153: 0.5165 - recall_153: 0.8273\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5396 - auc_153: 0.5157 - precision_153: 0.5353 - recall_153: 0.9499\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5191 - auc_153: 0.5070 - precision_153: 0.5243 - recall_153: 0.9304\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5073 - auc_153: 0.5097 - precision_153: 0.5201 - recall_153: 0.8301\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5235 - auc_153: 0.5066 - precision_153: 0.5264 - recall_153: 0.9443\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5279 - auc_153: 0.5280 - precision_153: 0.5283 - recall_153: 0.9610\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.5117 - auc_153: 0.5109 - precision_153: 0.5205 - recall_153: 0.9192\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5279 - auc_153: 0.5070 - precision_153: 0.5301 - recall_153: 0.9081\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5176 - auc_153: 0.4929 - precision_153: 0.5244 - recall_153: 0.8997\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5308 - auc_153: 0.5332 - precision_153: 0.5296 - recall_153: 0.9721\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5279 - auc_153: 0.5352 - precision_153: 0.5275 - recall_153: 0.9889\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5132 - auc_153: 0.5089 - precision_153: 0.5220 - recall_153: 0.8914\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6917 - accuracy: 0.5264 - auc_153: 0.5186 - precision_153: 0.5370 - recall_153: 0.7270\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5235 - auc_153: 0.5265 - precision_153: 0.5254 - recall_153: 0.9805\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5279 - auc_153: 0.5023 - precision_153: 0.5300 - recall_153: 0.9109\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5337 - auc_153: 0.5257 - precision_153: 0.5319 - recall_153: 0.9526\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5352 - auc_153: 0.5277 - precision_153: 0.5376 - recall_153: 0.8357\n",
            "\tFold:  4\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 2s 13ms/step - loss: 0.6923 - accuracy: 0.5292 - auc_154: 0.4994 - precision_154: 0.5318 - recall_154: 0.9006\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5277 - auc_154: 0.4836 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5277 - auc_154: 0.4745 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5277 - auc_154: 0.5410 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5277 - auc_154: 0.5060 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5277 - auc_154: 0.5318 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5277 - auc_154: 0.5052 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5277 - auc_154: 0.5151 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5277 - auc_154: 0.4890 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5277 - auc_154: 0.5149 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5277 - auc_154: 0.5260 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5277 - auc_154: 0.5577 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5277 - auc_154: 0.5129 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5277 - auc_154: 0.5200 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6908 - accuracy: 0.5277 - auc_154: 0.5449 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5277 - auc_154: 0.5004 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.5277 - auc_154: 0.5375 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5277 - auc_154: 0.5302 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6908 - accuracy: 0.5277 - auc_154: 0.5334 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5277 - auc_154: 0.5615 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5277 - auc_154: 0.5666 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5277 - auc_154: 0.5669 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.5277 - auc_154: 0.5911 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6904 - accuracy: 0.5277 - auc_154: 0.5604 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5277 - auc_154: 0.5228 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.5277 - auc_154: 0.5694 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5277 - auc_154: 0.5668 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5277 - auc_154: 0.5790 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.5277 - auc_154: 0.5609 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5277 - auc_154: 0.5645 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.5277 - auc_154: 0.5684 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5277 - auc_154: 0.5911 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5277 - auc_154: 0.5674 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5277 - auc_154: 0.5615 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5277 - auc_154: 0.5895 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5277 - auc_154: 0.5750 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5277 - auc_154: 0.5813 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6890 - accuracy: 0.5277 - auc_154: 0.5908 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6886 - accuracy: 0.5277 - auc_154: 0.6075 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6877 - accuracy: 0.5277 - auc_154: 0.6137 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6887 - accuracy: 0.5277 - auc_154: 0.5928 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6885 - accuracy: 0.5277 - auc_154: 0.5940 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.5277 - auc_154: 0.6070 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5277 - auc_154: 0.6001 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5277 - auc_154: 0.5953 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6879 - accuracy: 0.5277 - auc_154: 0.5904 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6877 - accuracy: 0.5277 - auc_154: 0.5920 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6863 - accuracy: 0.5277 - auc_154: 0.6289 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6863 - accuracy: 0.5277 - auc_154: 0.6234 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5277 - auc_154: 0.6278 - precision_154: 0.5277 - recall_154: 1.0000\n",
            "\tFold:  5\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 14ms/step - loss: 0.6924 - accuracy: 0.5215 - auc_155: 0.5209 - precision_155: 0.5299 - recall_155: 0.8622\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5301 - auc_155: 0.5153 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5301 - auc_155: 0.5282 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5301 - auc_155: 0.5429 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5301 - auc_155: 0.5421 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5301 - auc_155: 0.5631 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.5301 - auc_155: 0.5591 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5301 - auc_155: 0.5501 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5301 - auc_155: 0.5734 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5301 - auc_155: 0.5534 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.5301 - auc_155: 0.5826 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5301 - auc_155: 0.6033 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.5301 - auc_155: 0.5841 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5301 - auc_155: 0.5522 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5301 - auc_155: 0.5933 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5301 - auc_155: 0.5995 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5301 - auc_155: 0.5982 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5301 - auc_155: 0.5767 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6892 - accuracy: 0.5301 - auc_155: 0.5901 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5301 - auc_155: 0.6028 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5301 - auc_155: 0.5828 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5301 - auc_155: 0.6040 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.5301 - auc_155: 0.6145 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5301 - auc_155: 0.5975 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6878 - accuracy: 0.5301 - auc_155: 0.6003 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6873 - accuracy: 0.5301 - auc_155: 0.6215 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6869 - accuracy: 0.5301 - auc_155: 0.6267 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5301 - auc_155: 0.6167 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6862 - accuracy: 0.5301 - auc_155: 0.6172 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6862 - accuracy: 0.5301 - auc_155: 0.6149 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6853 - accuracy: 0.5301 - auc_155: 0.6267 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5301 - auc_155: 0.6350 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6847 - accuracy: 0.5301 - auc_155: 0.6235 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6841 - accuracy: 0.5301 - auc_155: 0.6251 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6834 - accuracy: 0.5301 - auc_155: 0.6241 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6830 - accuracy: 0.5301 - auc_155: 0.6302 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6819 - accuracy: 0.5301 - auc_155: 0.6398 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5301 - auc_155: 0.6238 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6806 - accuracy: 0.5301 - auc_155: 0.6377 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6801 - accuracy: 0.5301 - auc_155: 0.6386 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6798 - accuracy: 0.5301 - auc_155: 0.6367 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6784 - accuracy: 0.5301 - auc_155: 0.6464 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6781 - accuracy: 0.5301 - auc_155: 0.6375 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6767 - accuracy: 0.5301 - auc_155: 0.6435 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6762 - accuracy: 0.5301 - auc_155: 0.6385 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6757 - accuracy: 0.5301 - auc_155: 0.6404 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6742 - accuracy: 0.5301 - auc_155: 0.6453 - precision_155: 0.5301 - recall_155: 1.0000\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6734 - accuracy: 0.5559 - auc_155: 0.6477 - precision_155: 0.5442 - recall_155: 0.9973\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6728 - accuracy: 0.5688 - auc_155: 0.6453 - precision_155: 0.5535 - recall_155: 0.9649\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6720 - accuracy: 0.5688 - auc_155: 0.6492 - precision_155: 0.5552 - recall_155: 0.9378\n",
            "\tFold:  6\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 2s 15ms/step - loss: 0.6924 - accuracy: 0.5036 - auc_156: 0.4942 - precision_156: 0.5284 - recall_156: 0.7460\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5397 - auc_156: 0.4751 - precision_156: 0.5399 - recall_156: 0.9947\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5397 - auc_156: 0.4621 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6902 - accuracy: 0.5411 - auc_156: 0.5016 - precision_156: 0.5405 - recall_156: 1.0000\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5397 - auc_156: 0.4864 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5296 - auc_156: 0.4860 - precision_156: 0.5366 - recall_156: 0.9412\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6915 - accuracy: 0.5411 - auc_156: 0.4901 - precision_156: 0.5407 - recall_156: 0.9947\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5397 - auc_156: 0.4782 - precision_156: 0.5398 - recall_156: 0.9973\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6911 - accuracy: 0.5397 - auc_156: 0.4877 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5397 - auc_156: 0.4749 - precision_156: 0.5399 - recall_156: 0.9947\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6920 - accuracy: 0.5397 - auc_156: 0.4765 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5426 - auc_156: 0.4878 - precision_156: 0.5419 - recall_156: 0.9866\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5368 - auc_156: 0.4981 - precision_156: 0.5385 - recall_156: 0.9920\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6920 - accuracy: 0.5397 - auc_156: 0.4716 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5382 - auc_156: 0.4955 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6925 - accuracy: 0.5354 - auc_156: 0.4586 - precision_156: 0.5378 - recall_156: 0.9893\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5368 - auc_156: 0.4511 - precision_156: 0.5384 - recall_156: 0.9947\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5426 - auc_156: 0.5015 - precision_156: 0.5412 - recall_156: 1.0000\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5382 - auc_156: 0.5001 - precision_156: 0.5391 - recall_156: 0.9947\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6904 - accuracy: 0.5397 - auc_156: 0.5014 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.5469 - auc_156: 0.5088 - precision_156: 0.5440 - recall_156: 0.9920\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5382 - auc_156: 0.4906 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5397 - auc_156: 0.4807 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5397 - auc_156: 0.4689 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6911 - accuracy: 0.5382 - auc_156: 0.4882 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5368 - auc_156: 0.4769 - precision_156: 0.5384 - recall_156: 0.9947\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5382 - auc_156: 0.5015 - precision_156: 0.5391 - recall_156: 0.9947\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5382 - auc_156: 0.4761 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5397 - auc_156: 0.4843 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5411 - auc_156: 0.5144 - precision_156: 0.5405 - recall_156: 1.0000\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6890 - accuracy: 0.5455 - auc_156: 0.5369 - precision_156: 0.5428 - recall_156: 1.0000\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6905 - accuracy: 0.5397 - auc_156: 0.4982 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5397 - auc_156: 0.5015 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5397 - auc_156: 0.5514 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5397 - auc_156: 0.4962 - precision_156: 0.5409 - recall_156: 0.9733\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5397 - auc_156: 0.4666 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6900 - accuracy: 0.5397 - auc_156: 0.5082 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5440 - auc_156: 0.4672 - precision_156: 0.5420 - recall_156: 1.0000\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5411 - auc_156: 0.5083 - precision_156: 0.5405 - recall_156: 1.0000\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5397 - auc_156: 0.4961 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6910 - accuracy: 0.5397 - auc_156: 0.4854 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5397 - auc_156: 0.5065 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6913 - accuracy: 0.5382 - auc_156: 0.4708 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5411 - auc_156: 0.5121 - precision_156: 0.5405 - recall_156: 1.0000\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5411 - auc_156: 0.4994 - precision_156: 0.5405 - recall_156: 1.0000\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5382 - auc_156: 0.4889 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6900 - accuracy: 0.5382 - auc_156: 0.5118 - precision_156: 0.5390 - recall_156: 0.9973\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5354 - auc_156: 0.4932 - precision_156: 0.5379 - recall_156: 0.9866\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5397 - auc_156: 0.5170 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6905 - accuracy: 0.5397 - auc_156: 0.5069 - precision_156: 0.5397 - recall_156: 1.0000\n",
            "\tFold:  7\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 14ms/step - loss: 0.6944 - accuracy: 0.5007 - auc_157: 0.4874 - precision_157: 0.5206 - recall_157: 0.7182\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6908 - accuracy: 0.5265 - auc_157: 0.5216 - precision_157: 0.5286 - recall_157: 0.9756\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5380 - auc_157: 0.4920 - precision_157: 0.5358 - recall_157: 0.9539\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.5151 - auc_157: 0.4638 - precision_157: 0.5230 - recall_157: 0.9539\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5308 - auc_157: 0.5367 - precision_157: 0.5315 - recall_157: 0.9593\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.5409 - auc_157: 0.4945 - precision_157: 0.5363 - recall_157: 0.9810\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5265 - auc_157: 0.4832 - precision_157: 0.5284 - recall_157: 0.9837\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5265 - auc_157: 0.5116 - precision_157: 0.5285 - recall_157: 0.9810\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5108 - auc_157: 0.4881 - precision_157: 0.5214 - recall_157: 0.9241\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5352 - auc_157: 0.5148 - precision_157: 0.5335 - recall_157: 0.9702\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6913 - accuracy: 0.5294 - auc_157: 0.5060 - precision_157: 0.5306 - recall_157: 0.9648\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5251 - auc_157: 0.4899 - precision_157: 0.5279 - recall_157: 0.9756\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5251 - auc_157: 0.4876 - precision_157: 0.5276 - recall_157: 0.9837\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6908 - accuracy: 0.5308 - auc_157: 0.5303 - precision_157: 0.5340 - recall_157: 0.8943\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6923 - accuracy: 0.5208 - auc_157: 0.4919 - precision_157: 0.5270 - recall_157: 0.9268\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5323 - auc_157: 0.5202 - precision_157: 0.5309 - recall_157: 1.0000\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6900 - accuracy: 0.5308 - auc_157: 0.5427 - precision_157: 0.5311 - recall_157: 0.9729\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5194 - auc_157: 0.5217 - precision_157: 0.5252 - recall_157: 0.9593\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6917 - accuracy: 0.5237 - auc_157: 0.5022 - precision_157: 0.5276 - recall_157: 0.9593\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5294 - auc_157: 0.5256 - precision_157: 0.5298 - recall_157: 0.9892\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5265 - auc_157: 0.5252 - precision_157: 0.5284 - recall_157: 0.9837\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6926 - accuracy: 0.5136 - auc_157: 0.4955 - precision_157: 0.5225 - recall_157: 0.9431\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5308 - auc_157: 0.5214 - precision_157: 0.5324 - recall_157: 0.9350\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5323 - auc_157: 0.4953 - precision_157: 0.5314 - recall_157: 0.9864\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5409 - auc_157: 0.4999 - precision_157: 0.5383 - recall_157: 0.9322\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5251 - auc_157: 0.4990 - precision_157: 0.5275 - recall_157: 0.9864\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6920 - accuracy: 0.5208 - auc_157: 0.5091 - precision_157: 0.5268 - recall_157: 0.9322\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6925 - accuracy: 0.5294 - auc_157: 0.4763 - precision_157: 0.5298 - recall_157: 0.9892\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5337 - auc_157: 0.5541 - precision_157: 0.5318 - recall_157: 0.9973\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5280 - auc_157: 0.5491 - precision_157: 0.5301 - recall_157: 0.9539\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5294 - auc_157: 0.4910 - precision_157: 0.5300 - recall_157: 0.9810\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5222 - auc_157: 0.5302 - precision_157: 0.5261 - recall_157: 0.9837\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5251 - auc_157: 0.5412 - precision_157: 0.5278 - recall_157: 0.9783\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5524 - auc_157: 0.5112 - precision_157: 0.5435 - recall_157: 0.9648\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6904 - accuracy: 0.5265 - auc_157: 0.5272 - precision_157: 0.5283 - recall_157: 0.9864\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5294 - auc_157: 0.4988 - precision_157: 0.5301 - recall_157: 0.9783\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5179 - auc_157: 0.4832 - precision_157: 0.5247 - recall_157: 0.9512\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5337 - auc_157: 0.4962 - precision_157: 0.5318 - recall_157: 0.9973\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.5294 - auc_157: 0.5488 - precision_157: 0.5298 - recall_157: 0.9892\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5251 - auc_157: 0.5023 - precision_157: 0.5286 - recall_157: 0.9512\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5294 - auc_157: 0.5151 - precision_157: 0.5300 - recall_157: 0.9810\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5194 - auc_157: 0.4835 - precision_157: 0.5249 - recall_157: 0.9729\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.5337 - auc_157: 0.4987 - precision_157: 0.5318 - recall_157: 0.9973\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5337 - auc_157: 0.5271 - precision_157: 0.5325 - recall_157: 0.9756\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5352 - auc_157: 0.5056 - precision_157: 0.5328 - recall_157: 0.9892\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5352 - auc_157: 0.4934 - precision_157: 0.5337 - recall_157: 0.9648\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5294 - auc_157: 0.5396 - precision_157: 0.5313 - recall_157: 0.9431\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6927 - accuracy: 0.5251 - auc_157: 0.4798 - precision_157: 0.5276 - recall_157: 0.9837\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6884 - accuracy: 0.5251 - auc_157: 0.5727 - precision_157: 0.5274 - recall_157: 0.9919\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5265 - auc_157: 0.5239 - precision_157: 0.5289 - recall_157: 0.9675\n",
            "\tFold:  8\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 15ms/step - loss: 0.6988 - accuracy: 0.5165 - auc_158: 0.4664 - precision_158: 0.5267 - recall_158: 0.9299\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6970 - accuracy: 0.4906 - auc_158: 0.4805 - precision_158: 0.5252 - recall_158: 0.4771\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6884 - accuracy: 0.5468 - auc_158: 0.5401 - precision_158: 0.5456 - recall_158: 0.9030\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5353 - auc_158: 0.4927 - precision_158: 0.5373 - recall_158: 0.9326\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6934 - accuracy: 0.5237 - auc_158: 0.4779 - precision_158: 0.5299 - recall_158: 0.9569\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5094 - auc_158: 0.4833 - precision_158: 0.5251 - recall_158: 0.8464\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5252 - auc_158: 0.4823 - precision_158: 0.5365 - recall_158: 0.8113\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5353 - auc_158: 0.4855 - precision_158: 0.5349 - recall_158: 0.9919\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5151 - auc_158: 0.5019 - precision_158: 0.5289 - recall_158: 0.8383\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5309 - auc_158: 0.4798 - precision_158: 0.5333 - recall_158: 0.9704\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6908 - accuracy: 0.5353 - auc_158: 0.5067 - precision_158: 0.5373 - recall_158: 0.9326\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6891 - accuracy: 0.5194 - auc_158: 0.5365 - precision_158: 0.5296 - recall_158: 0.8922\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5252 - auc_158: 0.4854 - precision_158: 0.5322 - recall_158: 0.9137\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5381 - auc_158: 0.5073 - precision_158: 0.5365 - recall_158: 0.9892\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6921 - accuracy: 0.5223 - auc_158: 0.5017 - precision_158: 0.5295 - recall_158: 0.9434\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5165 - auc_158: 0.5028 - precision_158: 0.5273 - recall_158: 0.9111\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5252 - auc_158: 0.5301 - precision_158: 0.5322 - recall_158: 0.9137\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5252 - auc_158: 0.4941 - precision_158: 0.5315 - recall_158: 0.9326\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6948 - accuracy: 0.5353 - auc_158: 0.4565 - precision_158: 0.5359 - recall_158: 0.9650\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5266 - auc_158: 0.4727 - precision_158: 0.5309 - recall_158: 0.9730\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6934 - accuracy: 0.5165 - auc_158: 0.4856 - precision_158: 0.5263 - recall_158: 0.9434\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5223 - auc_158: 0.4939 - precision_158: 0.5304 - recall_158: 0.9164\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6908 - accuracy: 0.5209 - auc_158: 0.5234 - precision_158: 0.5343 - recall_158: 0.7978\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5353 - auc_158: 0.5223 - precision_158: 0.5348 - recall_158: 0.9946\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6915 - accuracy: 0.5266 - auc_158: 0.5001 - precision_158: 0.5323 - recall_158: 0.9326\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5367 - auc_158: 0.5087 - precision_158: 0.5367 - recall_158: 0.9650\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5137 - auc_158: 0.5119 - precision_158: 0.5261 - recall_158: 0.8949\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6936 - accuracy: 0.5237 - auc_158: 0.4837 - precision_158: 0.5299 - recall_158: 0.9569\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5209 - auc_158: 0.4867 - precision_158: 0.5291 - recall_158: 0.9326\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6890 - accuracy: 0.5367 - auc_158: 0.5514 - precision_158: 0.5426 - recall_158: 0.8410\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6942 - accuracy: 0.5266 - auc_158: 0.4589 - precision_158: 0.5307 - recall_158: 0.9784\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6896 - accuracy: 0.5396 - auc_158: 0.5301 - precision_158: 0.5372 - recall_158: 0.9919\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.5353 - auc_158: 0.5313 - precision_158: 0.5397 - recall_158: 0.8787\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6921 - accuracy: 0.5353 - auc_158: 0.4954 - precision_158: 0.5352 - recall_158: 0.9838\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5353 - auc_158: 0.5051 - precision_158: 0.5354 - recall_158: 0.9784\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5223 - auc_158: 0.5324 - precision_158: 0.5295 - recall_158: 0.9434\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6900 - accuracy: 0.5424 - auc_158: 0.5168 - precision_158: 0.5396 - recall_158: 0.9730\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5281 - auc_158: 0.5148 - precision_158: 0.5347 - recall_158: 0.8922\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5453 - auc_158: 0.4991 - precision_158: 0.5404 - recall_158: 0.9919\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.5065 - auc_158: 0.4852 - precision_158: 0.5241 - recall_158: 0.8194\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5309 - auc_158: 0.4792 - precision_158: 0.5336 - recall_158: 0.9623\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5324 - auc_158: 0.5274 - precision_158: 0.5335 - recall_158: 0.9865\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5266 - auc_158: 0.5346 - precision_158: 0.5308 - recall_158: 0.9757\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5194 - auc_158: 0.5326 - precision_158: 0.5282 - recall_158: 0.9353\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5338 - auc_158: 0.4960 - precision_158: 0.5362 - recall_158: 0.9380\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6911 - accuracy: 0.5137 - auc_158: 0.5071 - precision_158: 0.5253 - recall_158: 0.9218\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6900 - accuracy: 0.5410 - auc_158: 0.5215 - precision_158: 0.5393 - recall_158: 0.9623\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5353 - auc_158: 0.5148 - precision_158: 0.5349 - recall_158: 0.9919\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5353 - auc_158: 0.5335 - precision_158: 0.5350 - recall_158: 0.9892\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5281 - auc_158: 0.4948 - precision_158: 0.5326 - recall_158: 0.9461\n",
            "\tFold:  9\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 2s 14ms/step - loss: 0.6928 - accuracy: 0.5081 - auc_159: 0.4923 - precision_159: 0.5196 - recall_159: 0.8197\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5229 - auc_159: 0.4965 - precision_159: 0.5247 - recall_159: 0.9577\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5081 - auc_159: 0.4922 - precision_159: 0.5185 - recall_159: 0.8676\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5258 - auc_159: 0.4963 - precision_159: 0.5254 - recall_159: 0.9915\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5170 - auc_159: 0.4769 - precision_159: 0.5208 - recall_159: 0.9859\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6923 - accuracy: 0.5199 - auc_159: 0.5083 - precision_159: 0.5223 - recall_159: 0.9887\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5258 - auc_159: 0.4899 - precision_159: 0.5254 - recall_159: 0.9915\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5199 - auc_159: 0.4664 - precision_159: 0.5225 - recall_159: 0.9803\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5214 - auc_159: 0.5318 - precision_159: 0.5230 - recall_159: 0.9915\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5244 - auc_159: 0.4964 - precision_159: 0.5250 - recall_159: 0.9775\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5258 - auc_159: 0.5007 - precision_159: 0.5255 - recall_159: 0.9859\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6921 - accuracy: 0.5199 - auc_159: 0.5074 - precision_159: 0.5223 - recall_159: 0.9887\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6951 - accuracy: 0.5214 - auc_159: 0.4236 - precision_159: 0.5233 - recall_159: 0.9803\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5288 - auc_159: 0.4864 - precision_159: 0.5267 - recall_159: 1.0000\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5391 - auc_159: 0.5151 - precision_159: 0.5335 - recall_159: 0.9634\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5199 - auc_159: 0.4902 - precision_159: 0.5274 - recall_159: 0.8141\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6930 - accuracy: 0.5258 - auc_159: 0.4936 - precision_159: 0.5256 - recall_159: 0.9831\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6933 - accuracy: 0.5214 - auc_159: 0.4784 - precision_159: 0.5236 - recall_159: 0.9690\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5199 - auc_159: 0.4627 - precision_159: 0.5225 - recall_159: 0.9803\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6926 - accuracy: 0.5244 - auc_159: 0.4937 - precision_159: 0.5244 - recall_159: 1.0000\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5258 - auc_159: 0.5240 - precision_159: 0.5254 - recall_159: 0.9887\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5214 - auc_159: 0.4839 - precision_159: 0.5231 - recall_159: 0.9887\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5096 - auc_159: 0.5106 - precision_159: 0.5195 - recall_159: 0.8648\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5185 - auc_159: 0.5506 - precision_159: 0.5236 - recall_159: 0.9070\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.5391 - auc_159: 0.5323 - precision_159: 0.5338 - recall_159: 0.9577\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6896 - accuracy: 0.5332 - auc_159: 0.5687 - precision_159: 0.5295 - recall_159: 0.9859\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5347 - auc_159: 0.5338 - precision_159: 0.5319 - recall_159: 0.9380\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5140 - auc_159: 0.4997 - precision_159: 0.5214 - recall_159: 0.8930\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5244 - auc_159: 0.5075 - precision_159: 0.5247 - recall_159: 0.9887\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6908 - accuracy: 0.5377 - auc_159: 0.5281 - precision_159: 0.5324 - recall_159: 0.9718\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6943 - accuracy: 0.5229 - auc_159: 0.4840 - precision_159: 0.5237 - recall_159: 0.9972\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6917 - accuracy: 0.5244 - auc_159: 0.5018 - precision_159: 0.5247 - recall_159: 0.9887\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6909 - accuracy: 0.5273 - auc_159: 0.5290 - precision_159: 0.5264 - recall_159: 0.9831\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5096 - auc_159: 0.4821 - precision_159: 0.5176 - recall_159: 0.9521\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5273 - auc_159: 0.5145 - precision_159: 0.5260 - recall_159: 0.9972\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5332 - auc_159: 0.5368 - precision_159: 0.5300 - recall_159: 0.9690\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.5199 - auc_159: 0.4977 - precision_159: 0.5224 - recall_159: 0.9859\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6922 - accuracy: 0.5362 - auc_159: 0.4989 - precision_159: 0.5321 - recall_159: 0.9577\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6923 - accuracy: 0.5126 - auc_159: 0.5084 - precision_159: 0.5190 - recall_159: 0.9634\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6905 - accuracy: 0.5318 - auc_159: 0.5431 - precision_159: 0.5303 - recall_159: 0.9380\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5229 - auc_159: 0.5515 - precision_159: 0.5244 - recall_159: 0.9690\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5273 - auc_159: 0.5590 - precision_159: 0.5260 - recall_159: 0.9972\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.5199 - auc_159: 0.5515 - precision_159: 0.5227 - recall_159: 0.9746\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6892 - accuracy: 0.5332 - auc_159: 0.5671 - precision_159: 0.5299 - recall_159: 0.9746\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6904 - accuracy: 0.5303 - auc_159: 0.5367 - precision_159: 0.5285 - recall_159: 0.9662\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5185 - auc_159: 0.5487 - precision_159: 0.5217 - recall_159: 0.9803\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6903 - accuracy: 0.5347 - auc_159: 0.5421 - precision_159: 0.5318 - recall_159: 0.9408\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6902 - accuracy: 0.5244 - auc_159: 0.5369 - precision_159: 0.5253 - recall_159: 0.9634\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.5214 - auc_159: 0.5163 - precision_159: 0.5243 - recall_159: 0.9408\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5214 - auc_159: 0.5239 - precision_159: 0.5233 - recall_159: 0.9803\n",
            "\tFold:  10\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 1s 15ms/step - loss: 0.6889 - accuracy: 0.5622 - auc_160: 0.5613 - precision_160: 0.5850 - recall_160: 0.6772\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6901 - accuracy: 0.5451 - auc_160: 0.4980 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6910 - accuracy: 0.5465 - auc_160: 0.4802 - precision_160: 0.5458 - recall_160: 1.0000\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6903 - accuracy: 0.5436 - auc_160: 0.4936 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5451 - auc_160: 0.5003 - precision_160: 0.5453 - recall_160: 0.9948\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.5451 - auc_160: 0.5124 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5436 - auc_160: 0.5052 - precision_160: 0.5449 - recall_160: 0.9869\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.5451 - auc_160: 0.4511 - precision_160: 0.5453 - recall_160: 0.9948\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6905 - accuracy: 0.5451 - auc_160: 0.4842 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6880 - accuracy: 0.5451 - auc_160: 0.5200 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5408 - auc_160: 0.4856 - precision_160: 0.5436 - recall_160: 0.9816\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6911 - accuracy: 0.5436 - auc_160: 0.4764 - precision_160: 0.5445 - recall_160: 0.9948\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6891 - accuracy: 0.5465 - auc_160: 0.4993 - precision_160: 0.5458 - recall_160: 1.0000\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5508 - auc_160: 0.4944 - precision_160: 0.5482 - recall_160: 1.0000\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6880 - accuracy: 0.5451 - auc_160: 0.5215 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6911 - accuracy: 0.5451 - auc_160: 0.4808 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6912 - accuracy: 0.5308 - auc_160: 0.4841 - precision_160: 0.5391 - recall_160: 0.9580\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6900 - accuracy: 0.5451 - auc_160: 0.4979 - precision_160: 0.5456 - recall_160: 0.9895\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.5451 - auc_160: 0.5148 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5451 - auc_160: 0.4814 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6879 - accuracy: 0.5479 - auc_160: 0.5283 - precision_160: 0.5466 - recall_160: 1.0000\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6888 - accuracy: 0.5436 - auc_160: 0.5242 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6889 - accuracy: 0.5436 - auc_160: 0.5145 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.5451 - auc_160: 0.5036 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5436 - auc_160: 0.4801 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5436 - auc_160: 0.4747 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6907 - accuracy: 0.5422 - auc_160: 0.4860 - precision_160: 0.5438 - recall_160: 0.9948\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6884 - accuracy: 0.5451 - auc_160: 0.5171 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5451 - auc_160: 0.5034 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6882 - accuracy: 0.5451 - auc_160: 0.5213 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6887 - accuracy: 0.5422 - auc_160: 0.5157 - precision_160: 0.5438 - recall_160: 0.9948\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6903 - accuracy: 0.5436 - auc_160: 0.4843 - precision_160: 0.5445 - recall_160: 0.9948\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5436 - auc_160: 0.5212 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5436 - auc_160: 0.5004 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5451 - auc_160: 0.5024 - precision_160: 0.5452 - recall_160: 0.9974\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6898 - accuracy: 0.5408 - auc_160: 0.5050 - precision_160: 0.5432 - recall_160: 0.9895\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6913 - accuracy: 0.5465 - auc_160: 0.4762 - precision_160: 0.5458 - recall_160: 1.0000\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6882 - accuracy: 0.5422 - auc_160: 0.5245 - precision_160: 0.5438 - recall_160: 0.9948\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6878 - accuracy: 0.5451 - auc_160: 0.5184 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6879 - accuracy: 0.5436 - auc_160: 0.5319 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6881 - accuracy: 0.5451 - auc_160: 0.5240 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6885 - accuracy: 0.5436 - auc_160: 0.5249 - precision_160: 0.5444 - recall_160: 0.9974\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6884 - accuracy: 0.5479 - auc_160: 0.5265 - precision_160: 0.5466 - recall_160: 1.0000\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6873 - accuracy: 0.5451 - auc_160: 0.5419 - precision_160: 0.5453 - recall_160: 0.9948\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6897 - accuracy: 0.5465 - auc_160: 0.5049 - precision_160: 0.5458 - recall_160: 1.0000\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6887 - accuracy: 0.5422 - auc_160: 0.5125 - precision_160: 0.5440 - recall_160: 0.9895\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6904 - accuracy: 0.5451 - auc_160: 0.4898 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.5451 - auc_160: 0.5078 - precision_160: 0.5453 - recall_160: 0.9948\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6855 - accuracy: 0.5465 - auc_160: 0.5749 - precision_160: 0.5458 - recall_160: 1.0000\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6871 - accuracy: 0.5451 - auc_160: 0.5487 - precision_160: 0.5451 - recall_160: 1.0000\n",
            "\n",
            " =========== ALL ITERATIONS RESULTS SUMMARY ===========\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   iteration  accuracy    auroc  precision   recall\n",
              "0          1  0.529412  0.52778   0.541818  0.73399"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2558e81b-9ea5-4b1d-9730-4027eb76ba2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iteration</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>auroc</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.52778</td>\n",
              "      <td>0.541818</td>\n",
              "      <td>0.73399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2558e81b-9ea5-4b1d-9730-4027eb76ba2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2558e81b-9ea5-4b1d-9730-4027eb76ba2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2558e81b-9ea5-4b1d-9730-4027eb76ba2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averages over all iterations: \n",
            "      AUROC: 0.53\n",
            "  Precision: 0.54\n",
            "     Recall: 0.73\n",
            "   Accuracy: 0.53\n",
            "\n",
            "Median iteration number:  1\n",
            "\n",
            "Median AUROC: 0.53\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Troubleshoot"
      ],
      "metadata": {
        "id": "QTiwHO-AZCxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_list.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlrIb9OZpgu8",
        "outputId": "d6e62dce-44be-4962-8904-0f920e0f8147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UDEy0WFkqI7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}