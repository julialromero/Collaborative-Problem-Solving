{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning_pipeline_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julialromero/Collaborative-Problem-Solving/blob/main/learning_pipeline_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v1g3ar0jiAuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc19f5c-d7cd-4531-f4ba-e6e103d84ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BRAjwxfli5cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import os\n",
        "from skimage import io\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from keras import layers, Input, Model, optimizers\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "PROJECT_DIR = \"drive/MyDrive/CSCI 5922 - Final Project/\"  #<--- Make a shortcut for the \"CSCI 5922 - Final Project\" shared folder on your Google Drive"
      ],
      "metadata": {
        "id": "UN0E43_si6aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233b3311-2b6f-4faa-9e42-ede37ea8ff1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  4 12:14:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get User Input"
      ],
      "metadata": {
        "id": "s0pWhCIDjhIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose what size images to use\n",
        "PROJECT_DIR = \"drive/MyDrive/CSCI 5922 - Final Project/\"  #<--- Make a shortcut for the \"CSCI 5922 - Final Project\" shared folder on your Google Drive\n",
        "## \"small\" = 98x98, \"med\" = 332x332, \"large\" = 719x719\n",
        "image_size = \"large\"\n",
        "shuffled = True\n",
        "chance = False\n",
        "normalize = False\n",
        "scaled = False\n",
        "num_iters = 10\n",
        "num_folds = 10\n",
        "threshold = 0.5\n",
        "num_epochs = 50\n",
        "\n",
        "if image_size == \"large\":\n",
        "  imgsize = (int(719/2), int(719/2)) \n",
        "  if shuffled:\n",
        "    IMG_DIR = \"719x719 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"719x719 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"med\":\n",
        "  imgsize = (332, 332)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"332x332 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"332x332 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"small\":\n",
        "  imgsize = (98, 98)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"98x98 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"98x98 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "print(\"Processing images from: \", IMG_DIR)"
      ],
      "metadata": {
        "id": "r-z42Z2RjiSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2311b8e9-f2de-4243-f0d8-d7b32752b06f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing images from:  719x719 - Recurrence_Matrices/RAW_SHUFFLED/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "BmoT19DNj5DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read, preprocess, and scale images to uniform dimension\n",
        "\n",
        "def extract_image(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) \n",
        "\n",
        "    return x\n",
        "\n",
        "'''\n",
        "    Converts grayscale image to 3 channels in order to fit Inception v3 model\n",
        "'''\n",
        "def extract_image_inceptionv3(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) \n",
        "    x = np.squeeze(np.stack((x,)*3))\n",
        "    x = x.swapaxes(0,1)\n",
        "    x = x.swapaxes(1,2)\n",
        "\n",
        "    return x\n",
        "\n",
        "def extract_score(filename, outcome_df, score_col=\"task_score\"):\n",
        "    #  match this file's id/block with task score and return\n",
        "    groupid, splitname = filename.split(\"-\")\n",
        "    block = splitname.split(\"_\")[0]\n",
        "    row = outcome_df.loc[(outcome_df.GROUPID == int(groupid)) & (outcome_df.block == block)]\n",
        "    if(row.shape[0] != 1):\n",
        "        print(f\"Error -- Number of task scores recorded is not 1 for block {block} and groupid {groupid}.\")\n",
        "        return np.nan\n",
        "    score = row[score_col].values[0]\n",
        "    return score\n",
        "\n",
        "\n",
        "def extract_binary_score(filename, outcome_df, score_col=\"task_score\", median_score=2):\n",
        "    #  match this file's id/block with task score and return\n",
        "    groupid, splitname = filename.split(\"-\")\n",
        "    block = splitname.split(\"_\")[0]\n",
        "    row = outcome_df.loc[(outcome_df.GROUPID == int(groupid)) & (outcome_df.block == block)]\n",
        "    if(row.shape[0] != 1):\n",
        "        print(f\"Error -- Number of task scores recorded is not 1 for block {block} and groupid {groupid}.\")\n",
        "        return np.nan\n",
        "    raw_score = row[score_col].values[0]\n",
        "    if raw_score <= median_score:\n",
        "        score = 0\n",
        "    else:\n",
        "        score = 1\n",
        "    return score\n",
        "\n",
        "def min_max_scaling(series):\n",
        "    # https://datagy.io/pandas-normalize-column/\n",
        "    return (series - series.min()) / (series.max() - series.min())\n",
        "\n",
        "def absolute_maximum_scale(series):\n",
        "    # https://datagy.io/pandas-normalize-column/\n",
        "    return series / series.abs().max()\n",
        "\n",
        "def get_fold_data(GROUPID_list, score_col, incv3=False, verbose=False):\n",
        "  # read data to np arrays\n",
        "  recurrence_plot_list = []\n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = []\n",
        "  \n",
        "  labels = []\n",
        "  binary_labels = []\n",
        "\n",
        "  for filename in os.listdir(PROJECT_DIR + IMG_DIR):\n",
        "      # Check if file belongs to one of the teams in the desired group\n",
        "      for GROUPID in GROUPID_list:\n",
        "        if str(GROUPID) == filename.split(\"-\")[0]:\n",
        "          # preprocess image\n",
        "          if incv3:\n",
        "            t_incv3 = extract_image_inceptionv3(PROJECT_DIR + IMG_DIR + filename)\n",
        "          else:\n",
        "            t = extract_image(PROJECT_DIR + IMG_DIR + filename)\n",
        "\n",
        "          # get task score\n",
        "          lab = extract_score(filename, outcome_df, score_col)\n",
        "          bin_lab = extract_binary_score(filename, outcome_df, score_col=\"task_score\", median_score=2)\n",
        "\n",
        "          # append data \n",
        "          if incv3:\n",
        "            recurrence_plot_list_incv3.append(t_incv3)\n",
        "          else:\n",
        "            recurrence_plot_list.append(t)\n",
        "          \n",
        "          labels.append(lab)\n",
        "          binary_labels.append(bin_lab)\n",
        "\n",
        "  # convert to arrays \n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = np.array(recurrence_plot_list_incv3)\n",
        "    plot_list = recurrence_plot_list_incv3\n",
        "  else:\n",
        "    recurrence_plot_list = np.array(recurrence_plot_list)\n",
        "    plot_list = recurrence_plot_list\n",
        "  \n",
        "  labels = np.array(labels)\n",
        "  binary_labels = np.array(binary_labels)\n",
        "\n",
        "  if verbose:\n",
        "    print(\"\\nFOLD DATA INFO: \")\n",
        "    if incv3:\n",
        "      print(f\"\\trecurrence_plot_list_incv3: {recurrence_plot_list_incv3.shape}\")\n",
        "    else:\n",
        "      print(f\"\\trecurrence_plot_list: {recurrence_plot_list.shape}\")\n",
        "    \n",
        "    binary_counts = dict(Counter(binary_labels))\n",
        "    print(\"\\tBinary label counts: \", binary_counts)\n",
        "\n",
        "  return [plot_list, labels, binary_labels]\n",
        "  \n"
      ],
      "metadata": {
        "id": "njVlH7TOj6Jf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Team Outcomes"
      ],
      "metadata": {
        "id": "MJSniIOFjuNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_df = pd.read_csv(PROJECT_DIR + \"team_block_outcomes.csv\")\n",
        "\n",
        "# get median task_score\n",
        "task_scores = outcome_df[\"task_score\"]\n",
        "median_task_score = np.median(task_scores)\n",
        "mean_task_score = np.mean(task_scores)\n",
        "print(\"median: \", median_task_score)\n",
        "print(\"mean: \", mean_task_score)\n",
        "\n",
        "# normalize task_score\n",
        "outcome_df[\"norm_task_score\"] = min_max_scaling(outcome_df[\"task_score\"])\n",
        "\n",
        "# scale task score from -1 to 1\n",
        "outcome_df[\"scaled_task_score\"] = absolute_maximum_scale(outcome_df[\"task_score\"])\n",
        "\n",
        "# score_counts = dict(Counter(task_scores))\n",
        "# for key in score_counts:\n",
        "#     print(\"%d: %d\" % (key, score_counts[key]))\n",
        "\n",
        "outcome_df"
      ],
      "metadata": {
        "id": "pPdt0o8MjvZf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "ca973c89-d9cd-4011-dc2b-d4e192e42110"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median:  2.0\n",
            "mean:  3.5437956204379564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     GROUPID      block  CPS_and_ITN_mean   Valence  num_gold  num_silver  \\\n",
              "0       1010  ExpBlock1         -0.304697  3.666667       1.0         1.0   \n",
              "1       1010  ExpBlock2         -0.304697  3.666667       2.0         1.0   \n",
              "2       1020  ExpBlock1         -0.389995  4.333333       0.0         2.0   \n",
              "3       1020  ExpBlock2         -0.026413  4.666667       4.0         1.0   \n",
              "4       1020     Warmup         -0.742380  3.666667       0.0         0.0   \n",
              "..       ...        ...               ...       ...       ...         ...   \n",
              "269    10103  ExpBlock2         -0.026413  3.666667       1.0         1.0   \n",
              "270    10103     Warmup         -1.405215  3.333333       1.0         2.0   \n",
              "271    10104  ExpBlock1         -0.531224  3.000000       0.0         0.0   \n",
              "272    10104  ExpBlock2         -1.023464  4.000000       0.0         1.0   \n",
              "273    10104     Warmup         -0.194209  3.000000       0.0         0.0   \n",
              "\n",
              "     task_score  norm_task_score  scaled_task_score  \n",
              "0           3.0         0.200000           0.200000  \n",
              "1           5.0         0.333333           0.333333  \n",
              "2           2.0         0.133333           0.133333  \n",
              "3           9.0         0.600000           0.600000  \n",
              "4           0.0         0.000000           0.000000  \n",
              "..          ...              ...                ...  \n",
              "269         3.0         0.200000           0.200000  \n",
              "270         4.0         0.266667           0.266667  \n",
              "271         0.0         0.000000           0.000000  \n",
              "272         1.0         0.066667           0.066667  \n",
              "273         0.0         0.000000           0.000000  \n",
              "\n",
              "[274 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8095009f-f46d-43b2-ad21-daab3a1e7a03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GROUPID</th>\n",
              "      <th>block</th>\n",
              "      <th>CPS_and_ITN_mean</th>\n",
              "      <th>Valence</th>\n",
              "      <th>num_gold</th>\n",
              "      <th>num_silver</th>\n",
              "      <th>task_score</th>\n",
              "      <th>norm_task_score</th>\n",
              "      <th>scaled_task_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1010</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.304697</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.304697</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1020</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.389995</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1020</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.026413</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1020</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-0.742380</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>10103</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.026413</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>10103</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-1.405215</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>10104</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.531224</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>10104</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-1.023464</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>10104</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-0.194209</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>274 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8095009f-f46d-43b2-ad21-daab3a1e7a03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8095009f-f46d-43b2-ad21-daab3a1e7a03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8095009f-f46d-43b2-ad21-daab3a1e7a03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression w/ Team-level Cross Validation"
      ],
      "metadata": {
        "id": "G1tXo-RPmCIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep folds for team-level cross validation"
      ],
      "metadata": {
        "id": "-H9KHjoamQ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fold names\n",
        "train_folds = []\n",
        "test_folds = []\n",
        "set_type = \"test\"\n",
        "for j in range(1,num_folds+1): \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    test_folds.append(col_name)\n",
        "    set_type = \"train\"  \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    train_folds.append(col_name)\n",
        "    set_type = \"test\"\n",
        "\n",
        "folds_dict_list = []\n",
        "\n",
        "# Split teams into 5 groups\n",
        "teams = pd.unique(outcome_df.GROUPID)\n",
        "\n",
        "# For every iteration\n",
        "for i in range(1,num_iters+1):\n",
        "    print(\"Iteration: \", i)\n",
        "    teams = shuffle(teams, random_state=i)\n",
        "    groups = np.array_split(teams, num_folds)\n",
        "    \n",
        "    # Define groups for each fold\n",
        "    fold_groups = {}\n",
        "    for j, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
        "        # make the current group the test group\n",
        "        fold_groups[test_fold] = groups[j]\n",
        "        # make all other groups the train group\n",
        "        train_group = groups[:j] + groups[j+1:]\n",
        "        train_group = [team for group in train_group for team in group]\n",
        "        fold_groups[train_fold] = train_group\n",
        "        \n",
        "    ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(fold_groups['Fold'+str(j)+'_test']).isdisjoint(set(fold_groups['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "    print(\"* No team overlap *\")\n",
        "\n",
        "      \n",
        "    # Add fold groups to dictionary\n",
        "    folds_dict_list.append(fold_groups)\n",
        "    \n",
        "\n",
        "# Informational\n",
        "print(\"\\nNumber of iterations: \", len(folds_dict_list))\n",
        "\n",
        "print(\"\\nIterating through folds_dict_list to check for overlap...\")\n",
        "for i,dicti in enumerate(folds_dict_list):\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(dicti['Fold'+str(j)+'_test']).isdisjoint(set(dicti['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "print(\"* No team overlap *\")  \n",
        "\n"
      ],
      "metadata": {
        "id": "djmgkOokmG-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e88972-2187-42c8-be7f-aab3a0b17574"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "* No team overlap *\n",
            "Iteration:  2\n",
            "* No team overlap *\n",
            "Iteration:  3\n",
            "* No team overlap *\n",
            "Iteration:  4\n",
            "* No team overlap *\n",
            "Iteration:  5\n",
            "* No team overlap *\n",
            "Iteration:  6\n",
            "* No team overlap *\n",
            "Iteration:  7\n",
            "* No team overlap *\n",
            "Iteration:  8\n",
            "* No team overlap *\n",
            "Iteration:  9\n",
            "* No team overlap *\n",
            "Iteration:  10\n",
            "* No team overlap *\n",
            "\n",
            "Number of iterations:  10\n",
            "\n",
            "Iterating through folds_dict_list to check for overlap...\n",
            "* No team overlap *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Garcia model"
      ],
      "metadata": {
        "id": "DsWcvYrnme7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resource: https://www.kaggle.com/code/guidosalimbeni/regression-with-convolutional-neural-network-keras/notebook\n",
        "\n",
        "def get_reg_garcia_model():\n",
        "  # Garcia-Ceja paper feeds CNN images with dims 100 x 100 x 4 (width x height x channels)\n",
        "  # Labels are one hot encoded\n",
        "  inputs = Input(shape=(imgsize[0], imgsize[1], 1))\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(inputs)\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Dense(512, activation=\"relu\")(x) \n",
        "  x = layers.Dropout(0.50)(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(1)(x)\n",
        "\n",
        "  # out = layers.LeakyReLU()(x)\n",
        "  out = layers.Dense(1, activation=\"linear\")(x)   # TODO: Is this the proper output for regression? \"linear\" or \"relu\" or \"sigmoid\" \n",
        "  # https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
        "\n",
        "  lr = 0.0001 # paper used 0.001\n",
        "  eps = 1e-08  # paper used 1e-08, but keras default is 1e-07\n",
        "  adam = keras.optimizers.Adam(learning_rate=lr, epsilon=eps)\n",
        "\n",
        "  mse = tf.keras.metrics.MeanSquaredError()\n",
        "  rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "  mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "  cos_sim = tf.keras.metrics.CosineSimilarity(axis=1)\n",
        "  \n",
        "  model_reg = Model(inputs=inputs, outputs=out)\n",
        "  model_reg.compile(\n",
        "    optimizer=adam,\n",
        "    loss=\"mse\", \n",
        "    metrics=['accuracy', mse, rmse, mae, cos_sim]\n",
        "  )\n",
        "\n",
        "  return model_reg\n",
        "\n",
        "model_reg = get_reg_garcia_model()\n",
        "model_reg.summary()\n"
      ],
      "metadata": {
        "id": "J-efAe-nmhZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fadbf0-0cb9-4fc7-eed1-354ae7156283"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_403\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_404 (InputLayer)      [(None, 359, 359, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_1612 (Conv2D)        (None, 357, 357, 16)      160       \n",
            "                                                                 \n",
            " conv2d_1613 (Conv2D)        (None, 355, 355, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_806 (MaxPooli  (None, 177, 177, 16)     0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_1209 (Dropout)      (None, 177, 177, 16)      0         \n",
            "                                                                 \n",
            " conv2d_1614 (Conv2D)        (None, 175, 175, 32)      4640      \n",
            "                                                                 \n",
            " conv2d_1615 (Conv2D)        (None, 173, 173, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_807 (MaxPooli  (None, 86, 86, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_1210 (Dropout)      (None, 86, 86, 32)        0         \n",
            "                                                                 \n",
            " dense_1209 (Dense)          (None, 86, 86, 512)       16896     \n",
            "                                                                 \n",
            " dropout_1211 (Dropout)      (None, 86, 86, 512)       0         \n",
            "                                                                 \n",
            " flatten_403 (Flatten)       (None, 3786752)           0         \n",
            "                                                                 \n",
            " dense_1210 (Dense)          (None, 1)                 3786753   \n",
            "                                                                 \n",
            " dense_1211 (Dense)          (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,820,019\n",
            "Trainable params: 3,820,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Garcia - Run team-level cross validation"
      ],
      "metadata": {
        "id": "44Je521onVhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store metrics for all iterations\n",
        "maes = []    # MAE (mean absolute errors)\n",
        "mses = []    # MSE (mean squared errors)\n",
        "rmses = []   # RMSE (root mean squared errors)\n",
        "r2s = []     # r2 score\n",
        "corrs = []   # spearman correlations\n",
        "ps = []      # spearman correlation p-values\n",
        "\n",
        "all_y_test_task_score = [[] for i in range(num_iters)]\n",
        "predictions_task_score = [[] for i in range(num_iters)]\n",
        "predict_proba_task_score = [[] for i in range(num_iters)]\n",
        "\n",
        "# For each iteration \n",
        "for i in range(num_iters):\n",
        "    print(\"Iteration: \", i+1)\n",
        "    \n",
        "    # Lists for cumulative predictions for iteration\n",
        "    all_y_test = []\n",
        "    predictions = []\n",
        "    predict_proba = []\n",
        "    \n",
        "    # Get fold groups\n",
        "    fold_groups = folds_dict_list[i]\n",
        "    \n",
        "    # For each fold\n",
        "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
        "        print(\"\\tFold: \", j+1)\n",
        "        # Get data for teams in test set\n",
        "        if normalize:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[test_fold], score_col=\"norm_task_score\", incv3=False)\n",
        "        elif scaled:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[test_fold], score_col=\"scaled_task_score\", incv3=False)\n",
        "        else:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[test_fold], score_col=\"task_score\", incv3=False)\n",
        "        \n",
        "        X_test = plot_list\n",
        "        y_test = labels\n",
        "        all_y_test.extend(y_test.tolist())\n",
        "        \n",
        "        # Get data for teams in train set\n",
        "        if normalize:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[train_fold], score_col=\"norm_task_score\", incv3=False)\n",
        "        elif scaled:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[train_fold], score_col=\"scaled_task_score\", incv3=False)\n",
        "        else:\n",
        "          [plot_list, labels, binary_labels] = get_fold_data(fold_groups[train_fold], score_col=\"task_score\", incv3=False)\n",
        "        \n",
        "        X_train = plot_list\n",
        "        y_train = labels\n",
        "\n",
        "        # Train model\n",
        "        model_reg = get_reg_garcia_model()\n",
        "        # model_reg.summary()\n",
        "        info_reg_cv = model_reg.fit(x=X_train, y=y_train, epochs=num_epochs, verbose=False)\n",
        "\n",
        "        # Test model\n",
        "        y_pp = model_reg.predict(X_test)\n",
        "\n",
        "        predict_proba.extend(y_pp.tolist())\n",
        "        # predictions.extend(y_pred.tolist())\n",
        "\n",
        "    # ----- END OF FOLDS\n",
        "\n",
        "    all_y_test = np.array(all_y_test)\n",
        "    all_y_test_task_score[i] = all_y_test\n",
        "\n",
        "    # predictions = np.squeeze(np.array(predictions))\n",
        "    predict_proba = np.squeeze(np.array(predict_proba))\n",
        "    \n",
        "    # predictions_task_score[i] = predictions\n",
        "    predict_proba_task_score[i] = predict_proba\n",
        "    \n",
        "    \n",
        "    # Calculate the evaluation metrics of the iteration\n",
        "    mae = mean_absolute_error(all_y_test, predict_proba)\n",
        "    mse = mean_squared_error(all_y_test, predict_proba)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(all_y_test, predict_proba)\n",
        "    corr, p = spearmanr(all_y_test, predict_proba)\n",
        "    \n",
        "    maes.append(mae)\n",
        "    mses.append(mse)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "    corrs.append(corr)\n",
        "    ps.append(p)\n",
        "    \n",
        "    # Save actual labels and predictions for iteration\n",
        "    dfTruevPred = pd.DataFrame({'actual': all_y_test, 'predict_proba': predict_proba}) #, 'prediction': predictions})\n",
        "    if shuffled:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"results/shuffled/cross_val/Regression/Garcia_model/\" + image_size + \"/\" + image_size + \"_TaskScore_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\"\n",
        "    else:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"results/cross_val/Regression/Garcia_model/\" + image_size + \"/\" + image_size + \"_TaskScore_True_vs_Pred_\" + str(i+1) + \".csv\"\n",
        "\n",
        "    dfTruevPred.to_csv(ACTvPRED_SAVE_DIR, index=False)    \n",
        "    \n",
        "# ----- END OF ITERATIONS\n",
        "\n",
        "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
        "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], \\\n",
        "                          'mae': maes, 'mse': mses, 'rmse': rmses, 'r2': r2s, 'corrs': corrs, 'ps': ps})\n",
        "\n",
        "display(dfMetrics)\n",
        "\n",
        "if shuffled:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"results/shuffled/cross_val/Regression/Garcia_model/\" + image_size + \"/\" + image_size + \"_TaskScore_Metrics_SHUFF.csv\"\n",
        "else:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"results/cross_val/Regression/Garcia_model/\" + image_size + \"/\" + image_size + \"_TaskScore_Metrics.csv\"\n",
        "dfMetrics.to_csv(METRICS_SAVE_DIR, index=False)   \n",
        "\n",
        "print(\"Averages over all iterations:\")\n",
        "print(\"%6s %.2f\" % (\"MAE:\", np.mean(dfMetrics['mae'])))\n",
        "print(\"%6s %.2f\" % (\"MSE:\", np.mean(dfMetrics['mse'])))\n",
        "print(\"%6s %.2f\" % (\"RMSE:\", np.mean(dfMetrics['rmse'])))\n",
        "print(\"%6s %.2f\" % (\"r2:\", np.mean(dfMetrics['r2'])))\n",
        "print(\"%6s %.2f\" % (\"Corr:\", np.mean(dfMetrics['corrs'])))\n",
        "print(\"%6s %.7f\" % (\"p-val:\", np.mean(dfMetrics['ps'])))\n",
        "\n",
        "print(\"\\n%6s %.2f\" % (\"Med corr:\", np.median(dfMetrics['corrs'])))\n",
        "\n",
        "# Get median iterations\n",
        "med_auroc = np.median(corrs)\n",
        "med_corr_idx = np.argsort(corrs)[len(corrs)//2]\n",
        "print(\"\\nMedian iteration number: \", med_corr_idx+1)\n",
        "\n",
        "# PLOT ACTUAL vs. PREDICTED \n",
        "dfPlot = pd.DataFrame({\"med_y_test\": all_y_test_task_score[med_corr_idx], \"med_predict_proba\": predict_proba_task_score[med_corr_idx]})\n",
        "dfPlot.plot(y=['med_y_test', 'med_predict_proba'], title='Actual vs. Predicted Task Score for Median Model', \\\n",
        "                  style=['b-', 'ro'], figsize=(20, 5))\n",
        "\n",
        "residuals = all_y_test_task_score[med_corr_idx] - predict_proba_task_score[med_corr_idx]\n",
        "sns.distplot(residuals)\n"
      ],
      "metadata": {
        "id": "YPB_BOmNnW1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c5601-30f7-4c62-8f29-f201e1ce4037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "\tFold:  1\n",
            "\tFold:  2\n",
            "\tFold:  3\n",
            "\tFold:  4\n",
            "\tFold:  5\n",
            "\tFold:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Inception v3 model"
      ],
      "metadata": {
        "id": "IGZDDKVXm8bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reg_incv3_model():\n",
        "  # Use InceptionV3 model for feature extraction\n",
        "  ## Resource: http://marubon-ds.blogspot.com/2017/10/inceptionv3-fine-tuning-model.html\n",
        "\n",
        "  new_input = Input(shape=(imgsize[0], imgsize[1], 3)) \n",
        "\n",
        "  pretrained_model = tf.keras.applications.InceptionV3(\n",
        "                    include_top=False,\n",
        "                    weights=\"imagenet\",\n",
        "                    input_tensor=new_input\n",
        "  )\n",
        "\n",
        "  x = pretrained_model.output\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  out = layers.Dense(1, activation=\"linear\")(x)   # TODO: Is this the proper output for regression?\n",
        "\n",
        "\n",
        "  lr = 0.0001 # paper used 0.001\n",
        "  eps = 1e-08   # paper used 1e-08, but keras default is 1e-07\n",
        "  adam = keras.optimizers.Adam(learning_rate=lr, epsilon=eps)\n",
        "\n",
        "  mse = tf.keras.metrics.MeanSquaredError()\n",
        "  rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "  mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "  cos_sim = tf.keras.metrics.CosineSimilarity(axis=1)\n",
        "\n",
        "  # TODO: change metrics for regression\n",
        "  model_pretrained = Model(inputs=new_input, outputs=out)\n",
        "  model_pretrained.compile(\n",
        "    optimizer=adam,\n",
        "    loss=\"mse\", \n",
        "    metrics=['accuracy', mse, rmse, mae, cos_sim]\n",
        "  )\n",
        "\n",
        "  return model_pretrained\n",
        "\n",
        "\n",
        "model_pretrained = get_reg_incv3_model()\n",
        "model_pretrained.summary()\n"
      ],
      "metadata": {
        "id": "qg8y5_8mm_5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}