{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c21e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from keras import layers, Input, Model, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28c3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "imag = io.imread('plots/2069-ExpBlock2_RAW.png')\n",
    "x = image.img_to_array(imag)\n",
    "\n",
    "n = preprocess_input(x)    # preprocess input for Inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34e98a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read, preprocess, and scale images to uniform dimension\n",
    "imgsize = (719, 719)    \n",
    "def extract_image(image_path):\n",
    "    imag = io.imread(image_path)\n",
    "    x = image.img_to_array(imag)\n",
    "\n",
    "    x = tf.keras.preprocessing.image.smart_resize(x, imgsize)\n",
    "    \n",
    "    n = preprocess_input(x)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6425ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = extract_image('plots/2069-ExpBlock2_RAW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea661349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 719, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(719, 719, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9694721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use InceptionV3 model for feature extraction\n",
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(None, None, 3),\n",
    "    pooling='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cabea1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 719, 719, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_314 (Conv2D)         (None, 717, 717, 16)      160       \n",
      "                                                                 \n",
      " conv2d_315 (Conv2D)         (None, 715, 715, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 357, 357, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 357, 357, 16)      0         \n",
      "                                                                 \n",
      " conv2d_316 (Conv2D)         (None, 355, 355, 32)      4640      \n",
      "                                                                 \n",
      " conv2d_317 (Conv2D)         (None, 353, 353, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 176, 176, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 176, 176, 32)      0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 176, 176, 512)     16896     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 176, 176, 512)     0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 176, 176, 1)       513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,777\n",
      "Trainable params: 33,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Garcia-Ceja paper feeds CNN images with dims 200 x 100 x 4 (width x height x channels)\n",
    "# Labels are one hot encoded\n",
    "\n",
    "inputs = Input(shape=(719, 719, 1))\n",
    "x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x) \n",
    "x = layers.Dropout(0.50)(x)\n",
    "out = layers.Dense(1)(x) \n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss=tf.keras.losses.MeanSquaredError(),  \n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26cd118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
