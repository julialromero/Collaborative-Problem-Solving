{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a48addfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "import shap \n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8de4c",
   "metadata": {},
   "source": [
    "# Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df414ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURES_FILE = \"MdRQA_measures.csv\"\n",
    "SHUFF_MEASURES_FILE = \"shuff_MdRQA_measures.csv\"\n",
    "LABELS_FILE = \"team_block_outcomes.csv\"\n",
    "TASK_SCORE_RESULTS = \"results/task_score/\"\n",
    "SUBJ_OUTCOME_RESULTS = \"results/subjective_outcome/\"\n",
    "VALENCE_RESULTS = \"results/valence/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084f123",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2951565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MdRQA_measures.csv shape: (271, 11)\n",
      "shuff_MdRQA_measures.csv shape: (271, 11)\n",
      "team_block_outcomes.csv shape: (274, 7)\n"
     ]
    }
   ],
   "source": [
    "dfMeasures = pd.read_csv(MEASURES_FILE)\n",
    "dfShuffMeasures = pd.read_csv(SHUFF_MEASURES_FILE)\n",
    "dfLabels = pd.read_csv(LABELS_FILE)\n",
    "\n",
    "print(\"%s shape: %s\" % (MEASURES_FILE, dfMeasures.shape))\n",
    "print(\"%s shape: %s\" % (SHUFF_MEASURES_FILE, dfShuffMeasures.shape))\n",
    "print(\"%s shape: %s\" % (LABELS_FILE, dfLabels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5bed641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['REC', 'DET', 'ADL', 'MDL', 'DENTR', 'LAM', 'AVL', 'MVL', 'VENTR']\n",
    "\n",
    "\n",
    "def get_group_data(dfData, GROUPID_list, features_list, label_names):\n",
    "    dfGroupsData = pd.DataFrame()    \n",
    "    for GROUPID in GROUPID_list:\n",
    "        dfGroupsData = pd.concat([dfGroupsData, dfData.loc[dfData['GROUPID'] == GROUPID, :]], ignore_index=True)\n",
    "        \n",
    "    data = dfGroupsData.loc[:, features_list]  \n",
    "    labels = dfGroupsData.loc[:, label_names]\n",
    "\n",
    "    return [data, labels, dfGroupsData]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7980252",
   "metadata": {},
   "source": [
    "# Experiment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9e0b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfData shape:  (271, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUPID</th>\n",
       "      <th>block</th>\n",
       "      <th>REC</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADL</th>\n",
       "      <th>MDL</th>\n",
       "      <th>DENTR</th>\n",
       "      <th>LAM</th>\n",
       "      <th>AVL</th>\n",
       "      <th>MVL</th>\n",
       "      <th>VENTR</th>\n",
       "      <th>CPS_and_ITN_mean</th>\n",
       "      <th>Valence</th>\n",
       "      <th>num_gold</th>\n",
       "      <th>num_silver</th>\n",
       "      <th>task_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>ExpBlock1</td>\n",
       "      <td>0.111890</td>\n",
       "      <td>46.765002</td>\n",
       "      <td>2.580148</td>\n",
       "      <td>12</td>\n",
       "      <td>8.031479</td>\n",
       "      <td>63.476117</td>\n",
       "      <td>3.202765</td>\n",
       "      <td>8</td>\n",
       "      <td>8.276899</td>\n",
       "      <td>-0.413762</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>ExpBlock2</td>\n",
       "      <td>0.221818</td>\n",
       "      <td>51.941830</td>\n",
       "      <td>2.801763</td>\n",
       "      <td>13</td>\n",
       "      <td>8.693110</td>\n",
       "      <td>71.437617</td>\n",
       "      <td>3.567544</td>\n",
       "      <td>14</td>\n",
       "      <td>8.801583</td>\n",
       "      <td>0.662988</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10100</td>\n",
       "      <td>ExpBlock1</td>\n",
       "      <td>0.469005</td>\n",
       "      <td>68.603876</td>\n",
       "      <td>3.236574</td>\n",
       "      <td>27</td>\n",
       "      <td>9.502080</td>\n",
       "      <td>83.376781</td>\n",
       "      <td>4.480822</td>\n",
       "      <td>28</td>\n",
       "      <td>9.315484</td>\n",
       "      <td>-0.780143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10100</td>\n",
       "      <td>ExpBlock2</td>\n",
       "      <td>0.328632</td>\n",
       "      <td>63.319890</td>\n",
       "      <td>3.373809</td>\n",
       "      <td>34</td>\n",
       "      <td>8.995863</td>\n",
       "      <td>78.390610</td>\n",
       "      <td>4.336822</td>\n",
       "      <td>35</td>\n",
       "      <td>8.899755</td>\n",
       "      <td>-0.290702</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10102</td>\n",
       "      <td>ExpBlock1</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>40.010880</td>\n",
       "      <td>2.781595</td>\n",
       "      <td>16</td>\n",
       "      <td>8.650819</td>\n",
       "      <td>60.603101</td>\n",
       "      <td>3.351069</td>\n",
       "      <td>15</td>\n",
       "      <td>8.895810</td>\n",
       "      <td>0.425265</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>2070</td>\n",
       "      <td>ExpBlock2</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>35.135661</td>\n",
       "      <td>2.392715</td>\n",
       "      <td>9</td>\n",
       "      <td>7.967704</td>\n",
       "      <td>59.342180</td>\n",
       "      <td>2.886733</td>\n",
       "      <td>9</td>\n",
       "      <td>8.447403</td>\n",
       "      <td>0.328772</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2070</td>\n",
       "      <td>Warmup</td>\n",
       "      <td>0.411115</td>\n",
       "      <td>49.651775</td>\n",
       "      <td>2.839304</td>\n",
       "      <td>42</td>\n",
       "      <td>9.178902</td>\n",
       "      <td>70.710415</td>\n",
       "      <td>3.726037</td>\n",
       "      <td>43</td>\n",
       "      <td>9.143787</td>\n",
       "      <td>-0.627717</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2071</td>\n",
       "      <td>ExpBlock1</td>\n",
       "      <td>0.291773</td>\n",
       "      <td>45.826191</td>\n",
       "      <td>2.544979</td>\n",
       "      <td>11</td>\n",
       "      <td>8.971522</td>\n",
       "      <td>68.343464</td>\n",
       "      <td>3.244426</td>\n",
       "      <td>12</td>\n",
       "      <td>9.145826</td>\n",
       "      <td>-0.568987</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2071</td>\n",
       "      <td>ExpBlock2</td>\n",
       "      <td>0.188310</td>\n",
       "      <td>46.079278</td>\n",
       "      <td>2.572276</td>\n",
       "      <td>16</td>\n",
       "      <td>8.522221</td>\n",
       "      <td>66.710627</td>\n",
       "      <td>3.169010</td>\n",
       "      <td>17</td>\n",
       "      <td>8.746838</td>\n",
       "      <td>-0.255739</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2071</td>\n",
       "      <td>Warmup</td>\n",
       "      <td>0.268505</td>\n",
       "      <td>43.939464</td>\n",
       "      <td>2.533835</td>\n",
       "      <td>10</td>\n",
       "      <td>8.857327</td>\n",
       "      <td>67.339723</td>\n",
       "      <td>3.216277</td>\n",
       "      <td>11</td>\n",
       "      <td>9.076562</td>\n",
       "      <td>0.243474</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GROUPID      block       REC        DET       ADL  MDL     DENTR  \\\n",
       "0       1010  ExpBlock1  0.111890  46.765002  2.580148   12  8.031479   \n",
       "1       1010  ExpBlock2  0.221818  51.941830  2.801763   13  8.693110   \n",
       "2      10100  ExpBlock1  0.469005  68.603876  3.236574   27  9.502080   \n",
       "3      10100  ExpBlock2  0.328632  63.319890  3.373809   34  8.995863   \n",
       "4      10102  ExpBlock1  0.275806  40.010880  2.781595   16  8.650819   \n",
       "..       ...        ...       ...        ...       ...  ...       ...   \n",
       "266     2070  ExpBlock2  0.128570  35.135661  2.392715    9  7.967704   \n",
       "267     2070     Warmup  0.411115  49.651775  2.839304   42  9.178902   \n",
       "268     2071  ExpBlock1  0.291773  45.826191  2.544979   11  8.971522   \n",
       "269     2071  ExpBlock2  0.188310  46.079278  2.572276   16  8.522221   \n",
       "270     2071     Warmup  0.268505  43.939464  2.533835   10  8.857327   \n",
       "\n",
       "           LAM       AVL  MVL     VENTR  CPS_and_ITN_mean   Valence  num_gold  \\\n",
       "0    63.476117  3.202765    8  8.276899         -0.413762  3.666667       1.0   \n",
       "1    71.437617  3.567544   14  8.801583          0.662988  5.000000       3.0   \n",
       "2    83.376781  4.480822   28  9.315484         -0.780143  2.666667       0.0   \n",
       "3    78.390610  4.336822   35  8.899755         -0.290702  3.000000       0.0   \n",
       "4    60.603101  3.351069   15  8.895810          0.425265  3.000000       0.0   \n",
       "..         ...       ...  ...       ...               ...       ...       ...   \n",
       "266  59.342180  2.886733    9  8.447403          0.328772  3.666667       1.0   \n",
       "267  70.710415  3.726037   43  9.143787         -0.627717  3.666667       5.0   \n",
       "268  68.343464  3.244426   12  9.145826         -0.568987  3.000000       0.0   \n",
       "269  66.710627  3.169010   17  8.746838         -0.255739  3.666667       0.0   \n",
       "270  67.339723  3.216277   11  9.076562          0.243474  3.666667       0.0   \n",
       "\n",
       "     num_silver  task_score  \n",
       "0           2.0         4.0  \n",
       "1           2.0         8.0  \n",
       "2           0.0         0.0  \n",
       "3           1.0         1.0  \n",
       "4           1.0         1.0  \n",
       "..          ...         ...  \n",
       "266         1.0         3.0  \n",
       "267         3.0        13.0  \n",
       "268         0.0         0.0  \n",
       "269         0.0         0.0  \n",
       "270         1.0         1.0  \n",
       "\n",
       "[271 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get model type\n",
    "shuffled = False\n",
    "chance = False\n",
    "num_iters = 25\n",
    "num_folds = 10\n",
    "model = \"RFR\"\n",
    "\n",
    "if shuffled:\n",
    "    dfData = pd.merge(dfShuffMeasures, dfLabels, on=['GROUPID', 'block'], how='inner')\n",
    "    # Drop rows with NaN for ADL or AVL\n",
    "    dfData = dfData.dropna()\n",
    "elif chance:\n",
    "    dfData = pd.merge(dfMeasures, dfLabels, on=['GROUPID', 'block'], how='inner')\n",
    "    # Shuffle labels\n",
    "    label_cols = ['CPS_and_ITN_mean', 'Valence', 'num_gold', 'num_silver', 'task_score']\n",
    "    dfData.loc[:, label_cols] = shuffle(dfData.loc[:, label_cols], random_state=12).reset_index(drop=True)\n",
    "else:\n",
    "    dfData = pd.merge(dfMeasures, dfLabels, on=['GROUPID', 'block'], how='inner')\n",
    "\n",
    "\n",
    "print(\"dfData shape: \", dfData.shape)\n",
    "display(dfData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0743a",
   "metadata": {},
   "source": [
    "## Prep for team-level cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "930a0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "* No team overlap *\n",
      "Iteration:  2\n",
      "* No team overlap *\n",
      "Iteration:  3\n",
      "* No team overlap *\n",
      "Iteration:  4\n",
      "* No team overlap *\n",
      "Iteration:  5\n",
      "* No team overlap *\n",
      "Iteration:  6\n",
      "* No team overlap *\n",
      "Iteration:  7\n",
      "* No team overlap *\n",
      "Iteration:  8\n",
      "* No team overlap *\n",
      "Iteration:  9\n",
      "* No team overlap *\n",
      "Iteration:  10\n",
      "* No team overlap *\n",
      "Iteration:  11\n",
      "* No team overlap *\n",
      "Iteration:  12\n",
      "* No team overlap *\n",
      "Iteration:  13\n",
      "* No team overlap *\n",
      "Iteration:  14\n",
      "* No team overlap *\n",
      "Iteration:  15\n",
      "* No team overlap *\n",
      "Iteration:  16\n",
      "* No team overlap *\n",
      "Iteration:  17\n",
      "* No team overlap *\n",
      "Iteration:  18\n",
      "* No team overlap *\n",
      "Iteration:  19\n",
      "* No team overlap *\n",
      "Iteration:  20\n",
      "* No team overlap *\n",
      "Iteration:  21\n",
      "* No team overlap *\n",
      "Iteration:  22\n",
      "* No team overlap *\n",
      "Iteration:  23\n",
      "* No team overlap *\n",
      "Iteration:  24\n",
      "* No team overlap *\n",
      "Iteration:  25\n",
      "* No team overlap *\n",
      "\n",
      "Number of iterations:  25\n",
      "\n",
      "Iterating through folds_dict_list to check for overlap...\n",
      "* No team overlap *\n"
     ]
    }
   ],
   "source": [
    "# Define fold names\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "set_type = \"test\"\n",
    "for j in range(1,num_folds+1): \n",
    "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
    "    test_folds.append(col_name)\n",
    "    set_type = \"train\"  \n",
    "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
    "    train_folds.append(col_name)\n",
    "    set_type = \"test\"\n",
    "\n",
    "folds_dict_list = []\n",
    "\n",
    "# Split teams into 5 groups\n",
    "teams = pd.unique(dfMeasures.GROUPID)\n",
    "\n",
    "# For every iteration\n",
    "for i in range(1,num_iters+1):\n",
    "    print(\"Iteration: \", i)\n",
    "    teams = shuffle(teams, random_state=i)\n",
    "    groups = np.array_split(teams, num_folds)\n",
    "    \n",
    "    # Define groups for each fold\n",
    "    fold_groups = {}\n",
    "    for j, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
    "        # make the current group the test group\n",
    "        fold_groups[test_fold] = groups[j]\n",
    "        # make all other groups the train group\n",
    "        train_group = groups[:j] + groups[j+1:]\n",
    "        train_group = [team for group in train_group for team in group]\n",
    "        fold_groups[train_fold] = train_group\n",
    "        \n",
    "    ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
    "    for j in range(1,num_folds+1):\n",
    "        assert set(fold_groups['Fold'+str(j)+'_test']).isdisjoint(set(fold_groups['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
    "    \n",
    "    print(\"* No team overlap *\")\n",
    "\n",
    "      \n",
    "    # Add fold groups to dictionary\n",
    "    folds_dict_list.append(fold_groups)\n",
    "    \n",
    "\n",
    "# Informational\n",
    "print(\"\\nNumber of iterations: \", len(folds_dict_list))\n",
    "\n",
    "print(\"\\nIterating through folds_dict_list to check for overlap...\")\n",
    "for i,dicti in enumerate(folds_dict_list):\n",
    "    for j in range(1,num_folds+1):\n",
    "        assert set(dicti['Fold'+str(j)+'_test']).isdisjoint(set(dicti['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
    "    \n",
    "print(\"* No team overlap *\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a614206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Define fold names\n",
    "# train_folds = []\n",
    "# test_folds = []\n",
    "# set_type = \"test\"\n",
    "# for j in range(1,num_folds+1): \n",
    "#     col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
    "#     test_folds.append(col_name)\n",
    "#     set_type = \"train\"  \n",
    "#     col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
    "#     train_folds.append(col_name)\n",
    "#     set_type = \"test\"\n",
    "\n",
    "# # print(\"Train fold names: \", train_folds)\n",
    "# # print(\"Test fold names: \",test_folds)\n",
    "\n",
    "\n",
    "# folds_dict_list = []\n",
    "\n",
    "# # Split teams into 5 groups\n",
    "# teams = pd.unique(dfMeasures.GROUPID)\n",
    "\n",
    "# # For every iteration\n",
    "# for i in range(1,num_iters+1):\n",
    "#     print(\"\\n\\n=============Iteration: \", i)\n",
    "#     random.Random(i).shuffle(teams)\n",
    "\n",
    "# #     teams = shuffle(teams, random_state=i)\n",
    "\n",
    "#     groups = np.array_split(teams, num_folds)\n",
    "#     print(\"\\ngroups: \")\n",
    "#     for k,grp in enumerate(groups):\n",
    "#         print(k, grp)\n",
    "    \n",
    "#     # Define groups for each fold\n",
    "#     fold_groups = {}\n",
    "#     for j, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
    "#         # make the current group the test group\n",
    "#         fold_groups[test_fold] = groups[j]\n",
    "#         # make all other groups the train group\n",
    "#         train_group = groups[:j] + groups[j+1:]\n",
    "#         train_group = [team for group in train_group for team in group]\n",
    "#         fold_groups[train_fold] = train_group\n",
    "        \n",
    "#     ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
    "#     for j in range(1,num_folds+1):\n",
    "#         assert set(fold_groups['Fold'+str(j)+'_test']).isdisjoint(set(fold_groups['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
    "    \n",
    "#     print(\"* No team overlap *\")\n",
    "    \n",
    "#     print(\"\\n!!!!! FOLD GROUPS BEFORE IT GOES BAD\")\n",
    "#     for kei in fold_groups:\n",
    "#         print(\"\\n\", kei)\n",
    "#         print(fold_groups[kei])\n",
    "\n",
    "        \n",
    "#     if i == 2:\n",
    "#         print(\"\\n BEFORE APPEND folds_dict_list[i-2] index = \", i-2)\n",
    "#         folds_dict = folds_dict_list[i-2]\n",
    "#         for key in folds_dict:\n",
    "#             print(\"\\n\", key)\n",
    "#             print(folds_dict[key])\n",
    "      \n",
    "#     # Add fold groups to dictionary\n",
    "#     folds_dict_list.append(fold_groups)\n",
    "    \n",
    "#     if i == 2:\n",
    "#         print(\"\\n AFTER APPEND folds_dict_list[i-2] index = \", i-2)\n",
    "#         folds_dict = folds_dict_list[i-2]\n",
    "#         for key in folds_dict:\n",
    "#             print(\"\\n\", key)\n",
    "#             print(folds_dict[key])   \n",
    "\n",
    "# # Informational\n",
    "# # print(\"\\nNumber of iterations: \", len(folds_dict_list))\n",
    "\n",
    "# print(\"\\n*~*~*~*~*~* iterate through folds_dict_list: \")\n",
    "# for i,dicti in enumerate(folds_dict_list):\n",
    "#     print(\"\\n list index: \", i)\n",
    "#     for j in range(1,num_folds+1):\n",
    "#         assert set(dicti['Fold'+str(j)+'_test']).isdisjoint(set(dicti['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a648fe",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68389051",
   "metadata": {},
   "source": [
    "## Predict Task Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "745c66e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "\n",
      " =========== ALL ITERATIONS RESULTS SUMMARY ===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>corrs</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.578229</td>\n",
       "      <td>11.132506</td>\n",
       "      <td>3.336541</td>\n",
       "      <td>0.325886</td>\n",
       "      <td>4.006128e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.614317</td>\n",
       "      <td>11.453538</td>\n",
       "      <td>3.384308</td>\n",
       "      <td>0.312814</td>\n",
       "      <td>1.453738e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.598598</td>\n",
       "      <td>11.139976</td>\n",
       "      <td>3.337660</td>\n",
       "      <td>0.308911</td>\n",
       "      <td>2.111163e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.575904</td>\n",
       "      <td>11.104554</td>\n",
       "      <td>3.332350</td>\n",
       "      <td>0.346134</td>\n",
       "      <td>4.808016e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.639483</td>\n",
       "      <td>11.736855</td>\n",
       "      <td>3.425909</td>\n",
       "      <td>0.334542</td>\n",
       "      <td>1.649056e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.688819</td>\n",
       "      <td>11.907335</td>\n",
       "      <td>3.450701</td>\n",
       "      <td>0.297437</td>\n",
       "      <td>6.128237e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2.655830</td>\n",
       "      <td>11.374772</td>\n",
       "      <td>3.372651</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>2.268048e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.682952</td>\n",
       "      <td>12.048705</td>\n",
       "      <td>3.471124</td>\n",
       "      <td>0.284311</td>\n",
       "      <td>1.962453e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.597306</td>\n",
       "      <td>11.256963</td>\n",
       "      <td>3.355140</td>\n",
       "      <td>0.333423</td>\n",
       "      <td>1.852329e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2.586974</td>\n",
       "      <td>11.304858</td>\n",
       "      <td>3.362270</td>\n",
       "      <td>0.334956</td>\n",
       "      <td>1.579365e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.554133</td>\n",
       "      <td>10.904587</td>\n",
       "      <td>3.302209</td>\n",
       "      <td>0.366913</td>\n",
       "      <td>4.637980e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.701919</td>\n",
       "      <td>12.266092</td>\n",
       "      <td>3.502298</td>\n",
       "      <td>0.283066</td>\n",
       "      <td>2.184883e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.642731</td>\n",
       "      <td>11.793052</td>\n",
       "      <td>3.434101</td>\n",
       "      <td>0.297725</td>\n",
       "      <td>5.970284e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2.584871</td>\n",
       "      <td>11.179647</td>\n",
       "      <td>3.343598</td>\n",
       "      <td>0.341152</td>\n",
       "      <td>8.216535e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2.598413</td>\n",
       "      <td>11.416181</td>\n",
       "      <td>3.378784</td>\n",
       "      <td>0.336614</td>\n",
       "      <td>1.327872e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2.656531</td>\n",
       "      <td>11.825753</td>\n",
       "      <td>3.438859</td>\n",
       "      <td>0.312206</td>\n",
       "      <td>1.541317e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2.545535</td>\n",
       "      <td>10.684900</td>\n",
       "      <td>3.268776</td>\n",
       "      <td>0.365078</td>\n",
       "      <td>5.741056e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2.533616</td>\n",
       "      <td>10.751048</td>\n",
       "      <td>3.278879</td>\n",
       "      <td>0.363216</td>\n",
       "      <td>7.119149e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2.721476</td>\n",
       "      <td>12.280051</td>\n",
       "      <td>3.504290</td>\n",
       "      <td>0.267805</td>\n",
       "      <td>7.816118e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2.661255</td>\n",
       "      <td>11.749113</td>\n",
       "      <td>3.427698</td>\n",
       "      <td>0.289161</td>\n",
       "      <td>1.285273e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2.605166</td>\n",
       "      <td>11.327709</td>\n",
       "      <td>3.365666</td>\n",
       "      <td>0.317518</td>\n",
       "      <td>9.207052e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2.605092</td>\n",
       "      <td>11.092108</td>\n",
       "      <td>3.330482</td>\n",
       "      <td>0.330477</td>\n",
       "      <td>2.510592e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2.648487</td>\n",
       "      <td>11.713633</td>\n",
       "      <td>3.422519</td>\n",
       "      <td>0.299059</td>\n",
       "      <td>5.285946e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>2.631587</td>\n",
       "      <td>11.561856</td>\n",
       "      <td>3.400273</td>\n",
       "      <td>0.313606</td>\n",
       "      <td>1.346945e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2.628044</td>\n",
       "      <td>11.459004</td>\n",
       "      <td>3.385115</td>\n",
       "      <td>0.317407</td>\n",
       "      <td>9.307768e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration       mae        mse      rmse     corrs            ps\n",
       "0           1  2.578229  11.132506  3.336541  0.325886  4.006128e-08\n",
       "1           2  2.614317  11.453538  3.384308  0.312814  1.453738e-07\n",
       "2           3  2.598598  11.139976  3.337660  0.308911  2.111163e-07\n",
       "3           4  2.575904  11.104554  3.332350  0.346134  4.808016e-09\n",
       "4           5  2.639483  11.736855  3.425909  0.334542  1.649056e-08\n",
       "5           6  2.688819  11.907335  3.450701  0.297437  6.128237e-07\n",
       "6           7  2.655830  11.374772  3.372651  0.331465  2.268048e-08\n",
       "7           8  2.682952  12.048705  3.471124  0.284311  1.962453e-06\n",
       "8           9  2.597306  11.256963  3.355140  0.333423  1.852329e-08\n",
       "9          10  2.586974  11.304858  3.362270  0.334956  1.579365e-08\n",
       "10         11  2.554133  10.904587  3.302209  0.366913  4.637980e-10\n",
       "11         12  2.701919  12.266092  3.502298  0.283066  2.184883e-06\n",
       "12         13  2.642731  11.793052  3.434101  0.297725  5.970284e-07\n",
       "13         14  2.584871  11.179647  3.343598  0.341152  8.216535e-09\n",
       "14         15  2.598413  11.416181  3.378784  0.336614  1.327872e-08\n",
       "15         16  2.656531  11.825753  3.438859  0.312206  1.541317e-07\n",
       "16         17  2.545535  10.684900  3.268776  0.365078  5.741056e-10\n",
       "17         18  2.533616  10.751048  3.278879  0.363216  7.119149e-10\n",
       "18         19  2.721476  12.280051  3.504290  0.267805  7.816118e-06\n",
       "19         20  2.661255  11.749113  3.427698  0.289161  1.285273e-06\n",
       "20         21  2.605166  11.327709  3.365666  0.317518  9.207052e-08\n",
       "21         22  2.605092  11.092108  3.330482  0.330477  2.510592e-08\n",
       "22         23  2.648487  11.713633  3.422519  0.299059  5.285946e-07\n",
       "23         24  2.631587  11.561856  3.400273  0.313606  1.346945e-07\n",
       "24         25  2.628044  11.459004  3.385115  0.317407  9.307768e-08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all iterations:\n",
      "  MAE: 2.62\n",
      "  MSE: 11.46\n",
      " RMSE: 3.38\n",
      " Corr: 0.32\n",
      "p-val: 0.0000006\n"
     ]
    }
   ],
   "source": [
    "# Resources\n",
    "## https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "# Store metrics for all iterations\n",
    "maes = []    # MAE (mean absolute errors)\n",
    "mses = []    # MSE (mean squared errors)\n",
    "rmses = []   # RMSE (root mean squared errors)\n",
    "corrs = []   # spearman correlations\n",
    "ps = []      # spearman correlation p-values\n",
    "\n",
    "all_y_test_task_score = [[] for i in range(num_iters)]\n",
    "predictions_task_score = [[] for i in range(num_iters)]\n",
    "predict_proba_task_score = [[] for i in range(num_iters)]\n",
    "\n",
    "# For storing shap values across all folds\n",
    "task_score_shap_values_0 = None\n",
    "task_score_shap_values_1 = None\n",
    "task_score_full_X_test = pd.DataFrame()\n",
    "\n",
    "#-----------------------------------------------#\n",
    "#      5-fold team level cross-validation       #\n",
    "#-----------------------------------------------#\n",
    "\n",
    "# For each iteration \n",
    "for i in range(num_iters):\n",
    "    print(\"Iteration: \", i+1)\n",
    "    \n",
    "    # Lists for cumulative test set and predictions for iteration\n",
    "    dfFullTest = pd.DataFrame()\n",
    "    all_y_test = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Create model for task_score prediction\n",
    "    if model == \"RFR\":\n",
    "        model_task_score = RandomForestRegressor(n_estimators=100, random_state=1, max_features='sqrt') \n",
    "\n",
    "    elif model == \"SVR\":\n",
    "        model_task_score = SVR()\n",
    "    \n",
    "    \n",
    "    # Get fold groups\n",
    "    fold_groups = folds_dict_list[i]\n",
    "    \n",
    "    # For each fold\n",
    "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
    "#         print(\"\\tFold: \", j+1)\n",
    "        # Get data for teams in test set\n",
    "        test_data_list = get_group_data(dfData, fold_groups[test_fold], features, 'task_score')\n",
    "        X_test = test_data_list[0]\n",
    "        y_test = test_data_list[1]\n",
    "        all_y_test.extend(y_test.tolist())\n",
    "\n",
    "        dfFullTest = pd.concat([dfFullTest, test_data_list[2]], ignore_index=True)      \n",
    "        \n",
    "        # Get data for teams in train set\n",
    "        train_data_list = get_group_data(dfData, fold_groups[train_fold], features, 'task_score')\n",
    "        X_train = train_data_list[0]\n",
    "        y_train = train_data_list[1]\n",
    "\n",
    "        # Train model\n",
    "        model_task_score.fit(X_train, y_train)\n",
    "\n",
    "        # Test model\n",
    "        y_pred = model_task_score.predict(X_test)\n",
    "        predictions.extend(y_pred.tolist())\n",
    "        \n",
    "#         ## Get SHAP values\n",
    "#         explainer = shap.TreeExplainer(model_task_scorerfc_task_score)\n",
    "#         shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "#         if j==0:\n",
    "#             task_score_shap_values_0 = shap_values[0]\n",
    "#             task_score_shap_values_1 = shap_values[1]\n",
    "#         else:\n",
    "#             task_score_shap_values_0 = np.vstack([task_score_shap_values_0, shap_values[0]])\n",
    "#             task_score_shap_values_1 = np.vstack([task_score_shap_values_1, shap_values[1]])\n",
    "#         task_score_full_X_test = pd.concat([task_score_full_X_test, X_test], ignore_index=True)\n",
    "#         ## End of get SHAP values\n",
    "\n",
    "# ----- END OF FOLDS\n",
    "    \n",
    "    all_y_test = np.array(all_y_test)\n",
    "    all_y_test_task_score[i] = all_y_test\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    predictions_task_score[i] = predictions\n",
    "\n",
    "    # Calculate the absolute errors (MAE) of the iteration\n",
    "    mae = metrics.mean_absolute_error(all_y_test, predictions)\n",
    "    mse = metrics.mean_squared_error(all_y_test, predictions)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(all_y_test, predictions))\n",
    "    corr, p = spearmanr(all_y_test, predictions)\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "    corrs.append(corr)\n",
    "    ps.append(p)\n",
    "\n",
    "     # Save actual labels and predictions for iteration\n",
    "    dfTruevPred = dfFullTest.loc[:, ['GROUPID', 'block', 'task_score']]\n",
    "    dfTruevPred['prediction'] = predictions\n",
    "    dfTruevPred.sort_values(['GROUPID', 'block', 'task_score'], ignore_index=True, inplace=True)\n",
    "\n",
    "    dfTruevPred['error'] = abs(dfTruevPred['prediction'] - dfTruevPred['task_score'])\n",
    "#     print(\"MAE from df: \", round(np.mean(dfTruevPred['error']), 2))\n",
    "#     # FOR PLOTTING ACTUAL vs. PREDICTED   \n",
    "#     dfTruevPred.plot(y=['task_score', 'prediction'], title='Actual vs. Predicted Task Score', \\\n",
    "#                      style=['b-', 'ro'], figsize=(20, 5))\n",
    "#     # END PLOTTING\n",
    "        \n",
    "    \n",
    "    if shuffled:\n",
    "        dfTruevPred.to_csv(TASK_SCORE_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_TaskScore_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\", index=False)\n",
    "    elif chance:\n",
    "        dfTruevPred.to_csv(TASK_SCORE_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_TaskScore_True_vs_Pred_CHANCE_\" + str(i+1) + \".csv\", index=False)\n",
    "    else:\n",
    "        dfTruevPred.to_csv(TASK_SCORE_RESULTS + \"RAW/\" + model + \"/\" + model + \"_TaskScore_True_vs_Pred_\" + str(i+1) + \".csv\", index=False)\n",
    "  \n",
    "\n",
    "    \n",
    "#     if model == \"RFR\":    \n",
    "#         ### Compute Feature Importances for last fold iteration ###\n",
    "#         # Impurity-based importances\n",
    "#         importances = model_task_score.feature_importances_\n",
    "#         std = np.std([tree.feature_importances_ for tree in model_task_score.estimators_], axis=0)\n",
    "#         imps = pd.Series(importances, index=features)\n",
    "#         stds = pd.Series(std, index=features)\n",
    "#         ## Plot feature importances\n",
    "#         fig1, ax1 = plt.subplots()\n",
    "#         imps.plot.bar(yerr=std, ax=ax1)\n",
    "#         ax1.set_title(\"Task Score Feature importances using MDI\")\n",
    "#         ax1.set_ylabel(\"Mean decrease in impurity\")\n",
    "#         plt.show()\n",
    "#         ## END plotting feature importances\n",
    "    \n",
    "    \n",
    "# ----- END OF ITERATIONS\n",
    "\n",
    "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
    "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], \\\n",
    "                          'mae': maes, 'mse': mses, 'rmse': rmses, 'corrs': corrs, 'ps': ps})\n",
    "\n",
    "display(dfMetrics)\n",
    "\n",
    "if shuffled:\n",
    "    dfMetrics.to_csv(TASK_SCORE_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_TaskScore_Metrics_SHUFF.csv\", index=False)\n",
    "elif chance:\n",
    "    dfMetrics.to_csv(TASK_SCORE_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_TaskScore_Metrics_CHANCE.csv\", index=False)\n",
    "else:\n",
    "    dfMetrics.to_csv(TASK_SCORE_RESULTS + \"RAW/\" + model + \"/\" + model + \"_TaskScore_Metrics.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Average over all iterations:\")\n",
    "print(\"%6s %.2f\" % (\"MAE:\", np.mean(dfMetrics['mae'])))\n",
    "print(\"%6s %.2f\" % (\"MSE:\", np.mean(dfMetrics['mse'])))\n",
    "print(\"%6s %.2f\" % (\"RMSE:\", np.mean(dfMetrics['rmse'])))\n",
    "print(\"%6s %.2f\" % (\"Corr:\", np.mean(dfMetrics['corrs'])))\n",
    "print(\"%6s %.7f\" % (\"p-val:\", np.mean(dfMetrics['ps'])))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe617ac5",
   "metadata": {},
   "source": [
    "# Predict Subjective Outcome (combined CPS and ITN score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1272b86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "\n",
      " =========== ALL ITERATIONS RESULTS SUMMARY ===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>corrs</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.448270</td>\n",
       "      <td>0.323950</td>\n",
       "      <td>0.569166</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>0.895847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440088</td>\n",
       "      <td>0.315805</td>\n",
       "      <td>0.561966</td>\n",
       "      <td>0.061461</td>\n",
       "      <td>0.313430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.450520</td>\n",
       "      <td>0.323464</td>\n",
       "      <td>0.568739</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>0.957569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.443326</td>\n",
       "      <td>0.323420</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>0.856580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.441004</td>\n",
       "      <td>0.319461</td>\n",
       "      <td>0.565209</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.936162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.434989</td>\n",
       "      <td>0.315003</td>\n",
       "      <td>0.561251</td>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.316642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.437171</td>\n",
       "      <td>0.313981</td>\n",
       "      <td>0.560340</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>0.721585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.446004</td>\n",
       "      <td>0.323601</td>\n",
       "      <td>0.568860</td>\n",
       "      <td>-0.010053</td>\n",
       "      <td>0.869155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.447429</td>\n",
       "      <td>0.327646</td>\n",
       "      <td>0.572403</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.960564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.455344</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>0.577887</td>\n",
       "      <td>-0.034057</td>\n",
       "      <td>0.576694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.442656</td>\n",
       "      <td>0.317219</td>\n",
       "      <td>0.563222</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.896761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.443296</td>\n",
       "      <td>0.321188</td>\n",
       "      <td>0.566734</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.809344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.448804</td>\n",
       "      <td>0.319055</td>\n",
       "      <td>0.564849</td>\n",
       "      <td>-0.007011</td>\n",
       "      <td>0.908538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.453329</td>\n",
       "      <td>0.330907</td>\n",
       "      <td>0.575245</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>0.794304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.451492</td>\n",
       "      <td>0.328705</td>\n",
       "      <td>0.573328</td>\n",
       "      <td>-0.020497</td>\n",
       "      <td>0.736944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.451995</td>\n",
       "      <td>0.328429</td>\n",
       "      <td>0.573087</td>\n",
       "      <td>-0.026769</td>\n",
       "      <td>0.660868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.444288</td>\n",
       "      <td>0.325004</td>\n",
       "      <td>0.570091</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.874163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.441818</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.565445</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.534482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.437318</td>\n",
       "      <td>0.313165</td>\n",
       "      <td>0.559611</td>\n",
       "      <td>0.053832</td>\n",
       "      <td>0.377385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.441158</td>\n",
       "      <td>0.315996</td>\n",
       "      <td>0.562135</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.932517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.441349</td>\n",
       "      <td>0.321300</td>\n",
       "      <td>0.566833</td>\n",
       "      <td>-0.002440</td>\n",
       "      <td>0.968109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.436407</td>\n",
       "      <td>0.318621</td>\n",
       "      <td>0.564465</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.604945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.449286</td>\n",
       "      <td>0.325543</td>\n",
       "      <td>0.570564</td>\n",
       "      <td>-0.009045</td>\n",
       "      <td>0.882172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.446306</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.567221</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.976393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.445196</td>\n",
       "      <td>0.321158</td>\n",
       "      <td>0.566708</td>\n",
       "      <td>-0.013935</td>\n",
       "      <td>0.819380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration       mae       mse      rmse     corrs        ps\n",
       "0           1  0.448270  0.323950  0.569166  0.007989  0.895847\n",
       "1           2  0.440088  0.315805  0.561966  0.061461  0.313430\n",
       "2           3  0.450520  0.323464  0.568739 -0.003247  0.957569\n",
       "3           4  0.443326  0.323420  0.568701  0.011029  0.856580\n",
       "4           5  0.441004  0.319461  0.565209  0.004888  0.936162\n",
       "5           6  0.434989  0.315003  0.561251  0.061055  0.316642\n",
       "6           7  0.437171  0.313981  0.560340  0.021744  0.721585\n",
       "7           8  0.446004  0.323601  0.568860 -0.010053  0.869155\n",
       "8           9  0.447429  0.327646  0.572403  0.003018  0.960564\n",
       "9          10  0.455344  0.333953  0.577887 -0.034057  0.576694\n",
       "10         11  0.442656  0.317219  0.563222  0.007918  0.896761\n",
       "11         12  0.443296  0.321188  0.566734  0.014724  0.809344\n",
       "12         13  0.448804  0.319055  0.564849 -0.007011  0.908538\n",
       "13         14  0.453329  0.330907  0.575245 -0.015910  0.794304\n",
       "14         15  0.451492  0.328705  0.573328 -0.020497  0.736944\n",
       "15         16  0.451995  0.328429  0.573087 -0.026769  0.660868\n",
       "16         17  0.444288  0.325004  0.570091  0.009665  0.874163\n",
       "17         18  0.441818  0.319728  0.565445  0.037896  0.534482\n",
       "18         19  0.437318  0.313165  0.559611  0.053832  0.377385\n",
       "19         20  0.441158  0.315996  0.562135  0.005168  0.932517\n",
       "20         21  0.441349  0.321300  0.566833 -0.002440  0.968109\n",
       "21         22  0.436407  0.318621  0.564465  0.031562  0.604945\n",
       "22         23  0.449286  0.325543  0.570564 -0.009045  0.882172\n",
       "23         24  0.446306  0.321739  0.567221  0.001806  0.976393\n",
       "24         25  0.445196  0.321158  0.566708 -0.013935  0.819380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all iterations:\n",
      "  MAE: 0.44\n",
      "  MSE: 0.32\n",
      " RMSE: 0.57\n",
      " Corr: 0.01\n",
      "p-val: 0.7672213\n"
     ]
    }
   ],
   "source": [
    "# Resources\n",
    "## https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "# Store metrics for all iterations\n",
    "# aurocs = []\n",
    "maes = []    # MAE (mean absolute errors)\n",
    "mses = []    # MSE (mean squared errors)\n",
    "rmses = []   # RMSE (root mean squared errors)\n",
    "corrs = []   # spearman correlations\n",
    "ps = []      # spearman correlation p-values\n",
    "\n",
    "all_y_test_subj_out = [[] for i in range(num_iters)]\n",
    "predictions_subj_out = [[] for i in range(num_iters)]\n",
    "\n",
    "# For storing shap values across all folds\n",
    "subj_out_shap_values_0 = None\n",
    "subj_out_shap_values_1 = None\n",
    "subj_out_full_X_test = pd.DataFrame()\n",
    "\n",
    "#-----------------------------------------------#\n",
    "#      5-fold team level cross-validation       #\n",
    "#-----------------------------------------------#\n",
    "\n",
    "# For each iteration \n",
    "for i in range(num_iters):\n",
    "    print(\"Iteration: \", i+1)\n",
    "    \n",
    "    # Lists for cumulative test set and predictions for iteration\n",
    "    dfFullTest = pd.DataFrame()\n",
    "    all_y_test = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Create model for task_score prediction\n",
    "    if model == \"RFR\":\n",
    "        model_subj_out = RandomForestRegressor(n_estimators=100, random_state=1, \\\n",
    "                                           max_features='sqrt') \n",
    "    elif model == \"SVR\":\n",
    "        model_subj_out = SVR()\n",
    "    \n",
    "    # Get fold groups\n",
    "    fold_groups = folds_dict_list[i]\n",
    "    \n",
    "    # For each fold\n",
    "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
    "#         print(\"\\tFold: \", j+1)\n",
    "        # Get data for teams in test set\n",
    "        test_data_list = get_group_data(dfData, fold_groups[test_fold], features, 'CPS_and_ITN_mean')\n",
    "        X_test = test_data_list[0]\n",
    "        y_test = test_data_list[1]\n",
    "        all_y_test.extend(y_test.tolist())\n",
    "        dfFullTest = pd.concat([dfFullTest, test_data_list[2]], ignore_index=True)\n",
    "        \n",
    "        # Get data for teams in train set\n",
    "        train_data_list = get_group_data(dfData, fold_groups[train_fold], features, 'CPS_and_ITN_mean')\n",
    "        X_train = train_data_list[0]\n",
    "        y_train = train_data_list[1]\n",
    "        \n",
    "\n",
    "        # Train model\n",
    "        model_subj_out.fit(X_train, y_train)\n",
    "\n",
    "        # Test model\n",
    "        y_pred = model_subj_out.predict(X_test)\n",
    "        predictions.extend(y_pred.tolist())\n",
    "        \n",
    "#         ## Get SHAP values\n",
    "#         explainer = shap.TreeExplainer(model_subj_outrfc_subj_out)\n",
    "#         shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "#         if j==0:\n",
    "#             subj_out_shap_values_0 = shap_values[0]\n",
    "#             subj_out_shap_values_1 = shap_values[1]\n",
    "#         else:\n",
    "#             subj_out_shap_values_0 = np.vstack([subj_out_shap_values_0, shap_values[0]])\n",
    "#             subj_out_shap_values_1 = np.vstack([subj_out_shap_values_1, shap_values[1]])\n",
    "#         subj_out_full_X_test = pd.concat([subj_out_full_X_test, X_test], ignore_index=True)\n",
    "#         ## End of get SHAP values\n",
    "\n",
    "# ----- END OF FOLDS\n",
    "\n",
    "    # Calculate the absolute errors (MAE) of the iteration\n",
    "    predictions = np.array(predictions)\n",
    "    all_y_test = np.array(all_y_test)\n",
    "    mae = metrics.mean_absolute_error(all_y_test, predictions)\n",
    "    mse = metrics.mean_squared_error(all_y_test, predictions)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(all_y_test, predictions))\n",
    "    corr, p = spearmanr(all_y_test, predictions)\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "    corrs.append(corr)\n",
    "    ps.append(p)\n",
    "    \n",
    "    # Save iteration subjective outcome truth labels, and predictions for stats across all iterations\n",
    "    all_y_test_subj_out[i] = all_y_test\n",
    "    predictions_subj_out[i] = predictions\n",
    "\n",
    "    # Save actual labels and predictions for iteration\n",
    "    dfTruevPred = dfFullTest.loc[:, ['GROUPID', 'block', 'CPS_and_ITN_mean']]\n",
    "    dfTruevPred['prediction'] = predictions\n",
    "    dfTruevPred.sort_values(['GROUPID', 'block', 'CPS_and_ITN_mean'], ignore_index=True, inplace=True)\n",
    "    dfTruevPred['error'] = abs(dfTruevPred['prediction'] - dfTruevPred['CPS_and_ITN_mean'])\n",
    "#     print(\"MAE from df: \", round(np.mean(dfTruevPred['error']), 2))\n",
    "    \n",
    "    if shuffled:\n",
    "        dfTruevPred.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_SubjOut_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\", index=False)\n",
    "    elif chance:\n",
    "        dfTruevPred.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_SubjOut_True_vs_Pred_CHANCE_\" + str(i+1) + \".csv\", index=False)\n",
    "    else:\n",
    "        dfTruevPred.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW/\" + model + \"/\" + model + \"_SubjOut_True_vs_Pred_\" + str(i+1) + \".csv\", index=False)\n",
    "    \n",
    "#     # FOR PLOTTING ACTUAL vs. PREDICTED    \n",
    "#     dfTruevPred.plot(y=['CPS_and_ITN_mean', 'prediction'], title='Actual vs. Predicted Subjective Outcome', \\\n",
    "#                      style=['b-', 'ro'], figsize=(20, 5))\n",
    "#     # END PLOTTING\n",
    "    \n",
    "#     if model == \"RFR\":\n",
    "#         ### Compute Feature Importances for last fold iteration ###\n",
    "#         # Impurity-based importances\n",
    "#         importances = model_subj_out.feature_importances_\n",
    "#         std = np.std([tree.feature_importances_ for tree in model_subj_out.estimators_], axis=0)\n",
    "#         imps = pd.Series(importances, index=features)\n",
    "#         stds = pd.Series(std, index=features)\n",
    "#         ## Plot feature importances\n",
    "#         fig1, ax1 = plt.subplots()\n",
    "#         imps.plot.bar(yerr=std, ax=ax1)\n",
    "#         ax1.set_title(\"CPS and ITN Feature importances using MDI\")\n",
    "#         ax1.set_ylabel(\"Mean decrease in impurity\")\n",
    "#         plt.show()\n",
    "#         ## END plotting feature importances\n",
    "    \n",
    "    \n",
    "# ----- END OF ITERATIONS\n",
    "\n",
    "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
    "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], \\\n",
    "                          'mae': maes, 'mse': mses, 'rmse': rmses, 'corrs': corrs, 'ps': ps})\n",
    "display(dfMetrics)\n",
    "\n",
    "if shuffled:\n",
    "    dfMetrics.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_SubjOut_Metrics_SHUFF.csv\", index=False)\n",
    "elif chance:\n",
    "    dfMetrics.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_SubjOut_Metrics_CHANCE.csv\", index=False)\n",
    "else:\n",
    "    dfMetrics.to_csv(SUBJ_OUTCOME_RESULTS + \"RAW/\" + model + \"/\" + model + \"_SubjOut_Metrics.csv\", index=False)\n",
    "\n",
    "print(\"Average over all iterations:\")\n",
    "print(\"%6s %.2f\" % (\"MAE:\", np.mean(dfMetrics['mae'])))\n",
    "print(\"%6s %.2f\" % (\"MSE:\", np.mean(dfMetrics['mse'])))\n",
    "print(\"%6s %.2f\" % (\"RMSE:\", np.mean(dfMetrics['rmse'])))\n",
    "print(\"%6s %.2f\" % (\"Corr:\", np.mean(dfMetrics['corrs'])))\n",
    "print(\"%6s %.7f\" % (\"p-val:\", np.mean(dfMetrics['ps'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4afa8b",
   "metadata": {},
   "source": [
    "# Predict Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6940a075",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "\n",
      " =========== ALL ITERATIONS RESULTS SUMMARY ===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>corrs</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.567982</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>0.007110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.568326</td>\n",
       "      <td>0.495828</td>\n",
       "      <td>0.704151</td>\n",
       "      <td>0.181152</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.566897</td>\n",
       "      <td>0.495012</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>0.183132</td>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.570229</td>\n",
       "      <td>0.500588</td>\n",
       "      <td>0.707522</td>\n",
       "      <td>0.146658</td>\n",
       "      <td>0.015683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.572428</td>\n",
       "      <td>0.503443</td>\n",
       "      <td>0.709537</td>\n",
       "      <td>0.122625</td>\n",
       "      <td>0.043701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.573306</td>\n",
       "      <td>0.504759</td>\n",
       "      <td>0.710464</td>\n",
       "      <td>0.092924</td>\n",
       "      <td>0.127019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.573873</td>\n",
       "      <td>0.505575</td>\n",
       "      <td>0.711038</td>\n",
       "      <td>0.095828</td>\n",
       "      <td>0.115519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.573109</td>\n",
       "      <td>0.505421</td>\n",
       "      <td>0.710929</td>\n",
       "      <td>0.090863</td>\n",
       "      <td>0.135709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.567441</td>\n",
       "      <td>0.498867</td>\n",
       "      <td>0.706306</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.018216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.572523</td>\n",
       "      <td>0.501469</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.126814</td>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.570361</td>\n",
       "      <td>0.500810</td>\n",
       "      <td>0.707680</td>\n",
       "      <td>0.133685</td>\n",
       "      <td>0.027775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.569693</td>\n",
       "      <td>0.497511</td>\n",
       "      <td>0.705344</td>\n",
       "      <td>0.172422</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.569753</td>\n",
       "      <td>0.498415</td>\n",
       "      <td>0.705985</td>\n",
       "      <td>0.146502</td>\n",
       "      <td>0.015795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.576212</td>\n",
       "      <td>0.507078</td>\n",
       "      <td>0.712094</td>\n",
       "      <td>0.075309</td>\n",
       "      <td>0.216545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.570545</td>\n",
       "      <td>0.503563</td>\n",
       "      <td>0.709621</td>\n",
       "      <td>0.115255</td>\n",
       "      <td>0.058108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>0.501716</td>\n",
       "      <td>0.708319</td>\n",
       "      <td>0.127196</td>\n",
       "      <td>0.036373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.571426</td>\n",
       "      <td>0.504281</td>\n",
       "      <td>0.710128</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>0.063508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.507349</td>\n",
       "      <td>0.712285</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.136642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.571423</td>\n",
       "      <td>0.501963</td>\n",
       "      <td>0.708493</td>\n",
       "      <td>0.127530</td>\n",
       "      <td>0.035880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.574519</td>\n",
       "      <td>0.507062</td>\n",
       "      <td>0.712083</td>\n",
       "      <td>0.076049</td>\n",
       "      <td>0.212050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.571189</td>\n",
       "      <td>0.501638</td>\n",
       "      <td>0.708264</td>\n",
       "      <td>0.127747</td>\n",
       "      <td>0.035564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.570988</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.706050</td>\n",
       "      <td>0.176572</td>\n",
       "      <td>0.003543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.576289</td>\n",
       "      <td>0.507329</td>\n",
       "      <td>0.712270</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.201030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>0.498852</td>\n",
       "      <td>0.706295</td>\n",
       "      <td>0.163386</td>\n",
       "      <td>0.007031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.566413</td>\n",
       "      <td>0.493340</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.186655</td>\n",
       "      <td>0.002031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration       mae       mse      rmse     corrs        ps\n",
       "0           1  0.567982  0.497321  0.705210  0.163164  0.007110\n",
       "1           2  0.568326  0.495828  0.704151  0.181152  0.002761\n",
       "2           3  0.566897  0.495012  0.703571  0.183132  0.002475\n",
       "3           4  0.570229  0.500588  0.707522  0.146658  0.015683\n",
       "4           5  0.572428  0.503443  0.709537  0.122625  0.043701\n",
       "5           6  0.573306  0.504759  0.710464  0.092924  0.127019\n",
       "6           7  0.573873  0.505575  0.711038  0.095828  0.115519\n",
       "7           8  0.573109  0.505421  0.710929  0.090863  0.135709\n",
       "8           9  0.567441  0.498867  0.706306  0.143354  0.018216\n",
       "9          10  0.572523  0.501469  0.708145  0.126814  0.036943\n",
       "10         11  0.570361  0.500810  0.707680  0.133685  0.027775\n",
       "11         12  0.569693  0.497511  0.705344  0.172422  0.004418\n",
       "12         13  0.569753  0.498415  0.705985  0.146502  0.015795\n",
       "13         14  0.576212  0.507078  0.712094  0.075309  0.216545\n",
       "14         15  0.570545  0.503563  0.709621  0.115255  0.058108\n",
       "15         16  0.573460  0.501716  0.708319  0.127196  0.036373\n",
       "16         17  0.571426  0.504281  0.710128  0.112882  0.063508\n",
       "17         18  0.573770  0.507349  0.712285  0.090647  0.136642\n",
       "18         19  0.571423  0.501963  0.708493  0.127530  0.035880\n",
       "19         20  0.574519  0.507062  0.712083  0.076049  0.212050\n",
       "20         21  0.571189  0.501638  0.708264  0.127747  0.035564\n",
       "21         22  0.570988  0.498507  0.706050  0.176572  0.003543\n",
       "22         23  0.576289  0.507329  0.712270  0.077913  0.201030\n",
       "23         24  0.569941  0.498852  0.706295  0.163386  0.007031\n",
       "24         25  0.566413  0.493340  0.702381  0.186655  0.002031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over all iterations:\n",
      "  MAE: 0.57\n",
      "  MSE: 0.50\n",
      " RMSE: 0.71\n",
      " Corr: 0.13\n",
      "p-val: 0.0624570\n"
     ]
    }
   ],
   "source": [
    "# Resources\n",
    "## https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "# Store metrics for all iterations\n",
    "# aurocs = []\n",
    "maes = []    # MAE (mean absolute errors)\n",
    "mses = []    # MSE (mean squared errors)\n",
    "rmses = []   # RMSE (root mean squared errors)\n",
    "corrs = []   # spearman correlations\n",
    "ps = []      # spearman correlation p-values\n",
    "\n",
    "all_y_test_valence = [[] for i in range(num_iters)]\n",
    "predictions_valence = [[] for i in range(num_iters)]\n",
    "\n",
    "# For storing shap values across all folds\n",
    "valence_shap_values_0 = None\n",
    "valence_shap_values_1 = None\n",
    "valence_full_X_test = pd.DataFrame()\n",
    "\n",
    "#-----------------------------------------------#\n",
    "#      5-fold team level cross-validation       #\n",
    "#-----------------------------------------------#\n",
    "\n",
    "# For each iteration \n",
    "for i in range(num_iters):\n",
    "    print(\"Iteration: \", i+1)\n",
    "    \n",
    "    # Lists for cumulative test set and predictions for iteration\n",
    "    dfFullTest = pd.DataFrame()\n",
    "    all_y_test = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Create model for task_score prediction\n",
    "    if model == \"RFR\":\n",
    "        model_valence = RandomForestRegressor(n_estimators=100, random_state=1, \\\n",
    "                                           max_features='sqrt') \n",
    "    elif model == \"SVR\":\n",
    "        model_valence = SVR()\n",
    "    \n",
    "    # Get fold groups\n",
    "    fold_groups = folds_dict_list[i]\n",
    "    \n",
    "    # For each fold\n",
    "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
    "#         print(\"\\tFold: \", j+1)\n",
    "        # Get data for teams in test set\n",
    "        test_data_list = get_group_data(dfData, fold_groups[test_fold], features, 'Valence')\n",
    "        X_test = test_data_list[0]\n",
    "        y_test = test_data_list[1]\n",
    "        all_y_test.extend(y_test.tolist())\n",
    "        dfFullTest = pd.concat([dfFullTest, test_data_list[2]], ignore_index=True)\n",
    "        \n",
    "        # Get data for teams in train set\n",
    "        train_data_list = get_group_data(dfData, fold_groups[train_fold], features, 'Valence')\n",
    "        X_train = train_data_list[0]\n",
    "        y_train = train_data_list[1]\n",
    "        \n",
    "\n",
    "        # Train model\n",
    "        model_valence.fit(X_train, y_train)\n",
    "\n",
    "        # Test model\n",
    "        y_pred = model_valence.predict(X_test)\n",
    "        predictions.extend(y_pred.tolist())\n",
    "        \n",
    "#         ## Get SHAP values\n",
    "#         explainer = shap.TreeExplainer(model_valencerfc_valence)\n",
    "#         shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "#         if j==0:\n",
    "#             valence_shap_values_0 = shap_values[0]\n",
    "#             valence_shap_values_1 = shap_values[1]\n",
    "#         else:\n",
    "#             valence_shap_values_0 = np.vstack([valence_shap_values_0, shap_values[0]])\n",
    "#             valence_shap_values_1 = np.vstack([valence_shap_values_1, shap_values[1]])\n",
    "#         valence_full_X_test = pd.concat([valence_full_X_test, X_test], ignore_index=True)\n",
    "#         ## End of get SHAP values\n",
    "\n",
    "# ----- END OF FOLDS\n",
    "\n",
    "    # Calculate the absolute errors (MAE) of the iteration\n",
    "    predictions = np.array(predictions)\n",
    "    all_y_test = np.array(all_y_test)\n",
    "    mae = metrics.mean_absolute_error(all_y_test, predictions)\n",
    "    mse = metrics.mean_squared_error(all_y_test, predictions)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(all_y_test, predictions))\n",
    "    corr, p = spearmanr(all_y_test, predictions)\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "    corrs.append(corr)\n",
    "    ps.append(p)\n",
    "    \n",
    "    # Save iteration valence truth labels, and predictions for stats across all iterations\n",
    "    all_y_test_subj_out[i] = all_y_test\n",
    "    predictions_subj_out[i] = predictions\n",
    "\n",
    "    # Save actual labels and predictions for iteration\n",
    "    dfTruevPred = dfFullTest.loc[:, ['GROUPID', 'block', 'Valence']]\n",
    "    dfTruevPred['prediction'] = predictions\n",
    "    dfTruevPred.sort_values(['GROUPID', 'block', 'Valence'], ignore_index=True, inplace=True)\n",
    "    dfTruevPred['error'] = abs(dfTruevPred['prediction'] - dfTruevPred['Valence'])\n",
    "#     print(\"MAE from df: \", round(np.mean(dfTruevPred['error']), 2))\n",
    "    \n",
    "    if shuffled:\n",
    "        dfTruevPred.to_csv(VALENCE_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_Valence_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\", index=False)\n",
    "    elif chance:\n",
    "        dfTruevPred.to_csv(VALENCE_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_Valence_True_vs_Pred_CHANCE_\" + str(i+1) + \".csv\", index=False)\n",
    "    else:\n",
    "        dfTruevPred.to_csv(VALENCE_RESULTS + \"RAW/\" + model + \"/\" + model + \"_Valence_True_vs_Pred_\" + str(i+1) + \".csv\", index=False)\n",
    "    \n",
    "#     # FOR PLOTTING ACTUAL vs. PREDICTED   \n",
    "#     dfTruevPred.plot(y=['Valence', 'prediction'], title='Actual vs. Predicted Valence', \\\n",
    "#                      style=['b-', 'ro'], figsize=(20, 5))\n",
    "#     # END PLOTTING\n",
    "    \n",
    "#     if model == \"RFR\":\n",
    "#         ### Compute Feature Importances for last fold iteration ###\n",
    "#         # Impurity-based importances\n",
    "#         importances = model_valence.feature_importances_\n",
    "#         std = np.std([tree.feature_importances_ for tree in model_valence.estimators_], axis=0)\n",
    "#         imps = pd.Series(importances, index=features)\n",
    "#         stds = pd.Series(std, index=features)\n",
    "#         ## Plot feature importances\n",
    "#         fig1, ax1 = plt.subplots()\n",
    "#         imps.plot.bar(yerr=std, ax=ax1)\n",
    "#         ax1.set_title(\"Valence Feature importances using MDI\")\n",
    "#         ax1.set_ylabel(\"Mean decrease in impurity\")\n",
    "#         plt.show()\n",
    "#         ## END plotting feature importances\n",
    "    \n",
    "    \n",
    "# ----- END OF ITERATIONS\n",
    "\n",
    "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
    "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], \\\n",
    "                          'mae': maes, 'mse': mses, 'rmse': rmses, 'corrs': corrs, 'ps': ps})\n",
    "display(dfMetrics)\n",
    "\n",
    "if shuffled:\n",
    "    dfMetrics.to_csv(VALENCE_RESULTS + \"RAW_SHUFFLED/\" + model + \"/\" + model + \"_Valence_Metrics_SHUFF.csv\", index=False)\n",
    "elif chance:\n",
    "    dfMetrics.to_csv(VALENCE_RESULTS + \"RAW_CHANCE/\" + model + \"/\" + model + \"_Valence_Metrics_CHANCE.csv\", index=False)\n",
    "else:\n",
    "    dfMetrics.to_csv(VALENCE_RESULTS + \"RAW/\" + model + \"/\" + model + \"_Valence_Metrics.csv\", index=False)\n",
    "\n",
    "print(\"Average over all iterations:\")\n",
    "print(\"%6s %.2f\" % (\"MAE:\", np.mean(dfMetrics['mae'])))\n",
    "print(\"%6s %.2f\" % (\"MSE:\", np.mean(dfMetrics['mse'])))\n",
    "print(\"%6s %.2f\" % (\"RMSE:\", np.mean(dfMetrics['rmse'])))\n",
    "print(\"%6s %.2f\" % (\"Corr:\", np.mean(dfMetrics['corrs'])))\n",
    "print(\"%6s %.7f\" % (\"p-val:\", np.mean(dfMetrics['ps'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e56216",
   "metadata": {},
   "source": [
    "## without cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3beae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['REC', 'DET', 'ADL', 'MDL', 'DENTR', 'LAM', 'AVL', 'MVL', 'VENTR']\n",
    "\n",
    "X = dfData.loc[:, features]  \n",
    "y = dfData.loc[:, 'task_score']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "model_task_score = RandomForestRegressor(n_estimators=100, random_state=1, max_features='sqrt')\n",
    "\n",
    "\n",
    "# Train model\n",
    "model_task_score.fit(X_train, y_train)\n",
    "    \n",
    "# Predict    \n",
    "y_pred = model_task_score.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"%5s %.2f\" % (\"MAE:\", mae))\n",
    "print(\"%5s %.2f\" % (\"MSE:\", mse))\n",
    "print(\"%5s %.2f\" % (\"RMSE:\", rmse))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c240b02",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd208c3d",
   "metadata": {},
   "source": [
    "## Predict Task Score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fba86",
   "metadata": {},
   "source": [
    "### OHE labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc6294",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc474d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['REC', 'DET', 'ADL', 'MDL', 'DENTR', 'LAM', 'AVL', 'MVL', 'VENTR']\n",
    "\n",
    "X = dfData.loc[:, features]  \n",
    "y = dfData.loc[:, 'task_score_cat']\n",
    "\n",
    "# y_bin = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "model_task_score = RandomForestClassifier(n_estimators=100, random_state=1, \\\n",
    "                                           max_features='sqrt', class_weight='balanced') \n",
    "\n",
    "# Train model\n",
    "model_task_score.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "y_pred = model_task_score.predict(X_test)\n",
    "\n",
    "# display(pd.DataFrame({\"y_test\": y_test, \"y_pred\": y_pred}))\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "\n",
    "# #roc auc score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "# y_pp = model_task_score.predict_proba(X_test) \n",
    "# print(\"\\ny_train info\")\n",
    "# print(\"total len: \", len(y_train))\n",
    "# print(\"unique vals: \", len(set(y_train)))\n",
    "# print(\"\\ny_test info\")\n",
    "# print(\"total len: \", len(y_test))\n",
    "# print(\"unique vals: \", len(set(y_test)))\n",
    "# print(\"\\ny_pp info\")\n",
    "# print(\"y_pp shape: \", y_pp.shape)\n",
    "\n",
    "# auroc = roc_auc_score(y_test, y_pp, multi_class='ovo', average='weighted')\n",
    "# print(auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8125a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b0121e",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac616f44",
   "metadata": {},
   "source": [
    "## Random Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc81f9",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe173050",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['REC', 'DET', 'ADL', 'MDL', 'DENTR', 'LAM', 'AVL', 'MVL', 'VENTR']\n",
    "\n",
    "X = dfData.loc[:, features]  \n",
    "y = dfData.loc[:, 'task_score_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "## Use the random grid to search for best hyperparameters\n",
    "\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "pprint(rf_random.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators=100, random_state=1, max_features='sqrt') \n",
    "base_model.fit(X_train, y_train)\n",
    "base_predictions = base_model.predict(X_test)\n",
    "\n",
    "print('Base Model Performance')\n",
    "print(classification_report(y_test, base_predictions, zero_division=1))\n",
    "\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_predictions = best_random.predict(X_test)\n",
    "\n",
    "print('Random Model Performance')\n",
    "print(classification_report(y_test, random_predictions, zero_division=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db72d82",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef54b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "## https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfData.loc[:, features], dfData.loc[:, 'task_score'], \\\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "if model == \"RFR\":\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    pprint(random_grid)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ## Use the random grid to search for best hyperparameters\n",
    "    \n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    pprint(rf_random.best_params_)\n",
    "\n",
    "    base_model = RandomForestRegressor(n_estimators=100, random_state=1, max_features='sqrt') \n",
    "    base_model.fit(X_train, y_train)\n",
    "    base_predictions = base_model.predict(X_test)\n",
    "    base_mae = metrics.mean_absolute_error(y_test, base_predictions)\n",
    "\n",
    "    print(\"===== Random Forest Regessor =====\")\n",
    "    print('Base Model Performance')\n",
    "    print('MAE: ', np.round(base_mae, 2))\n",
    "\n",
    "\n",
    "    best_random = rf_random.best_estimator_\n",
    "    random_predictions = best_random.predict(X_test)\n",
    "    random_mae = metrics.mean_absolute_error(y_test, random_predictions)\n",
    "\n",
    "    print('Random Model Performance')\n",
    "    print('MAE: ', np.round(random_mae, 2))\n",
    "\n",
    "\n",
    "    print('Improvement of {:0.2f}%.'.format( 100 * (random_mae - base_mae) / base_mae))\n",
    "    \n",
    "elif model == \"SVR\":\n",
    "    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    \n",
    "    degree = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    gamma = ['scale', 'auto', 0.1]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'kernel': kernel,\n",
    "                   'degree': degree,\n",
    "                   'gamma': gamma}\n",
    "    pprint(random_grid)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ## Use the random grid to search for best hyperparameters\n",
    "    \n",
    "    # First create the base model to tune\n",
    "    sv = SVR()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    sv_random = RandomizedSearchCV(estimator = sv, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    sv_random.fit(X_train, y_train)\n",
    "\n",
    "    pprint(sv_random.best_params_)\n",
    "\n",
    "    base_model = SVR() \n",
    "    base_model.fit(X_train, y_train)\n",
    "    base_predictions = base_model.predict(X_test)\n",
    "    base_mae = metrics.mean_absolute_error(y_test, base_predictions)\n",
    "\n",
    "    print(\"===== Support Vector Machine Regessor =====\")\n",
    "    print('Base Model Performance')\n",
    "    print('MAE: ', np.round(base_mae, 2))\n",
    "\n",
    "\n",
    "    best_random = sv_random.best_estimator_\n",
    "    random_predictions = best_random.predict(X_test)\n",
    "    random_mae = metrics.mean_absolute_error(y_test, random_predictions)\n",
    "\n",
    "    print('Random Model Performance')\n",
    "    print('MAE: ', np.round(random_mae, 2))\n",
    "\n",
    "\n",
    "    print('Improvement of {:0.2f}%.'.format( 100 * (random_mae - base_mae) / base_mae))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
