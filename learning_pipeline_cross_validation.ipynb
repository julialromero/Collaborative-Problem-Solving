{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning_pipeline_cross_validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOa4TdsN/pPDaauR9IPnO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julialromero/Collaborative-Problem-Solving/blob/main/learning_pipeline_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eOxWUqK_HHo",
        "outputId": "04006a48-319c-4b21-ed31-d6372273d6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "d_1O1Ue7_a8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import os\n",
        "from skimage import io\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from keras import layers, Input, Model, optimizers\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "PROJECT_DIR = \"drive/MyDrive/CSCI 5922 - Final Project/\"  #<--- Make a shortcut for the \"CSCI 5922 - Final Project\" shared folder on your Google Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6seyr38_bqO",
        "outputId": "5139883e-98fb-4489-8fe8-d003cb34df99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 21:11:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get User Input"
      ],
      "metadata": {
        "id": "U6Xc1Ta4_eCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose what size images to use\n",
        "## \"small\" = 98x98, \"med\" = 332x332, \"large\" = 719x719\n",
        "image_size = \"med\"\n",
        "shuffled = False\n",
        "chance = False\n",
        "num_iters = 10\n",
        "num_folds = 10\n",
        "threshold = 0.5\n",
        "num_epochs = 70\n",
        "\n",
        "if image_size == \"large\":\n",
        "  imgsize = (int(719/2), int(719/2)) \n",
        "  if shuffled:\n",
        "    IMG_DIR = \"719x719 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"719x719 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"med\":\n",
        "  imgsize = (332, 332)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"332x332 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"332x332 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "elif image_size == \"small\":\n",
        "  imgsize = (98, 98)\n",
        "  if shuffled:\n",
        "    IMG_DIR = \"98x98 - Recurrence_Matrices/RAW_SHUFFLED/\"\n",
        "  else:\n",
        "    IMG_DIR = \"98x98 - Recurrence_Matrices/RAW/\"\n",
        "\n",
        "print(\"Processing images from: \", IMG_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ovsn_S_fwH",
        "outputId": "d2657076-2fb2-4feb-8d5f-8387d2cde333"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing images from:  332x332 - Recurrence_Matrices/RAW/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Team Outcomes"
      ],
      "metadata": {
        "id": "En3XjYMh_24D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_df = pd.read_csv(PROJECT_DIR + \"team_block_outcomes.csv\")\n",
        "\n",
        "# get median task_score\n",
        "task_scores = outcome_df[\"task_score\"]\n",
        "median_task_score = np.median(task_scores)\n",
        "mean_task_score = np.mean(task_scores)\n",
        "print(\"median: \", median_task_score)\n",
        "print(\"mean: \", mean_task_score)\n",
        "\n",
        "# score_counts = dict(Counter(task_scores))\n",
        "# for key in score_counts:\n",
        "#     print(\"%d: %d\" % (key, score_counts[key]))\n",
        "\n",
        "outcome_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "t75ukXDa_59f",
        "outputId": "0b291b3b-abcb-4934-d8f3-3b9f735e13e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median:  2.0\n",
            "mean:  3.5437956204379564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     GROUPID      block  CPS_and_ITN_mean   Valence  num_gold  num_silver  \\\n",
              "0       1010  ExpBlock1         -0.304697  3.666667       1.0         1.0   \n",
              "1       1010  ExpBlock2         -0.304697  3.666667       2.0         1.0   \n",
              "2       1020  ExpBlock1         -0.389995  4.333333       0.0         2.0   \n",
              "3       1020  ExpBlock2         -0.026413  4.666667       4.0         1.0   \n",
              "4       1020     Warmup         -0.742380  3.666667       0.0         0.0   \n",
              "..       ...        ...               ...       ...       ...         ...   \n",
              "269    10103  ExpBlock2         -0.026413  3.666667       1.0         1.0   \n",
              "270    10103     Warmup         -1.405215  3.333333       1.0         2.0   \n",
              "271    10104  ExpBlock1         -0.531224  3.000000       0.0         0.0   \n",
              "272    10104  ExpBlock2         -1.023464  4.000000       0.0         1.0   \n",
              "273    10104     Warmup         -0.194209  3.000000       0.0         0.0   \n",
              "\n",
              "     task_score  \n",
              "0           3.0  \n",
              "1           5.0  \n",
              "2           2.0  \n",
              "3           9.0  \n",
              "4           0.0  \n",
              "..          ...  \n",
              "269         3.0  \n",
              "270         4.0  \n",
              "271         0.0  \n",
              "272         1.0  \n",
              "273         0.0  \n",
              "\n",
              "[274 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6115eb07-54a7-4fe5-b15a-414d6ce412bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GROUPID</th>\n",
              "      <th>block</th>\n",
              "      <th>CPS_and_ITN_mean</th>\n",
              "      <th>Valence</th>\n",
              "      <th>num_gold</th>\n",
              "      <th>num_silver</th>\n",
              "      <th>task_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1010</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.304697</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.304697</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1020</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.389995</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1020</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.026413</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1020</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-0.742380</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>10103</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-0.026413</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>10103</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-1.405215</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>10104</td>\n",
              "      <td>ExpBlock1</td>\n",
              "      <td>-0.531224</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>10104</td>\n",
              "      <td>ExpBlock2</td>\n",
              "      <td>-1.023464</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>10104</td>\n",
              "      <td>Warmup</td>\n",
              "      <td>-0.194209</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>274 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6115eb07-54a7-4fe5-b15a-414d6ce412bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6115eb07-54a7-4fe5-b15a-414d6ce412bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6115eb07-54a7-4fe5-b15a-414d6ce412bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "mcC3y7rJ_h5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read, preprocess, and scale images to uniform dimension\n",
        "\n",
        "def extract_image(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) # TODO: try interpolation = \"nearest\" instead of default \"bilinear\"\n",
        "\n",
        "    return x\n",
        "\n",
        "def extract_image_inceptionv3(image_path):\n",
        "    imag = io.imread(image_path, as_gray=True)\n",
        "    x = image.img_to_array(imag)\n",
        "\n",
        "    x = tf.image.resize(x, imgsize) # TODO: try interpolation = \"nearest\" instead of default \"bilinear\"\n",
        "    x = np.squeeze(np.stack((x,)*3))\n",
        "    x = x.swapaxes(0,1)\n",
        "    x = x.swapaxes(1,2)\n",
        "\n",
        "    return x\n",
        "\n",
        "def extract_score(filename, outcome_df, score_col=\"task_score\"):\n",
        "    #  match this file's id/block with task score and return\n",
        "    groupid, splitname = filename.split(\"-\")\n",
        "    block = splitname.split(\"_\")[0]\n",
        "    row = outcome_df.loc[(outcome_df.GROUPID == int(groupid)) & (outcome_df.block == block)]\n",
        "    if(row.shape[0] != 1):\n",
        "        print(f\"Error -- Number of task scores recorded is not 1 for block {block} and groupid {groupid}.\")\n",
        "        return np.nan\n",
        "    score = row[score_col].values[0]\n",
        "    return score\n",
        "\n",
        "\n",
        "def extract_binary_score(filename, outcome_df, score_col=\"task_score\", median_score=2):\n",
        "    #  match this file's id/block with task score and return\n",
        "    groupid, splitname = filename.split(\"-\")\n",
        "    block = splitname.split(\"_\")[0]\n",
        "    row = outcome_df.loc[(outcome_df.GROUPID == int(groupid)) & (outcome_df.block == block)]\n",
        "    if(row.shape[0] != 1):\n",
        "        print(f\"Error -- Number of task scores recorded is not 1 for block {block} and groupid {groupid}.\")\n",
        "        return np.nan\n",
        "    raw_score = row[score_col].values[0]\n",
        "    if raw_score <= median_score:\n",
        "        score = 0\n",
        "    else:\n",
        "        score = 1\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "def get_fold_data(GROUPID_list, incv3=False, verbose=False):\n",
        "  # read data to np arrays\n",
        "  recurrence_plot_list = []\n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = []\n",
        "  \n",
        "  labels = []\n",
        "  binary_labels = []\n",
        "\n",
        "  for filename in os.listdir(PROJECT_DIR + IMG_DIR):\n",
        "      # Check if file belongs to one of the teams in the desired group\n",
        "      for GROUPID in GROUPID_list:\n",
        "        if str(GROUPID) == filename.split(\"-\")[0]:\n",
        "          # preprocess image\n",
        "          t = extract_image(PROJECT_DIR + IMG_DIR + filename)\n",
        "          if incv3:\n",
        "            t_incv3 = extract_image_inceptionv3(PROJECT_DIR + IMG_DIR + filename)\n",
        "\n",
        "          # get task score\n",
        "          lab = extract_score(filename, outcome_df, score_col=\"task_score\")\n",
        "          bin_lab = extract_binary_score(filename, outcome_df, score_col=\"task_score\", median_score=2)\n",
        "\n",
        "          # append data\n",
        "          recurrence_plot_list.append(t)\n",
        "          if incv3:\n",
        "            recurrence_plot_list_incv3.append(t_incv3)\n",
        "          \n",
        "          labels.append(lab)\n",
        "          binary_labels.append(bin_lab)\n",
        "      \n",
        "  recurrence_plot_list = np.array(recurrence_plot_list)\n",
        "  if incv3:\n",
        "    recurrence_plot_list_incv3 = np.array(recurrence_plot_list_incv3)\n",
        "    plot_list = recurrence_plot_list_incv3\n",
        "  else:\n",
        "    plot_list = recurrence_plot_list\n",
        "  \n",
        "  labels = np.array(labels)\n",
        "  binary_labels = np.array(binary_labels)\n",
        "\n",
        "  if verbose:\n",
        "    print(\"\\m FOLD DATA INFO: \")\n",
        "    print(f\"\\trecurrence_plot_list: {recurrence_plot_list.shape}\")\n",
        "    if incv3:\n",
        "      print(f\"\\trecurrence_plot_list_incv3: {recurrence_plot_list_incv3.shape}\")\n",
        "    \n",
        "    binary_counts = dict(Counter(binary_labels))\n",
        "    print(\"\\tBinary label counts: \", binary_counts)\n",
        "\n",
        "  return [plot_list, labels, binary_labels]\n",
        "  \n",
        "\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=None,\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)"
      ],
      "metadata": {
        "id": "CSTKsbhf_i4k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification w/ Team-level Cross Validation"
      ],
      "metadata": {
        "id": "MH7mm3sM_-Lg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep folds for team-level cross validation"
      ],
      "metadata": {
        "id": "C1RqeopR__Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fold names\n",
        "train_folds = []\n",
        "test_folds = []\n",
        "set_type = \"test\"\n",
        "for j in range(1,num_folds+1): \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    test_folds.append(col_name)\n",
        "    set_type = \"train\"  \n",
        "    col_name = \"Fold\" + str(j) + \"_\" + set_type\n",
        "    train_folds.append(col_name)\n",
        "    set_type = \"test\"\n",
        "\n",
        "folds_dict_list = []\n",
        "\n",
        "# Split teams into 5 groups\n",
        "teams = pd.unique(outcome_df.GROUPID)\n",
        "\n",
        "# For every iteration\n",
        "for i in range(1,num_iters+1):\n",
        "    print(\"Iteration: \", i)\n",
        "    teams = shuffle(teams, random_state=i)\n",
        "    groups = np.array_split(teams, num_folds)\n",
        "    \n",
        "    # Define groups for each fold\n",
        "    fold_groups = {}\n",
        "    for j, (train_fold, test_fold) in enumerate(zip(train_folds, test_folds)):\n",
        "        # make the current group the test group\n",
        "        fold_groups[test_fold] = groups[j]\n",
        "        # make all other groups the train group\n",
        "        train_group = groups[:j] + groups[j+1:]\n",
        "        train_group = [team for group in train_group for team in group]\n",
        "        fold_groups[train_fold] = train_group\n",
        "        \n",
        "    ## Confirm that for each fold, there is no team overlap bewteen train and test set\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(fold_groups['Fold'+str(j)+'_test']).isdisjoint(set(fold_groups['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "    print(\"* No team overlap *\")\n",
        "\n",
        "      \n",
        "    # Add fold groups to dictionary\n",
        "    folds_dict_list.append(fold_groups)\n",
        "    \n",
        "\n",
        "# Informational\n",
        "print(\"\\nNumber of iterations: \", len(folds_dict_list))\n",
        "\n",
        "print(\"\\nIterating through folds_dict_list to check for overlap...\")\n",
        "for i,dicti in enumerate(folds_dict_list):\n",
        "    for j in range(1,num_folds+1):\n",
        "        assert set(dicti['Fold'+str(j)+'_test']).isdisjoint(set(dicti['Fold'+str(j)+'_train'])), \"There is overlap in train and test set \" + str(j)\n",
        "    \n",
        "print(\"* No team overlap *\")  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG3KmXd7AD6s",
        "outputId": "5e25fd74-907d-4bb0-f1f0-6019e36c8df0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "* No team overlap *\n",
            "Iteration:  2\n",
            "* No team overlap *\n",
            "Iteration:  3\n",
            "* No team overlap *\n",
            "Iteration:  4\n",
            "* No team overlap *\n",
            "Iteration:  5\n",
            "* No team overlap *\n",
            "Iteration:  6\n",
            "* No team overlap *\n",
            "Iteration:  7\n",
            "* No team overlap *\n",
            "Iteration:  8\n",
            "* No team overlap *\n",
            "Iteration:  9\n",
            "* No team overlap *\n",
            "Iteration:  10\n",
            "* No team overlap *\n",
            "\n",
            "Number of iterations:  10\n",
            "\n",
            "Iterating through folds_dict_list to check for overlap...\n",
            "* No team overlap *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare model"
      ],
      "metadata": {
        "id": "iaww4uJ_AEl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_garcia_model():\n",
        "  # Garcia-Ceja paper feeds CNN images with dims 100 x 100 x 4 (width x height x channels)\n",
        "  # Labels are one hot encoded\n",
        "  inputs = Input(shape=(imgsize[0], imgsize[1], 1))\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(inputs)\n",
        "  x = layers.Conv2D(filters=16, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=3, strides=(1, 1), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "  x = layers.Dense(512, activation=\"relu\")(x) \n",
        "  x = layers.Dropout(0.50)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  out = layers.Dense(1, activation=\"sigmoid\")(x)   # change output layer to 1 and activation to sigmoid\n",
        "\n",
        "\n",
        "  bc = tf.keras.losses.BinaryCrossentropy()        # change loss to binary\n",
        "  lr = 0.00001 # paper used 0.001\n",
        "  eps = 1e-08  # paper used 1e-08, but keras default is 1e-07\n",
        "  adam = keras.optimizers.Adam(learning_rate=lr, epsilon=eps)\n",
        "  auc = tf.keras.metrics.AUC(\n",
        "        num_thresholds=200,\n",
        "        curve=\"ROC\",\n",
        "        from_logits=False\n",
        "  )\n",
        "  prec = tf.keras.metrics.Precision()\n",
        "  rec = tf.keras.metrics.Recall()\n",
        "\n",
        "\n",
        "  model_binary = Model(inputs=inputs, outputs=out)\n",
        "  model_binary.compile(\n",
        "    optimizer=adam,\n",
        "    loss=bc, \n",
        "    metrics=['accuracy', auc, prec, rec],\n",
        "  )\n",
        "\n",
        "  return model_binary\n",
        "\n",
        "model_binary = get_binary_garcia_model()\n",
        "model_binary.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9DXnFD9AKLo",
        "outputId": "e8a64d10-eb5c-4f72-bdf0-2bd449aa4770"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 98, 98, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 96, 96, 16)        160       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 94, 94, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 47, 47, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 47, 47, 16)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 45, 45, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 43, 43, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 21, 21, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 21, 32)        0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 21, 21, 512)       16896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 21, 21, 512)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 225792)            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 225793    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 259,057\n",
            "Trainable params: 259,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run team-level cross validation"
      ],
      "metadata": {
        "id": "kSDX7yb1AVx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store metrics for all iterations\n",
        "aurocs = []\n",
        "precision = []\n",
        "recall = []\n",
        "accuracy = []\n",
        "\n",
        "all_y_test_task_score = [[] for i in range(num_iters)]\n",
        "predictions_task_score = [[] for i in range(num_iters)]\n",
        "predict_proba_task_score = [[] for i in range(num_iters)]\n",
        "\n",
        "# For each iteration \n",
        "for i in range(num_iters):\n",
        "    print(\"Iteration: \", i+1)\n",
        "    \n",
        "    # Lists for cumulative predictions for iteration\n",
        "    all_y_test = []\n",
        "    predictions = []\n",
        "    predict_proba = []\n",
        "    \n",
        "    # Get fold groups\n",
        "    fold_groups = folds_dict_list[i]\n",
        "    \n",
        "    # For each fold\n",
        "    for j, (test_fold, train_fold) in enumerate(zip(test_folds, train_folds)):\n",
        "        print(\"\\tFold: \", j+1)\n",
        "        # Get data for teams in test set\n",
        "        [plot_list, labels, binary_labels] = get_fold_data(fold_groups[test_fold], incv3=False)\n",
        "        X_test = plot_list\n",
        "        y_test = binary_labels\n",
        "        all_y_test.extend(y_test.tolist())\n",
        "        \n",
        "        # Get data for teams in train set\n",
        "        [plot_list, labels, binary_labels] = get_fold_data(fold_groups[train_fold], incv3=False)\n",
        "        X_train = plot_list\n",
        "        y_train = binary_labels\n",
        "\n",
        "        # Train model\n",
        "        model_binary = get_binary_garcia_model()\n",
        "        # model_binary.summary()\n",
        "        info_bin_cv = model_binary.fit(x=X_train, y=y_train, epochs=num_epochs, verbose=False)\n",
        "\n",
        "        # Test model: https://androidkt.com/get-class-labels-from-predict-method-in-keras/\n",
        "        y_pp = model_binary.predict(X_test)\n",
        "        y_pred = np.where(y_pp > threshold, 1, 0)\n",
        "\n",
        "        predict_proba.extend(y_pp.tolist())\n",
        "        predictions.extend(y_pred.tolist())\n",
        "\n",
        "    # ----- END OF FOLDS\n",
        "\n",
        "    all_y_test = np.array(all_y_test)\n",
        "    all_y_test_task_score[i] = all_y_test\n",
        "\n",
        "    predictions = np.squeeze(np.array(predictions))\n",
        "    predict_proba = np.squeeze(np.array(predict_proba))\n",
        "    \n",
        "    predictions_task_score[i] = predictions\n",
        "    predict_proba_task_score[i] = predict_proba\n",
        "    \n",
        "    \n",
        "    # Get metrics of iteration\n",
        "    auroc = roc_auc_score(all_y_test, predict_proba)\n",
        "    prec = precision_score(all_y_test, predictions)\n",
        "    rec = recall_score(all_y_test, predictions)\n",
        "    acc = accuracy_score(all_y_test, predictions)\n",
        "    \n",
        "    aurocs.append(auroc)\n",
        "    precision.append(prec)\n",
        "    recall.append(rec)\n",
        "    accuracy.append(acc)\n",
        "\n",
        "     # Save actual labels and predictions for iteration\n",
        "    dfTruevPred = pd.DataFrame({'actual': all_y_test, 'predict_proba': predict_proba, 'prediction': predictions})\n",
        "\n",
        "    if shuffled:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"results/shuffled/cross_val/\" + image_size + \"_TaskScore_True_vs_Pred_SHUFF_\" + str(i+1) + \".csv\"\n",
        "    else:\n",
        "      ACTvPRED_SAVE_DIR = PROJECT_DIR + \"results/cross_val/\" + image_size + \"_TaskScore_True_vs_Pred_\" + str(i+1) + \".csv\"\n",
        "    dfTruevPred.to_csv(ACTvPRED_SAVE_DIR, index=False)    \n",
        "    \n",
        "# ----- END OF ITERATIONS\n",
        "\n",
        "print(\"\\n =========== ALL ITERATIONS RESULTS SUMMARY ===========\")\n",
        "dfMetrics = pd.DataFrame({'iteration': [i for i in range(1,num_iters+1)], 'accuracy': accuracy, \\\n",
        "                          'auroc': aurocs, 'precision': precision, 'recall': recall})\n",
        "\n",
        "display(dfMetrics)\n",
        "\n",
        "if shuffled:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"results/shuffled/cross_val/\" + image_size + \"_TaskScore_Metrics_SHUFF.csv\"\n",
        "else:\n",
        "  METRICS_SAVE_DIR = PROJECT_DIR + \"results/cross_val/\" + image_size + \"_TaskScore_Metrics.csv\"\n",
        "dfMetrics.to_csv(METRICS_SAVE_DIR, index=False)   \n",
        "\n",
        "print(\"Averages: \")\n",
        "print(\"%12s %.2f\" % (\"AUROC:\", np.mean(dfMetrics['auroc'])))\n",
        "print(\"%12s %.2f\" % (\"Precision:\", np.mean(dfMetrics['precision'])))\n",
        "print(\"%12s %.2f\" % (\"Recall:\", np.mean(dfMetrics['recall'])))\n",
        "print(\"%12s %.2f\" % (\"Accuracy:\", np.mean(dfMetrics['accuracy'])))\n",
        "\n",
        "\n",
        "print(\"\\n%6s %.2f\" % (\"Med AUROC:\", np.median(dfMetrics['auroc'])))\n",
        "\n",
        "# Get median iterations\n",
        "med_auroc = np.median(aurocs)\n",
        "med_auroc_idx = np.argsort(aurocs)[len(aurocs)//2]\n",
        "\n",
        "# Plot confusion matrix of median iteration\n",
        "cf_matrix = confusion_matrix(all_y_test_task_score[med_auroc_idx], predictions_task_score[med_auroc_idx])\n",
        "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
        "categories = ['Zero', 'One']\n",
        "make_confusion_matrix(cf_matrix, \n",
        "                      group_names=labels,\n",
        "                      categories=categories, \n",
        "                      cmap='Blues')\n",
        "# TODO: Save confusion matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezAHsr23AWSM",
        "outputId": "07917f0e-bde7-4fe9-d5c4-60f87593c494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "\tFold:  1\n"
          ]
        }
      ]
    }
  ]
}